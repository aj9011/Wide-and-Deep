{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil, os, warnings, re, datetime, multiprocessing\n",
    "warnings.filterwarnings(action='ignore')\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import _pickle as pickle\n",
    "from gensim.models import Doc2Vec\n",
    "from itertools import chain, combinations\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import namedtuple, Counter\n",
    "from sklearn.preprocessing import MultiLabelBinarizer, LabelEncoder\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "warnings.filterwarnings(action='default')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start = datetime.datetime.now()\n",
    "# 주문_2014 = pd.read_csv('C:/Users/kim85/OneDrive/Project_AgileSoda/원본/추가5차_180920/주문_2014.csv', encoding = 'utf-8', index_col=0, dtype = 'str')\n",
    "# 주문_2015 = pd.read_csv('C:/Users/kim85/OneDrive/Project_AgileSoda/원본/추가5차_180920/주문_2015.csv', encoding = 'utf-8', index_col=0, dtype = 'str')\n",
    "# 주문_2016 = pd.read_csv('C:/Users/kim85/OneDrive/Project_AgileSoda/원본/추가5차_180920/주문_2016.csv', encoding = 'utf-8', index_col=0, dtype = 'str')\n",
    "# 주문_2017 = pd.read_csv('C:/Users/kim85/OneDrive/Project_AgileSoda/원본/추가5차_180920/주문_2017.csv', encoding = 'utf-8', index_col=0, dtype = 'str')\n",
    "# 주문_2018 = pd.read_csv('C:/Users/kim85/OneDrive/Project_AgileSoda/원본/추가5차_180920/주문_2018.csv', encoding = 'utf-8', index_col=0, dtype = 'str')\n",
    "# 주문상품_2014 = pd.read_csv('C:/Users/kim85/OneDrive/Project_AgileSoda/원본/추가5차_180920/주문상품_2014.csv', encoding = 'utf-8', index_col=0, dtype = 'str')\n",
    "# 주문상품_2015 = pd.read_csv('C:/Users/kim85/OneDrive/Project_AgileSoda/원본/추가5차_180920/주문상품_2015.csv', encoding = 'utf-8', index_col=0, dtype = 'str')\n",
    "# 주문상품_2016 = pd.read_csv('C:/Users/kim85/OneDrive/Project_AgileSoda/원본/추가5차_180920/주문상품_2016.csv', encoding = 'utf-8', index_col=0, dtype = 'str')\n",
    "# 주문상품_2017 = pd.read_csv('C:/Users/kim85/OneDrive/Project_AgileSoda/원본/추가5차_180920/주문상품_2017.csv', encoding = 'utf-8', index_col=0, dtype = 'str')\n",
    "# 주문상품_2018 = pd.read_csv('C:/Users/kim85/OneDrive/Project_AgileSoda/원본/추가5차_180920/주문상품_2018.csv', encoding = 'utf-8', index_col=0, dtype = 'str')\n",
    "# 주문상품출하_2014 = pd.read_csv('C:/Users/kim85/OneDrive/Project_AgileSoda/원본/추가5차_180920/주문상품출하_2014.csv', encoding = 'utf-8', index_col=0, dtype = 'str')\n",
    "# 주문상품출하_2015 = pd.read_csv('C:/Users/kim85/OneDrive/Project_AgileSoda/원본/추가5차_180920/주문상품출하_2015.csv', encoding = 'utf-8', index_col=0, dtype = 'str')\n",
    "# 주문상품출하_2016 = pd.read_csv('C:/Users/kim85/OneDrive/Project_AgileSoda/원본/추가5차_180920/주문상품출하_2016.csv', encoding = 'utf-8', index_col=0, dtype = 'str')\n",
    "# 주문상품출하_2017 = pd.read_csv('C:/Users/kim85/OneDrive/Project_AgileSoda/원본/추가5차_180920/주문상품출하_2017.csv', encoding = 'utf-8', index_col=0, dtype = 'str')\n",
    "# 주문상품출하_2018 = pd.read_csv('C:/Users/kim85/OneDrive/Project_AgileSoda/원본/추가5차_180920/주문상품출하_2018.csv', encoding = 'utf-8', index_col=0, dtype = 'str')\n",
    "# 상품마스터 = pd.read_csv('c:/Users/kim85/OneDrive/Project_AgileSoda/원본/추가6차_181005/상품마스터.csv',encoding ='utf-8',dtype = 'str')\n",
    "# 조직마스터 = pd.read_csv('c:/users/kim85/OneDrive/Project_AgileSoda/원본/추가6차_181005/조직마스터.csv', encoding ='utf-8', dtype ='str')\n",
    "# 사업장= pd.read_csv('c:/users/kim85/OneDrive/Project_AgileSoda/원본/추가6차_181005/사업장.csv', encoding ='utf-8', dtype ='str')\n",
    "# 공사유형 = pd.read_csv('c:/users/kim85/OneDrive/Project_AgileSoda/원본/추가6차_181005/공사유형.csv', encoding ='utf-8', dtype ='str')\n",
    "\n",
    "# 주문 = pd.concat([주문_2014, 주문_2015, 주문_2016, 주문_2017, 주문_2018])\n",
    "# 주문상품 = pd.concat([주문상품_2014, 주문상품_2015, 주문상품_2016, 주문상품_2017, 주문상품_2018])\n",
    "# 주문상품출하 = pd.concat([주문상품출하_2014, 주문상품출하_2015, 주문상품출하_2016, 주문상품출하_2017, 주문상품출하_2018])\n",
    "\n",
    "# # 주문 처리\n",
    "# 주문 = 주문.reset_index()[['ORDE_IDEN_NUMB','CONS_IDEN_NAME','GROUPID','CLIENTID','BRANCHID',\n",
    "#                        'DELI_AREA_CODE','REGI_DATE_TIME','ORDE_USER_ID']].drop_duplicates(keep='first')\n",
    "# 주문상품 = 주문상품.reset_index()[['ORDE_IDEN_NUMB','ORDE_SEQU_NUMB','GOOD_IDEN_NUMB',\n",
    "#                            'ORDE_REQU_QUAN']].drop_duplicates(keep='first')\n",
    "# 주문상품 = 주문상품.groupby(['ORDE_IDEN_NUMB','GOOD_IDEN_NUMB'])['ORDE_REQU_QUAN'].agg('sum').reset_index()\n",
    "# 주문상품출하 =  주문상품출하.reset_index()[['ORDE_IDEN_NUMB', 'DELI_STAT_FLAG']].drop_duplicates(keep='first')\n",
    "# 주문상품출하 = 주문상품출하[주문상품출하.DELI_STAT_FLAG=='70'].ORDE_IDEN_NUMB.unique()\n",
    "\n",
    "# 주문상품_주문 = pd.merge(주문상품, 주문, on = 'ORDE_IDEN_NUMB', how = 'left')\n",
    "# 주문상품_주문_출하 = 주문상품_주문[주문상품_주문.ORDE_IDEN_NUMB.isin(주문상품출하)]\n",
    "# 주문전체 = 주문상품_주문_출하[주문상품_주문_출하.GROUPID != '101'].drop_duplicates(keep='first')\n",
    "\n",
    "# # 상품 처리\n",
    "# 상품마스터 = 상품마스터[['good_iden_numb','cate_id','good_name','good_spec','good_type','repre_good']].drop_duplicates(keep='first')\n",
    "# 상품마스터 = 상품마스터.rename(columns = {'good_iden_numb':'GOOD_IDEN_NUMB'})\n",
    "# # repre_good - Y : 옵션대표상품, N : 단품, P : 옵션상품 // good_type - 10 : 일반, 20 : 지정,60 : 공구, 70 : 안전,80 : 보안\n",
    "\n",
    "# 상품주문전체 = pd.merge(주문전체, 상품마스터, on = 'GOOD_IDEN_NUMB', how = 'left')\n",
    "# 상품주문전체 = 상품주문전체[상품주문전체.repre_good=='N'] # 옵션상품 제외\n",
    "\n",
    "# # 사업장 처리\n",
    "# 사업장 = pd.concat([\n",
    "#         사업장[['BRANCHID','AREATYPE','BRANCHBUSITYPE','BRANCHBUSICLAS','WORKID']].rename(columns={'BRANCHID':'BORGID'}), \n",
    "#         사업장[['BRANCHCD','AREATYPE','BRANCHBUSITYPE','BRANCHBUSICLAS','WORKID']].rename(columns={'BRANCHCD':'BORGID'})\n",
    "#     ], axis=0).drop_duplicates(keep='first')\n",
    "\n",
    "# 공사유형_사업장 = pd.merge(\n",
    "#     사업장, \n",
    "#     공사유형[['WORKID','WORKNM']].drop_duplicates(keep='first'), \n",
    "#     how = 'left', on = 'WORKID')\n",
    "\n",
    "# 조직마스터 = 조직마스터[(조직마스터.BORGTYPECD == 'BCH') & (조직마스터.SVCTYPECD == 'BUY')] # 사업장레벨 및 구매사만\n",
    "# 조직마스터 = pd.concat([\n",
    "#         조직마스터[['BORGID','BORGNM']], \n",
    "#         조직마스터[['BORGCD','BORGNM']].rename(columns={'BORGCD':'BORGID'})\n",
    "#     ], axis=0).drop_duplicates(keep='first')\n",
    "\n",
    "# 조직전체 = pd.merge(조직마스터, 공사유형_사업장, how = 'left', on = 'BORGID').rename(columns={'BORGID':'BRANCHID'})\n",
    "\n",
    "# df = pd.merge(상품주문전체,조직전체,how = 'left',on = 'BRANCHID')\n",
    "# # 불필요컬럼 제외\n",
    "# df = df.drop([\n",
    "#         'CONS_IDEN_NAME','GROUPID','CLIENTID','ORDE_USER_ID','good_name','good_spec','repre_good','WORKNM','BORGNM'\n",
    "#         ], axis = 1)\n",
    "# df = df.drop_duplicates(keep='first')\n",
    "# # 날짜컬럼추가\n",
    "# df[\"REGI_DATE\"] = pd.to_datetime(df.REGI_DATE_TIME).dt.date\n",
    "# # 문자 -> 숫자화1\n",
    "# bptype = LabelEncoder()\n",
    "# df['BpType']=bptype.fit_transform(df.BRANCHBUSITYPE.tolist()).astype('str')\n",
    "# with open('./le_BpType.pkl','wb') as f:\n",
    "#     pickle.dump(bptype, f)\n",
    "# # 문자 -> 숫자화2\n",
    "# bpclass = LabelEncoder()\n",
    "# df['BpClass']=bpclass.fit_transform(df.BRANCHBUSICLAS.tolist()).astype('str')\n",
    "# with open('./le_BpClass.pkl','wb') as g:\n",
    "#     pickle.dump(bpclass, g)\n",
    "# # 널 데이터 제외(764건)\n",
    "# df = df.dropna()\n",
    "# df = df.drop(['BRANCHBUSITYPE','BRANCHBUSICLAS'],axis =1)\n",
    "# df.columns = ['OrderNum','ProductCode','ProductAmt','BpID', 'Deli_Region','OrderTime','ProductCategory','ProductClass','Region',\n",
    "#               'ConstructionType','OrderDate','BpType','BpClass']\n",
    "# duration = datetime.datetime.now()-start\n",
    "# m, s = divmod(duration.seconds, 60);h, m = divmod(m, 60);print(\"[%02d:%02d:%02d]\" %(h, m, s))\n",
    "# df = df[['OrderNum','OrderTime','OrderDate','ProductCode','ProductCategory', 'ProductClass','ProductAmt', \n",
    "#     'Deli_Region','BpID','Region','ConstructionType','BpType', 'BpClass']]\n",
    "# # 이상 데이터 불러오기 및 필요 데이터 필터링 부분.\n",
    "# df.to_csv('./Datasets/dfdf_181109_new.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('C:/pythondata/widendepp/df_181109_new.csv', dtype='str', encoding = 'utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>OrderNum</th>\n",
       "      <th>OrderTime</th>\n",
       "      <th>OrderDate</th>\n",
       "      <th>ProductCode</th>\n",
       "      <th>ProductCategory</th>\n",
       "      <th>ProductClass</th>\n",
       "      <th>ProductAmt</th>\n",
       "      <th>Deli_Region</th>\n",
       "      <th>BpID</th>\n",
       "      <th>Region</th>\n",
       "      <th>ConstructionType</th>\n",
       "      <th>BpType</th>\n",
       "      <th>BpClass</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>001404030001</td>\n",
       "      <td>2014-04-03 17:15:08.153</td>\n",
       "      <td>2014-04-03</td>\n",
       "      <td>10000001489</td>\n",
       "      <td>100761</td>\n",
       "      <td>20</td>\n",
       "      <td>1200</td>\n",
       "      <td>14</td>\n",
       "      <td>304956</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>53</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>001405270001</td>\n",
       "      <td>2014-05-27 09:29:59.153</td>\n",
       "      <td>2014-05-27</td>\n",
       "      <td>7400800012</td>\n",
       "      <td>100761</td>\n",
       "      <td>20</td>\n",
       "      <td>500</td>\n",
       "      <td>14</td>\n",
       "      <td>304956</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>53</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>001406030002</td>\n",
       "      <td>2014-06-03 17:30:24.200</td>\n",
       "      <td>2014-06-03</td>\n",
       "      <td>7400800012</td>\n",
       "      <td>100761</td>\n",
       "      <td>20</td>\n",
       "      <td>1500</td>\n",
       "      <td>14</td>\n",
       "      <td>304956</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>53</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>001410160001</td>\n",
       "      <td>2014-10-16 09:58:55.273</td>\n",
       "      <td>2014-10-16</td>\n",
       "      <td>10000001488</td>\n",
       "      <td>100761</td>\n",
       "      <td>20</td>\n",
       "      <td>600</td>\n",
       "      <td>14</td>\n",
       "      <td>304956</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>53</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>001411050001</td>\n",
       "      <td>2014-11-05 11:40:57.543</td>\n",
       "      <td>2014-11-05</td>\n",
       "      <td>10000001489</td>\n",
       "      <td>100761</td>\n",
       "      <td>20</td>\n",
       "      <td>1200</td>\n",
       "      <td>14</td>\n",
       "      <td>304956</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>53</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       OrderNum                OrderTime   OrderDate  ProductCode  \\\n",
       "0  001404030001  2014-04-03 17:15:08.153  2014-04-03  10000001489   \n",
       "1  001405270001  2014-05-27 09:29:59.153  2014-05-27   7400800012   \n",
       "2  001406030002  2014-06-03 17:30:24.200  2014-06-03   7400800012   \n",
       "3  001410160001  2014-10-16 09:58:55.273  2014-10-16  10000001488   \n",
       "4  001411050001  2014-11-05 11:40:57.543  2014-11-05  10000001489   \n",
       "\n",
       "  ProductCategory ProductClass ProductAmt Deli_Region    BpID Region  \\\n",
       "0          100761           20       1200          14  304956     10   \n",
       "1          100761           20        500          14  304956     10   \n",
       "2          100761           20       1500          14  304956     10   \n",
       "3          100761           20        600          14  304956     10   \n",
       "4          100761           20       1200          14  304956     10   \n",
       "\n",
       "  ConstructionType BpType BpClass  \n",
       "0                9     53      81  \n",
       "1                9     53      81  \n",
       "2                9     53      81  \n",
       "3                9     53      81  \n",
       "4                9     53      81  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['OrderTime'] =  pd.to_datetime(df['OrderTime'])\n",
    "df['OrderDate'] =  pd.to_datetime(df['OrderDate'])\n",
    "df['OrderYear'] = df['OrderDate'].dt.year\n",
    "df['ProductAmt'] =  df['ProductAmt'].astype('int64')\n",
    "df = df.drop(['OrderNum', 'OrderTime', 'Deli_Region','ProductAmt','ProductCategory','ProductClass'],axis = 1)\n",
    "\n",
    "df1 = df.groupby(['OrderDate','BpID','Region','ConstructionType','BpType','BpClass','OrderYear'])['ProductCode'].apply(list).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>OrderDate</th>\n",
       "      <th>BpID</th>\n",
       "      <th>Region</th>\n",
       "      <th>ConstructionType</th>\n",
       "      <th>BpType</th>\n",
       "      <th>BpClass</th>\n",
       "      <th>OrderYear</th>\n",
       "      <th>ProductCode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2014-01-02</td>\n",
       "      <td>304660</td>\n",
       "      <td>41</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>205</td>\n",
       "      <td>2014</td>\n",
       "      <td>[10000000332, 10000000334, 10000000338, 100000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2014-01-02</td>\n",
       "      <td>304685</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>190</td>\n",
       "      <td>3</td>\n",
       "      <td>2014</td>\n",
       "      <td>[10000001380, 10000001455, 10000001507]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2014-01-02</td>\n",
       "      <td>304695</td>\n",
       "      <td>20</td>\n",
       "      <td>36</td>\n",
       "      <td>213</td>\n",
       "      <td>149</td>\n",
       "      <td>2014</td>\n",
       "      <td>[10000002450, 10000002497, 10000002501, 100000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2014-01-02</td>\n",
       "      <td>304809</td>\n",
       "      <td>30</td>\n",
       "      <td>16</td>\n",
       "      <td>165</td>\n",
       "      <td>96</td>\n",
       "      <td>2014</td>\n",
       "      <td>[10000008077, 10000008077]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2014-01-02</td>\n",
       "      <td>304823</td>\n",
       "      <td>10</td>\n",
       "      <td>16</td>\n",
       "      <td>165</td>\n",
       "      <td>96</td>\n",
       "      <td>2014</td>\n",
       "      <td>[10000008077, 10000008077]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   OrderDate    BpID Region ConstructionType BpType BpClass  OrderYear  \\\n",
       "0 2014-01-02  304660     41                5      7     205       2014   \n",
       "1 2014-01-02  304685     20               20    190       3       2014   \n",
       "2 2014-01-02  304695     20               36    213     149       2014   \n",
       "3 2014-01-02  304809     30               16    165      96       2014   \n",
       "4 2014-01-02  304823     10               16    165      96       2014   \n",
       "\n",
       "                                         ProductCode  \n",
       "0  [10000000332, 10000000334, 10000000338, 100000...  \n",
       "1            [10000001380, 10000001455, 10000001507]  \n",
       "2  [10000002450, 10000002497, 10000002501, 100000...  \n",
       "3                         [10000008077, 10000008077]  \n",
       "4                         [10000008077, 10000008077]  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(104326, 8)\n"
     ]
    }
   ],
   "source": [
    "df2 = df1.sort_values(['BpID','OrderDate']).reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>OrderDate</th>\n",
       "      <th>BpID</th>\n",
       "      <th>Region</th>\n",
       "      <th>ConstructionType</th>\n",
       "      <th>BpType</th>\n",
       "      <th>BpClass</th>\n",
       "      <th>OrderYear</th>\n",
       "      <th>ProductCode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-03-13</td>\n",
       "      <td>304573</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>149</td>\n",
       "      <td>21</td>\n",
       "      <td>2017</td>\n",
       "      <td>[10000023533, 10000056705]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2014-03-05</td>\n",
       "      <td>304576</td>\n",
       "      <td>12</td>\n",
       "      <td>7</td>\n",
       "      <td>161</td>\n",
       "      <td>96</td>\n",
       "      <td>2014</td>\n",
       "      <td>[6601000010, 6601000024, 6601000053, 660100006...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2014-04-02</td>\n",
       "      <td>304576</td>\n",
       "      <td>12</td>\n",
       "      <td>7</td>\n",
       "      <td>161</td>\n",
       "      <td>96</td>\n",
       "      <td>2014</td>\n",
       "      <td>[10000008077, 6601000039, 6601000041, 66010000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2014-07-04</td>\n",
       "      <td>304576</td>\n",
       "      <td>12</td>\n",
       "      <td>7</td>\n",
       "      <td>161</td>\n",
       "      <td>96</td>\n",
       "      <td>2014</td>\n",
       "      <td>[6601000001]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2014-08-01</td>\n",
       "      <td>304576</td>\n",
       "      <td>12</td>\n",
       "      <td>7</td>\n",
       "      <td>161</td>\n",
       "      <td>96</td>\n",
       "      <td>2014</td>\n",
       "      <td>[10000009978, 10000010251, 6601000041, 6601000...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   OrderDate    BpID Region ConstructionType BpType BpClass  OrderYear  \\\n",
       "0 2017-03-13  304573     11                3    149      21       2017   \n",
       "1 2014-03-05  304576     12                7    161      96       2014   \n",
       "2 2014-04-02  304576     12                7    161      96       2014   \n",
       "3 2014-07-04  304576     12                7    161      96       2014   \n",
       "4 2014-08-01  304576     12                7    161      96       2014   \n",
       "\n",
       "                                         ProductCode  \n",
       "0                         [10000023533, 10000056705]  \n",
       "1  [6601000010, 6601000024, 6601000053, 660100006...  \n",
       "2  [10000008077, 6601000039, 6601000041, 66010000...  \n",
       "3                                       [6601000001]  \n",
       "4  [10000009978, 10000010251, 6601000041, 6601000...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(104326, 8)\n"
     ]
    }
   ],
   "source": [
    "print(df2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>OrderDate</th>\n",
       "      <th>BpID</th>\n",
       "      <th>Region</th>\n",
       "      <th>ConstructionType</th>\n",
       "      <th>BpType</th>\n",
       "      <th>BpClass</th>\n",
       "      <th>OrderYear</th>\n",
       "      <th>ProductCode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-03-13</td>\n",
       "      <td>304573</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>149</td>\n",
       "      <td>21</td>\n",
       "      <td>2017</td>\n",
       "      <td>[10000023533, 10000056705]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2014-03-05</td>\n",
       "      <td>304576</td>\n",
       "      <td>12</td>\n",
       "      <td>7</td>\n",
       "      <td>161</td>\n",
       "      <td>96</td>\n",
       "      <td>2014</td>\n",
       "      <td>[6601000010, 6601000024, 6601000053, 660100006...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2014-04-02</td>\n",
       "      <td>304576</td>\n",
       "      <td>12</td>\n",
       "      <td>7</td>\n",
       "      <td>161</td>\n",
       "      <td>96</td>\n",
       "      <td>2014</td>\n",
       "      <td>[10000008077, 6601000039, 6601000041, 66010000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2014-07-04</td>\n",
       "      <td>304576</td>\n",
       "      <td>12</td>\n",
       "      <td>7</td>\n",
       "      <td>161</td>\n",
       "      <td>96</td>\n",
       "      <td>2014</td>\n",
       "      <td>[6601000001]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   OrderDate    BpID Region ConstructionType BpType BpClass  OrderYear  \\\n",
       "0 2017-03-13  304573     11                3    149      21       2017   \n",
       "1 2014-03-05  304576     12                7    161      96       2014   \n",
       "2 2014-04-02  304576     12                7    161      96       2014   \n",
       "3 2014-07-04  304576     12                7    161      96       2014   \n",
       "\n",
       "                                         ProductCode  \n",
       "0                         [10000023533, 10000056705]  \n",
       "1  [6601000010, 6601000024, 6601000053, 660100006...  \n",
       "2  [10000008077, 6601000039, 6601000041, 66010000...  \n",
       "3                                       [6601000001]  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.iloc[0:4,].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = df2.iloc[0:4,].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tmp_pc = tmp['ProductCode'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['10000023533', '10000056705'],\n",
       " ['6601000010',\n",
       "  '6601000024',\n",
       "  '6601000053',\n",
       "  '6601000067',\n",
       "  '6601000170',\n",
       "  '6601000171',\n",
       "  '6601000174',\n",
       "  '6601000196'],\n",
       " ['10000008077',\n",
       "  '6601000039',\n",
       "  '6601000041',\n",
       "  '6601000045',\n",
       "  '6601000049',\n",
       "  '6601000050',\n",
       "  '6601000055',\n",
       "  '6601000060',\n",
       "  '6601000067',\n",
       "  '6601000174',\n",
       "  '6601000196'],\n",
       " ['6601000001']]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp_pc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'304573'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp['BpID'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['6601000001']]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp_pc[3:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['6601000050',\n",
       " '6601000055',\n",
       " '6601000174',\n",
       " '10000008077',\n",
       " '6601000053',\n",
       " '6601000045',\n",
       " '6601000049',\n",
       " '6601000170',\n",
       " '6601000067',\n",
       " '6601000010',\n",
       " '6601000039',\n",
       " '6601000171',\n",
       " '6601000024',\n",
       " '6601000196',\n",
       " '10000023533',\n",
       " '6601000060',\n",
       " '10000056705',\n",
       " '6601000041']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(set(chain.from_iterable(tmp_pc[0:3])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['6601000001']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(set(chain.from_iterable(tmp_pc[3:4])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loop start!!\n",
      "[0]/[104323]-----[00:00:00]\n",
      "[10000]/[104323]-----[00:00:04]\n",
      "[20000]/[104323]-----[00:00:08]\n",
      "[30000]/[104323]-----[00:00:13]\n",
      "[40000]/[104323]-----[00:00:17]\n",
      "[50000]/[104323]-----[00:00:22]\n",
      "[60000]/[104323]-----[00:00:26]\n",
      "[70000]/[104323]-----[00:00:31]\n",
      "[80000]/[104323]-----[00:00:35]\n",
      "[90000]/[104323]-----[00:00:40]\n",
      "[100000]/[104323]-----[00:00:44]\n"
     ]
    }
   ],
   "source": [
    "nx =  3 # 이전 기록 갯수(X)\n",
    "ny = 1 # 이후 기록 갯수(Y)\n",
    "df2_1 = { 'BpID':[],  'x_ProductCodes':[],  'y_ProductCodes':[]}\n",
    "print('Loop start!!')\n",
    "start = datetime.datetime.now()\n",
    "for ii in range(len(df2)-nx):\n",
    "    targetdata = df2.iloc[ii:ii+nx+ny,].reset_index(drop=True)\n",
    "    if len(targetdata['BpID'].unique())==1 and len(targetdata) == nx+ny:\n",
    "        tmpdata1 = targetdata['ProductCode'].tolist()\n",
    "        df2_1['BpID'].append(targetdata['BpID'][0])\n",
    "        df2_1['x_ProductCodes'].append(list(set(chain.from_iterable(tmpdata1[0:nx]))))\n",
    "        df2_1['y_ProductCodes'].append(list(set(chain.from_iterable(tmpdata1[nx:nx+ny]))))\n",
    "    if ii % 10000 == 0:\n",
    "        duration = datetime.datetime.now()-start;m, s = divmod(duration.seconds, 60)\n",
    "        h, m = divmod(m, 60);print(\"[%d]/[%d]-----[%02d:%02d:%02d]\" %(ii, len(df2)-nx, h, m, s)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2_2 = pd.DataFrame(df2_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BpID</th>\n",
       "      <th>x_ProductCodes</th>\n",
       "      <th>y_ProductCodes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>304576</td>\n",
       "      <td>[6601000050, 6601000055, 6601000174, 100000080...</td>\n",
       "      <td>[6602300021, 6601000174, 6601000045, 100000102...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>304576</td>\n",
       "      <td>[6601000050, 6601000055, 6601000174, 660230002...</td>\n",
       "      <td>[10000009271, 6600200174, 7400900162]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>304576</td>\n",
       "      <td>[6602300021, 6601000174, 6601000045, 100000102...</td>\n",
       "      <td>[6601000174, 6602300001, 6601000067, 100000076...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>304576</td>\n",
       "      <td>[6602300021, 6601000174, 6601000045, 100000102...</td>\n",
       "      <td>[10000010251]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>304576</td>\n",
       "      <td>[6601000174, 10000010251, 10000009271, 6602300...</td>\n",
       "      <td>[6601000060, 10000009271, 10000007607]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>304576</td>\n",
       "      <td>[6601000174, 10000010251, 10000009271, 6602300...</td>\n",
       "      <td>[6601000001]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>304576</td>\n",
       "      <td>[10000010251, 10000009271, 10000007607, 660100...</td>\n",
       "      <td>[6601000174, 10000009978, 6601000067, 66010000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>304576</td>\n",
       "      <td>[6601000174, 10000009978, 10000009271, 6601000...</td>\n",
       "      <td>[6601000174, 6601000043, 10000010251, 66010000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>304576</td>\n",
       "      <td>[6601000174, 6601000043, 10000010251, 66010000...</td>\n",
       "      <td>[10000010251, 6601000058, 6602300012, 66010000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>304576</td>\n",
       "      <td>[6601000174, 6601000043, 10000010251, 66010000...</td>\n",
       "      <td>[6601000001, 6601000045, 10000010251]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>304576</td>\n",
       "      <td>[6601000174, 6601000043, 10000010251, 66010000...</td>\n",
       "      <td>[10000018688, 10000018684, 10000018692, 660100...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>304576</td>\n",
       "      <td>[10000018688, 6601000045, 10000010251, 1000001...</td>\n",
       "      <td>[10000018676, 6602300008, 6601000045, 66010000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>304576</td>\n",
       "      <td>[10000018688, 10000018676, 6602300008, 6601000...</td>\n",
       "      <td>[10000009978, 6601000136, 6601000058, 6601000060]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>304576</td>\n",
       "      <td>[10000018688, 10000018676, 6602300008, 6601000...</td>\n",
       "      <td>[6601000060, 10000018609, 6600200058]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>304576</td>\n",
       "      <td>[10000018676, 6602300008, 6601000045, 66010000...</td>\n",
       "      <td>[10000018684, 10000023099, 10000007586, 100000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>304576</td>\n",
       "      <td>[10000009978, 6600200058, 10000018684, 6601000...</td>\n",
       "      <td>[10000018671, 6601000174, 6601000199, 66023000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>304576</td>\n",
       "      <td>[10000018671, 6601000174, 6601000199, 66023000...</td>\n",
       "      <td>[6601000024, 10000010251]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>304576</td>\n",
       "      <td>[10000018671, 6601000174, 6601000199, 66023000...</td>\n",
       "      <td>[6601000045, 10000018792, 7000100003, 66010000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>304576</td>\n",
       "      <td>[10000018671, 6601000174, 6601000199, 66023000...</td>\n",
       "      <td>[10000018611, 6601000174, 6601000045, 10000010...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>304576</td>\n",
       "      <td>[10000018611, 6601000174, 6601000045, 10000010...</td>\n",
       "      <td>[10000018609, 10000010251]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>304576</td>\n",
       "      <td>[10000018611, 6601000174, 6601000045, 10000010...</td>\n",
       "      <td>[6601000174, 2800500414, 6601000049, 660100003...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>304576</td>\n",
       "      <td>[10000018611, 6601000174, 6601000045, 10000010...</td>\n",
       "      <td>[6601000174, 6601000045, 10000010251, 10000009...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>304576</td>\n",
       "      <td>[6601000174, 6601000045, 2800500414, 100000102...</td>\n",
       "      <td>[6601000174, 6601000024, 10000010251]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>304576</td>\n",
       "      <td>[6601000174, 6601000045, 2800500414, 660100004...</td>\n",
       "      <td>[6601000053, 6601000045, 6601000049, 700010009...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>304576</td>\n",
       "      <td>[6601000174, 6601000045, 10000010251, 66010000...</td>\n",
       "      <td>[10000019403]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>304576</td>\n",
       "      <td>[6601000174, 6601000045, 10000010251, 66010000...</td>\n",
       "      <td>[6601000050, 6601000091, 6601000174, 660100004...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>304576</td>\n",
       "      <td>[6601000050, 6601000091, 6601000174, 660100005...</td>\n",
       "      <td>[6601000045, 10000009978, 6601000039, 10000025...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>304576</td>\n",
       "      <td>[6601000050, 6601000091, 6601000174, 660100004...</td>\n",
       "      <td>[6601000174, 10000025060, 10000025058, 1000002...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>304576</td>\n",
       "      <td>[6601000174, 10000025067, 2800500412, 10000000...</td>\n",
       "      <td>[10000025060, 10000025058, 10000025062, 660100...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>304576</td>\n",
       "      <td>[6601000174, 10000025058, 6601000045, 10000025...</td>\n",
       "      <td>[6600201041, 6601000174, 10000025060, 10000000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101134</th>\n",
       "      <td>GEN2040001</td>\n",
       "      <td>[10000024528, 7400100005, 10000009436, 1000001...</td>\n",
       "      <td>[7400100001, 10000007689, 10000018592]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101135</th>\n",
       "      <td>GEN2040001</td>\n",
       "      <td>[7400100005, 10000009436, 10000018592, 7400100...</td>\n",
       "      <td>[10000001253, 10000024528, 10000061721, 100000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101136</th>\n",
       "      <td>GEN2040001</td>\n",
       "      <td>[10000001253, 10000018592, 10000001252, 740010...</td>\n",
       "      <td>[10000000313, 10000000316]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101137</th>\n",
       "      <td>GEN2040001</td>\n",
       "      <td>[10000001253, 10000000313, 10000024528, 100000...</td>\n",
       "      <td>[10000000310, 10000000314, 10000017939]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101138</th>\n",
       "      <td>GEN2040001</td>\n",
       "      <td>[10000001253, 10000000313, 10000024528, 100000...</td>\n",
       "      <td>[7400100023, 6600200088]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101139</th>\n",
       "      <td>GEN2040001</td>\n",
       "      <td>[10000000313, 10000000314, 10000000310, 100000...</td>\n",
       "      <td>[6600200088, 10000000317, 10000000316, 1000000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101140</th>\n",
       "      <td>GEN2040001</td>\n",
       "      <td>[10000000314, 10000000317, 10000017939, 100000...</td>\n",
       "      <td>[10000000317, 10000018870, 10000057380, 100000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101141</th>\n",
       "      <td>GEN2040001</td>\n",
       "      <td>[10000000317, 10000018870, 10000057380, 100000...</td>\n",
       "      <td>[10000010274, 10000010276]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101142</th>\n",
       "      <td>GEN2040001</td>\n",
       "      <td>[10000000317, 10000018870, 10000057380, 100000...</td>\n",
       "      <td>[10000018596, 10000018870, 10000058701, 100000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101143</th>\n",
       "      <td>GEN2040001</td>\n",
       "      <td>[10000018596, 10000000317, 10000018870, 100000...</td>\n",
       "      <td>[10000000313, 10000000310, 10000024544, 100000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101144</th>\n",
       "      <td>GEN2040001</td>\n",
       "      <td>[10000018596, 10000000313, 10000000310, 100000...</td>\n",
       "      <td>[10000057380, 10000001518, 10000010814]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101145</th>\n",
       "      <td>GEN2040001</td>\n",
       "      <td>[10000018596, 10000000313, 10000010814, 100000...</td>\n",
       "      <td>[10000024528, 10000000364]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101146</th>\n",
       "      <td>GEN2040001</td>\n",
       "      <td>[10000000313, 10000024528, 10000010814, 100000...</td>\n",
       "      <td>[7400100005, 7400100012, 7400900175, 100000478...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101147</th>\n",
       "      <td>GEN2040001</td>\n",
       "      <td>[10000024528, 7400100005, 7400100012, 10000010...</td>\n",
       "      <td>[10000000513, 10000000582, 10000000514]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101148</th>\n",
       "      <td>GEN2040001</td>\n",
       "      <td>[10000024528, 7400100005, 7400100012, 74009001...</td>\n",
       "      <td>[10000018590, 7400900175, 10000024544, 1000002...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101149</th>\n",
       "      <td>GEN2040001</td>\n",
       "      <td>[10000018590, 7400100005, 7400100012, 74009001...</td>\n",
       "      <td>[10000000313, 10000024528, 10000018590, 100000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101150</th>\n",
       "      <td>GEN2040001</td>\n",
       "      <td>[10000000313, 10000024528, 10000018590, 100000...</td>\n",
       "      <td>[10000058701, 10000058764]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101151</th>\n",
       "      <td>GEN2040001</td>\n",
       "      <td>[10000000313, 10000024528, 10000018590, 100000...</td>\n",
       "      <td>[10000005145, 10000058505, 10000001518, 100000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101152</th>\n",
       "      <td>GEN2040001</td>\n",
       "      <td>[6600200674, 10000058701, 10000018592, 1000002...</td>\n",
       "      <td>[10000018870, 10000057378]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101153</th>\n",
       "      <td>GEN2040001</td>\n",
       "      <td>[10000058701, 10000005145, 10000018870, 100000...</td>\n",
       "      <td>[6600201264, 6600201262, 10000018590, 66002012...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101154</th>\n",
       "      <td>GEN2040001</td>\n",
       "      <td>[6600201264, 10000018590, 6600201262, 10000018...</td>\n",
       "      <td>[7400100010, 7400100016, 7400100013]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101155</th>\n",
       "      <td>GEN2040001</td>\n",
       "      <td>[7400100010, 6600201264, 10000018590, 66002012...</td>\n",
       "      <td>[10000010173, 10000010313]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101156</th>\n",
       "      <td>GEN2040001</td>\n",
       "      <td>[7400100010, 6600201264, 6600201262, 100000185...</td>\n",
       "      <td>[10000010274, 6600201039]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101157</th>\n",
       "      <td>GEN2040001</td>\n",
       "      <td>[7400100010, 6600201039, 7400100013, 740010001...</td>\n",
       "      <td>[7400100010, 7400100017, 10000047805, 10000018...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101158</th>\n",
       "      <td>GEN2040001</td>\n",
       "      <td>[7400100010, 6600201039, 10000018870, 10000057...</td>\n",
       "      <td>[10000024544, 7400100023, 10000024560]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101159</th>\n",
       "      <td>GEN2040001</td>\n",
       "      <td>[7400100010, 6600201039, 10000018870, 10000057...</td>\n",
       "      <td>[7400900179, 7400900176, 7400900175]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101160</th>\n",
       "      <td>GEN2040001</td>\n",
       "      <td>[7400100010, 10000018870, 10000057380, 1000001...</td>\n",
       "      <td>[10000000310, 10000017939]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101161</th>\n",
       "      <td>GEN2040001</td>\n",
       "      <td>[10000024560, 7400900175, 10000024544, 7400900...</td>\n",
       "      <td>[7400100012, 7400100015]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101162</th>\n",
       "      <td>GEN2040001</td>\n",
       "      <td>[7400100012, 7400100015, 7400900175, 100000003...</td>\n",
       "      <td>[10000010173, 10000057378, 10000018870]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101163</th>\n",
       "      <td>GEN2040001</td>\n",
       "      <td>[7400100012, 7400100015, 10000000310, 10000018...</td>\n",
       "      <td>[10000018592, 10000018593]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>101164 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              BpID                                     x_ProductCodes  \\\n",
       "0           304576  [6601000050, 6601000055, 6601000174, 100000080...   \n",
       "1           304576  [6601000050, 6601000055, 6601000174, 660230002...   \n",
       "2           304576  [6602300021, 6601000174, 6601000045, 100000102...   \n",
       "3           304576  [6602300021, 6601000174, 6601000045, 100000102...   \n",
       "4           304576  [6601000174, 10000010251, 10000009271, 6602300...   \n",
       "5           304576  [6601000174, 10000010251, 10000009271, 6602300...   \n",
       "6           304576  [10000010251, 10000009271, 10000007607, 660100...   \n",
       "7           304576  [6601000174, 10000009978, 10000009271, 6601000...   \n",
       "8           304576  [6601000174, 6601000043, 10000010251, 66010000...   \n",
       "9           304576  [6601000174, 6601000043, 10000010251, 66010000...   \n",
       "10          304576  [6601000174, 6601000043, 10000010251, 66010000...   \n",
       "11          304576  [10000018688, 6601000045, 10000010251, 1000001...   \n",
       "12          304576  [10000018688, 10000018676, 6602300008, 6601000...   \n",
       "13          304576  [10000018688, 10000018676, 6602300008, 6601000...   \n",
       "14          304576  [10000018676, 6602300008, 6601000045, 66010000...   \n",
       "15          304576  [10000009978, 6600200058, 10000018684, 6601000...   \n",
       "16          304576  [10000018671, 6601000174, 6601000199, 66023000...   \n",
       "17          304576  [10000018671, 6601000174, 6601000199, 66023000...   \n",
       "18          304576  [10000018671, 6601000174, 6601000199, 66023000...   \n",
       "19          304576  [10000018611, 6601000174, 6601000045, 10000010...   \n",
       "20          304576  [10000018611, 6601000174, 6601000045, 10000010...   \n",
       "21          304576  [10000018611, 6601000174, 6601000045, 10000010...   \n",
       "22          304576  [6601000174, 6601000045, 2800500414, 100000102...   \n",
       "23          304576  [6601000174, 6601000045, 2800500414, 660100004...   \n",
       "24          304576  [6601000174, 6601000045, 10000010251, 66010000...   \n",
       "25          304576  [6601000174, 6601000045, 10000010251, 66010000...   \n",
       "26          304576  [6601000050, 6601000091, 6601000174, 660100005...   \n",
       "27          304576  [6601000050, 6601000091, 6601000174, 660100004...   \n",
       "28          304576  [6601000174, 10000025067, 2800500412, 10000000...   \n",
       "29          304576  [6601000174, 10000025058, 6601000045, 10000025...   \n",
       "...            ...                                                ...   \n",
       "101134  GEN2040001  [10000024528, 7400100005, 10000009436, 1000001...   \n",
       "101135  GEN2040001  [7400100005, 10000009436, 10000018592, 7400100...   \n",
       "101136  GEN2040001  [10000001253, 10000018592, 10000001252, 740010...   \n",
       "101137  GEN2040001  [10000001253, 10000000313, 10000024528, 100000...   \n",
       "101138  GEN2040001  [10000001253, 10000000313, 10000024528, 100000...   \n",
       "101139  GEN2040001  [10000000313, 10000000314, 10000000310, 100000...   \n",
       "101140  GEN2040001  [10000000314, 10000000317, 10000017939, 100000...   \n",
       "101141  GEN2040001  [10000000317, 10000018870, 10000057380, 100000...   \n",
       "101142  GEN2040001  [10000000317, 10000018870, 10000057380, 100000...   \n",
       "101143  GEN2040001  [10000018596, 10000000317, 10000018870, 100000...   \n",
       "101144  GEN2040001  [10000018596, 10000000313, 10000000310, 100000...   \n",
       "101145  GEN2040001  [10000018596, 10000000313, 10000010814, 100000...   \n",
       "101146  GEN2040001  [10000000313, 10000024528, 10000010814, 100000...   \n",
       "101147  GEN2040001  [10000024528, 7400100005, 7400100012, 10000010...   \n",
       "101148  GEN2040001  [10000024528, 7400100005, 7400100012, 74009001...   \n",
       "101149  GEN2040001  [10000018590, 7400100005, 7400100012, 74009001...   \n",
       "101150  GEN2040001  [10000000313, 10000024528, 10000018590, 100000...   \n",
       "101151  GEN2040001  [10000000313, 10000024528, 10000018590, 100000...   \n",
       "101152  GEN2040001  [6600200674, 10000058701, 10000018592, 1000002...   \n",
       "101153  GEN2040001  [10000058701, 10000005145, 10000018870, 100000...   \n",
       "101154  GEN2040001  [6600201264, 10000018590, 6600201262, 10000018...   \n",
       "101155  GEN2040001  [7400100010, 6600201264, 10000018590, 66002012...   \n",
       "101156  GEN2040001  [7400100010, 6600201264, 6600201262, 100000185...   \n",
       "101157  GEN2040001  [7400100010, 6600201039, 7400100013, 740010001...   \n",
       "101158  GEN2040001  [7400100010, 6600201039, 10000018870, 10000057...   \n",
       "101159  GEN2040001  [7400100010, 6600201039, 10000018870, 10000057...   \n",
       "101160  GEN2040001  [7400100010, 10000018870, 10000057380, 1000001...   \n",
       "101161  GEN2040001  [10000024560, 7400900175, 10000024544, 7400900...   \n",
       "101162  GEN2040001  [7400100012, 7400100015, 7400900175, 100000003...   \n",
       "101163  GEN2040001  [7400100012, 7400100015, 10000000310, 10000018...   \n",
       "\n",
       "                                           y_ProductCodes  \n",
       "0       [6602300021, 6601000174, 6601000045, 100000102...  \n",
       "1                   [10000009271, 6600200174, 7400900162]  \n",
       "2       [6601000174, 6602300001, 6601000067, 100000076...  \n",
       "3                                           [10000010251]  \n",
       "4                  [6601000060, 10000009271, 10000007607]  \n",
       "5                                            [6601000001]  \n",
       "6       [6601000174, 10000009978, 6601000067, 66010000...  \n",
       "7       [6601000174, 6601000043, 10000010251, 66010000...  \n",
       "8       [10000010251, 6601000058, 6602300012, 66010000...  \n",
       "9                   [6601000001, 6601000045, 10000010251]  \n",
       "10      [10000018688, 10000018684, 10000018692, 660100...  \n",
       "11      [10000018676, 6602300008, 6601000045, 66010000...  \n",
       "12      [10000009978, 6601000136, 6601000058, 6601000060]  \n",
       "13                  [6601000060, 10000018609, 6600200058]  \n",
       "14      [10000018684, 10000023099, 10000007586, 100000...  \n",
       "15      [10000018671, 6601000174, 6601000199, 66023000...  \n",
       "16                              [6601000024, 10000010251]  \n",
       "17      [6601000045, 10000018792, 7000100003, 66010000...  \n",
       "18      [10000018611, 6601000174, 6601000045, 10000010...  \n",
       "19                             [10000018609, 10000010251]  \n",
       "20      [6601000174, 2800500414, 6601000049, 660100003...  \n",
       "21      [6601000174, 6601000045, 10000010251, 10000009...  \n",
       "22                  [6601000174, 6601000024, 10000010251]  \n",
       "23      [6601000053, 6601000045, 6601000049, 700010009...  \n",
       "24                                          [10000019403]  \n",
       "25      [6601000050, 6601000091, 6601000174, 660100004...  \n",
       "26      [6601000045, 10000009978, 6601000039, 10000025...  \n",
       "27      [6601000174, 10000025060, 10000025058, 1000002...  \n",
       "28      [10000025060, 10000025058, 10000025062, 660100...  \n",
       "29      [6600201041, 6601000174, 10000025060, 10000000...  \n",
       "...                                                   ...  \n",
       "101134             [7400100001, 10000007689, 10000018592]  \n",
       "101135  [10000001253, 10000024528, 10000061721, 100000...  \n",
       "101136                         [10000000313, 10000000316]  \n",
       "101137            [10000000310, 10000000314, 10000017939]  \n",
       "101138                           [7400100023, 6600200088]  \n",
       "101139  [6600200088, 10000000317, 10000000316, 1000000...  \n",
       "101140  [10000000317, 10000018870, 10000057380, 100000...  \n",
       "101141                         [10000010274, 10000010276]  \n",
       "101142  [10000018596, 10000018870, 10000058701, 100000...  \n",
       "101143  [10000000313, 10000000310, 10000024544, 100000...  \n",
       "101144            [10000057380, 10000001518, 10000010814]  \n",
       "101145                         [10000024528, 10000000364]  \n",
       "101146  [7400100005, 7400100012, 7400900175, 100000478...  \n",
       "101147            [10000000513, 10000000582, 10000000514]  \n",
       "101148  [10000018590, 7400900175, 10000024544, 1000002...  \n",
       "101149  [10000000313, 10000024528, 10000018590, 100000...  \n",
       "101150                         [10000058701, 10000058764]  \n",
       "101151  [10000005145, 10000058505, 10000001518, 100000...  \n",
       "101152                         [10000018870, 10000057378]  \n",
       "101153  [6600201264, 6600201262, 10000018590, 66002012...  \n",
       "101154               [7400100010, 7400100016, 7400100013]  \n",
       "101155                         [10000010173, 10000010313]  \n",
       "101156                          [10000010274, 6600201039]  \n",
       "101157  [7400100010, 7400100017, 10000047805, 10000018...  \n",
       "101158             [10000024544, 7400100023, 10000024560]  \n",
       "101159               [7400900179, 7400900176, 7400900175]  \n",
       "101160                         [10000000310, 10000017939]  \n",
       "101161                           [7400100012, 7400100015]  \n",
       "101162            [10000010173, 10000057378, 10000018870]  \n",
       "101163                         [10000018592, 10000018593]  \n",
       "\n",
       "[101164 rows x 3 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(101164, 3)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2_2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_d2v: (101164, 300)\n"
     ]
    }
   ],
   "source": [
    "# # # Doc2Vec 임베딩 생성\n",
    "# x_d2v_embed = myDoc2Vec(data=df2_2[['BpID','x_ProductCodes']], d2v_size=300, trainTF=False,\n",
    "#                         model_loc='./Trained_models/Models_Doc2Vec/BpID_300_181022.model')\n",
    "# print('x_d2v:', x_d2v_embed.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x아이템은 int로 변환\n",
    "df3_1 = pd.DataFrame([list([df2_2.BpID[ii], list(map(int, df2_2.x_ProductCodes[ii]))]) for ii in df2_2.x_ProductCodes.index], \n",
    "                      columns=['BpID','x_ProductCodes'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BpID</th>\n",
       "      <th>x_ProductCodes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>304576</td>\n",
       "      <td>[6601000050, 6601000055, 6601000174, 100000080...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>304576</td>\n",
       "      <td>[6601000050, 6601000055, 6601000174, 660230002...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>304576</td>\n",
       "      <td>[6602300021, 6601000174, 6601000045, 100000102...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>304576</td>\n",
       "      <td>[6602300021, 6601000174, 6601000045, 100000102...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>304576</td>\n",
       "      <td>[6601000174, 10000010251, 10000009271, 6602300...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>304576</td>\n",
       "      <td>[6601000174, 10000010251, 10000009271, 6602300...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>304576</td>\n",
       "      <td>[10000010251, 10000009271, 10000007607, 660100...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>304576</td>\n",
       "      <td>[6601000174, 10000009978, 10000009271, 6601000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>304576</td>\n",
       "      <td>[6601000174, 6601000043, 10000010251, 66010000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>304576</td>\n",
       "      <td>[6601000174, 6601000043, 10000010251, 66010000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>304576</td>\n",
       "      <td>[6601000174, 6601000043, 10000010251, 66010000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>304576</td>\n",
       "      <td>[10000018688, 6601000045, 10000010251, 1000001...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>304576</td>\n",
       "      <td>[10000018688, 10000018676, 6602300008, 6601000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>304576</td>\n",
       "      <td>[10000018688, 10000018676, 6602300008, 6601000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>304576</td>\n",
       "      <td>[10000018676, 6602300008, 6601000045, 66010000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>304576</td>\n",
       "      <td>[10000009978, 6600200058, 10000018684, 6601000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>304576</td>\n",
       "      <td>[10000018671, 6601000174, 6601000199, 66023000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>304576</td>\n",
       "      <td>[10000018671, 6601000174, 6601000199, 66023000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>304576</td>\n",
       "      <td>[10000018671, 6601000174, 6601000199, 66023000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>304576</td>\n",
       "      <td>[10000018611, 6601000174, 6601000045, 10000010...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>304576</td>\n",
       "      <td>[10000018611, 6601000174, 6601000045, 10000010...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>304576</td>\n",
       "      <td>[10000018611, 6601000174, 6601000045, 10000010...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>304576</td>\n",
       "      <td>[6601000174, 6601000045, 2800500414, 100000102...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>304576</td>\n",
       "      <td>[6601000174, 6601000045, 2800500414, 660100004...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>304576</td>\n",
       "      <td>[6601000174, 6601000045, 10000010251, 66010000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>304576</td>\n",
       "      <td>[6601000174, 6601000045, 10000010251, 66010000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>304576</td>\n",
       "      <td>[6601000050, 6601000091, 6601000174, 660100005...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>304576</td>\n",
       "      <td>[6601000050, 6601000091, 6601000174, 660100004...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>304576</td>\n",
       "      <td>[6601000174, 10000025067, 2800500412, 10000000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>304576</td>\n",
       "      <td>[6601000174, 10000025058, 6601000045, 10000025...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101134</th>\n",
       "      <td>GEN2040001</td>\n",
       "      <td>[10000024528, 7400100005, 10000009436, 1000001...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101135</th>\n",
       "      <td>GEN2040001</td>\n",
       "      <td>[7400100005, 10000009436, 10000018592, 7400100...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101136</th>\n",
       "      <td>GEN2040001</td>\n",
       "      <td>[10000001253, 10000018592, 10000001252, 740010...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101137</th>\n",
       "      <td>GEN2040001</td>\n",
       "      <td>[10000001253, 10000000313, 10000024528, 100000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101138</th>\n",
       "      <td>GEN2040001</td>\n",
       "      <td>[10000001253, 10000000313, 10000024528, 100000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101139</th>\n",
       "      <td>GEN2040001</td>\n",
       "      <td>[10000000313, 10000000314, 10000000310, 100000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101140</th>\n",
       "      <td>GEN2040001</td>\n",
       "      <td>[10000000314, 10000000317, 10000017939, 100000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101141</th>\n",
       "      <td>GEN2040001</td>\n",
       "      <td>[10000000317, 10000018870, 10000057380, 100000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101142</th>\n",
       "      <td>GEN2040001</td>\n",
       "      <td>[10000000317, 10000018870, 10000057380, 100000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101143</th>\n",
       "      <td>GEN2040001</td>\n",
       "      <td>[10000018596, 10000000317, 10000018870, 100000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101144</th>\n",
       "      <td>GEN2040001</td>\n",
       "      <td>[10000018596, 10000000313, 10000000310, 100000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101145</th>\n",
       "      <td>GEN2040001</td>\n",
       "      <td>[10000018596, 10000000313, 10000010814, 100000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101146</th>\n",
       "      <td>GEN2040001</td>\n",
       "      <td>[10000000313, 10000024528, 10000010814, 100000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101147</th>\n",
       "      <td>GEN2040001</td>\n",
       "      <td>[10000024528, 7400100005, 7400100012, 10000010...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101148</th>\n",
       "      <td>GEN2040001</td>\n",
       "      <td>[10000024528, 7400100005, 7400100012, 74009001...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101149</th>\n",
       "      <td>GEN2040001</td>\n",
       "      <td>[10000018590, 7400100005, 7400100012, 74009001...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101150</th>\n",
       "      <td>GEN2040001</td>\n",
       "      <td>[10000000313, 10000024528, 10000018590, 100000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101151</th>\n",
       "      <td>GEN2040001</td>\n",
       "      <td>[10000000313, 10000024528, 10000018590, 100000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101152</th>\n",
       "      <td>GEN2040001</td>\n",
       "      <td>[6600200674, 10000058701, 10000018592, 1000002...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101153</th>\n",
       "      <td>GEN2040001</td>\n",
       "      <td>[10000058701, 10000005145, 10000018870, 100000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101154</th>\n",
       "      <td>GEN2040001</td>\n",
       "      <td>[6600201264, 10000018590, 6600201262, 10000018...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101155</th>\n",
       "      <td>GEN2040001</td>\n",
       "      <td>[7400100010, 6600201264, 10000018590, 66002012...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101156</th>\n",
       "      <td>GEN2040001</td>\n",
       "      <td>[7400100010, 6600201264, 6600201262, 100000185...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101157</th>\n",
       "      <td>GEN2040001</td>\n",
       "      <td>[7400100010, 6600201039, 7400100013, 740010001...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101158</th>\n",
       "      <td>GEN2040001</td>\n",
       "      <td>[7400100010, 6600201039, 10000018870, 10000057...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101159</th>\n",
       "      <td>GEN2040001</td>\n",
       "      <td>[7400100010, 6600201039, 10000018870, 10000057...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101160</th>\n",
       "      <td>GEN2040001</td>\n",
       "      <td>[7400100010, 10000018870, 10000057380, 1000001...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101161</th>\n",
       "      <td>GEN2040001</td>\n",
       "      <td>[10000024560, 7400900175, 10000024544, 7400900...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101162</th>\n",
       "      <td>GEN2040001</td>\n",
       "      <td>[7400100012, 7400100015, 7400900175, 100000003...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101163</th>\n",
       "      <td>GEN2040001</td>\n",
       "      <td>[7400100012, 7400100015, 10000000310, 10000018...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>101164 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              BpID                                     x_ProductCodes\n",
       "0           304576  [6601000050, 6601000055, 6601000174, 100000080...\n",
       "1           304576  [6601000050, 6601000055, 6601000174, 660230002...\n",
       "2           304576  [6602300021, 6601000174, 6601000045, 100000102...\n",
       "3           304576  [6602300021, 6601000174, 6601000045, 100000102...\n",
       "4           304576  [6601000174, 10000010251, 10000009271, 6602300...\n",
       "5           304576  [6601000174, 10000010251, 10000009271, 6602300...\n",
       "6           304576  [10000010251, 10000009271, 10000007607, 660100...\n",
       "7           304576  [6601000174, 10000009978, 10000009271, 6601000...\n",
       "8           304576  [6601000174, 6601000043, 10000010251, 66010000...\n",
       "9           304576  [6601000174, 6601000043, 10000010251, 66010000...\n",
       "10          304576  [6601000174, 6601000043, 10000010251, 66010000...\n",
       "11          304576  [10000018688, 6601000045, 10000010251, 1000001...\n",
       "12          304576  [10000018688, 10000018676, 6602300008, 6601000...\n",
       "13          304576  [10000018688, 10000018676, 6602300008, 6601000...\n",
       "14          304576  [10000018676, 6602300008, 6601000045, 66010000...\n",
       "15          304576  [10000009978, 6600200058, 10000018684, 6601000...\n",
       "16          304576  [10000018671, 6601000174, 6601000199, 66023000...\n",
       "17          304576  [10000018671, 6601000174, 6601000199, 66023000...\n",
       "18          304576  [10000018671, 6601000174, 6601000199, 66023000...\n",
       "19          304576  [10000018611, 6601000174, 6601000045, 10000010...\n",
       "20          304576  [10000018611, 6601000174, 6601000045, 10000010...\n",
       "21          304576  [10000018611, 6601000174, 6601000045, 10000010...\n",
       "22          304576  [6601000174, 6601000045, 2800500414, 100000102...\n",
       "23          304576  [6601000174, 6601000045, 2800500414, 660100004...\n",
       "24          304576  [6601000174, 6601000045, 10000010251, 66010000...\n",
       "25          304576  [6601000174, 6601000045, 10000010251, 66010000...\n",
       "26          304576  [6601000050, 6601000091, 6601000174, 660100005...\n",
       "27          304576  [6601000050, 6601000091, 6601000174, 660100004...\n",
       "28          304576  [6601000174, 10000025067, 2800500412, 10000000...\n",
       "29          304576  [6601000174, 10000025058, 6601000045, 10000025...\n",
       "...            ...                                                ...\n",
       "101134  GEN2040001  [10000024528, 7400100005, 10000009436, 1000001...\n",
       "101135  GEN2040001  [7400100005, 10000009436, 10000018592, 7400100...\n",
       "101136  GEN2040001  [10000001253, 10000018592, 10000001252, 740010...\n",
       "101137  GEN2040001  [10000001253, 10000000313, 10000024528, 100000...\n",
       "101138  GEN2040001  [10000001253, 10000000313, 10000024528, 100000...\n",
       "101139  GEN2040001  [10000000313, 10000000314, 10000000310, 100000...\n",
       "101140  GEN2040001  [10000000314, 10000000317, 10000017939, 100000...\n",
       "101141  GEN2040001  [10000000317, 10000018870, 10000057380, 100000...\n",
       "101142  GEN2040001  [10000000317, 10000018870, 10000057380, 100000...\n",
       "101143  GEN2040001  [10000018596, 10000000317, 10000018870, 100000...\n",
       "101144  GEN2040001  [10000018596, 10000000313, 10000000310, 100000...\n",
       "101145  GEN2040001  [10000018596, 10000000313, 10000010814, 100000...\n",
       "101146  GEN2040001  [10000000313, 10000024528, 10000010814, 100000...\n",
       "101147  GEN2040001  [10000024528, 7400100005, 7400100012, 10000010...\n",
       "101148  GEN2040001  [10000024528, 7400100005, 7400100012, 74009001...\n",
       "101149  GEN2040001  [10000018590, 7400100005, 7400100012, 74009001...\n",
       "101150  GEN2040001  [10000000313, 10000024528, 10000018590, 100000...\n",
       "101151  GEN2040001  [10000000313, 10000024528, 10000018590, 100000...\n",
       "101152  GEN2040001  [6600200674, 10000058701, 10000018592, 1000002...\n",
       "101153  GEN2040001  [10000058701, 10000005145, 10000018870, 100000...\n",
       "101154  GEN2040001  [6600201264, 10000018590, 6600201262, 10000018...\n",
       "101155  GEN2040001  [7400100010, 6600201264, 10000018590, 66002012...\n",
       "101156  GEN2040001  [7400100010, 6600201264, 6600201262, 100000185...\n",
       "101157  GEN2040001  [7400100010, 6600201039, 7400100013, 740010001...\n",
       "101158  GEN2040001  [7400100010, 6600201039, 10000018870, 10000057...\n",
       "101159  GEN2040001  [7400100010, 6600201039, 10000018870, 10000057...\n",
       "101160  GEN2040001  [7400100010, 10000018870, 10000057380, 1000001...\n",
       "101161  GEN2040001  [10000024560, 7400900175, 10000024544, 7400900...\n",
       "101162  GEN2040001  [7400100012, 7400100015, 7400900175, 100000003...\n",
       "101163  GEN2040001  [7400100012, 7400100015, 10000000310, 10000018...\n",
       "\n",
       "[101164 rows x 2 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y아이템은 row단위로\n",
    "y_ProductCodes = []\n",
    "for ii in df2_2.y_ProductCodes.index:\n",
    "    for jj in df2_2.y_ProductCodes[ii]:\n",
    "        y_ProductCodes.append((ii, jj))\n",
    "df3_2 = pd.DataFrame(y_ProductCodes, columns=[ 'index','y_ProductCodes'] ).set_index('index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_ProductCodes</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6602300021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6601000174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6601000045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10000010251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10000009978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6601000093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6601000041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10000009271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6600200174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7400900162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6601000174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6602300001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6601000067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10000007695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6601000064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10000010251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6601000060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10000009271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10000007607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6601000001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6601000174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>10000009978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6601000067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6601000039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>10000007607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6601000060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>10000018609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>6601000174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>6601000043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>10000010251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101157</th>\n",
       "      <td>10000018870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101157</th>\n",
       "      <td>10000057380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101157</th>\n",
       "      <td>10000058436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101157</th>\n",
       "      <td>7400100013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101157</th>\n",
       "      <td>10000000308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101157</th>\n",
       "      <td>10000000382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101157</th>\n",
       "      <td>10000057388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101157</th>\n",
       "      <td>10000010166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101157</th>\n",
       "      <td>10000010160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101157</th>\n",
       "      <td>10000010162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101157</th>\n",
       "      <td>10000010312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101157</th>\n",
       "      <td>10000001518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101157</th>\n",
       "      <td>7400900176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101157</th>\n",
       "      <td>10000020381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101157</th>\n",
       "      <td>10000057378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101158</th>\n",
       "      <td>10000024544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101158</th>\n",
       "      <td>7400100023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101158</th>\n",
       "      <td>10000024560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101159</th>\n",
       "      <td>7400900179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101159</th>\n",
       "      <td>7400900176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101159</th>\n",
       "      <td>7400900175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101160</th>\n",
       "      <td>10000000310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101160</th>\n",
       "      <td>10000017939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101161</th>\n",
       "      <td>7400100012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101161</th>\n",
       "      <td>7400100015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101162</th>\n",
       "      <td>10000010173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101162</th>\n",
       "      <td>10000057378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101162</th>\n",
       "      <td>10000018870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101163</th>\n",
       "      <td>10000018592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101163</th>\n",
       "      <td>10000018593</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>424605 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       y_ProductCodes\n",
       "index                \n",
       "0          6602300021\n",
       "0          6601000174\n",
       "0          6601000045\n",
       "0         10000010251\n",
       "0         10000009978\n",
       "0          6601000093\n",
       "0          6601000041\n",
       "1         10000009271\n",
       "1          6600200174\n",
       "1          7400900162\n",
       "2          6601000174\n",
       "2          6602300001\n",
       "2          6601000067\n",
       "2         10000007695\n",
       "2          6601000064\n",
       "3         10000010251\n",
       "4          6601000060\n",
       "4         10000009271\n",
       "4         10000007607\n",
       "5          6601000001\n",
       "6          6601000174\n",
       "6         10000009978\n",
       "6          6601000067\n",
       "6          6601000039\n",
       "6         10000007607\n",
       "6          6601000060\n",
       "6         10000018609\n",
       "7          6601000174\n",
       "7          6601000043\n",
       "7         10000010251\n",
       "...               ...\n",
       "101157    10000018870\n",
       "101157    10000057380\n",
       "101157    10000058436\n",
       "101157     7400100013\n",
       "101157    10000000308\n",
       "101157    10000000382\n",
       "101157    10000057388\n",
       "101157    10000010166\n",
       "101157    10000010160\n",
       "101157    10000010162\n",
       "101157    10000010312\n",
       "101157    10000001518\n",
       "101157     7400900176\n",
       "101157    10000020381\n",
       "101157    10000057378\n",
       "101158    10000024544\n",
       "101158     7400100023\n",
       "101158    10000024560\n",
       "101159     7400900179\n",
       "101159     7400900176\n",
       "101159     7400900175\n",
       "101160    10000000310\n",
       "101160    10000017939\n",
       "101161     7400100012\n",
       "101161     7400100015\n",
       "101162    10000010173\n",
       "101162    10000057378\n",
       "101162    10000018870\n",
       "101163    10000018592\n",
       "101163    10000018593\n",
       "\n",
       "[424605 rows x 1 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(424605, 7)\n"
     ]
    }
   ],
   "source": [
    "# 모든 정보 결합\n",
    "df4 = pd.merge(\n",
    "    pd.concat([df3_1,\n",
    "#                x_d2v_embed,\n",
    "               df3_2],axis=1), \n",
    "    df2[['BpID','Region','ConstructionType','BpType','BpClass']].drop_duplicates(), \n",
    "    on='BpID', how='left')\n",
    "print(df4.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BpID</th>\n",
       "      <th>x_ProductCodes</th>\n",
       "      <th>y_ProductCodes</th>\n",
       "      <th>Region</th>\n",
       "      <th>ConstructionType</th>\n",
       "      <th>BpType</th>\n",
       "      <th>BpClass</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>304576</td>\n",
       "      <td>[6601000050, 6601000055, 6601000174, 100000080...</td>\n",
       "      <td>6602300021</td>\n",
       "      <td>12</td>\n",
       "      <td>7</td>\n",
       "      <td>161</td>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>304576</td>\n",
       "      <td>[6601000050, 6601000055, 6601000174, 100000080...</td>\n",
       "      <td>6601000174</td>\n",
       "      <td>12</td>\n",
       "      <td>7</td>\n",
       "      <td>161</td>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>304576</td>\n",
       "      <td>[6601000050, 6601000055, 6601000174, 100000080...</td>\n",
       "      <td>6601000045</td>\n",
       "      <td>12</td>\n",
       "      <td>7</td>\n",
       "      <td>161</td>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>304576</td>\n",
       "      <td>[6601000050, 6601000055, 6601000174, 100000080...</td>\n",
       "      <td>10000010251</td>\n",
       "      <td>12</td>\n",
       "      <td>7</td>\n",
       "      <td>161</td>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>304576</td>\n",
       "      <td>[6601000050, 6601000055, 6601000174, 100000080...</td>\n",
       "      <td>10000009978</td>\n",
       "      <td>12</td>\n",
       "      <td>7</td>\n",
       "      <td>161</td>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     BpID                                     x_ProductCodes y_ProductCodes  \\\n",
       "0  304576  [6601000050, 6601000055, 6601000174, 100000080...     6602300021   \n",
       "1  304576  [6601000050, 6601000055, 6601000174, 100000080...     6601000174   \n",
       "2  304576  [6601000050, 6601000055, 6601000174, 100000080...     6601000045   \n",
       "3  304576  [6601000050, 6601000055, 6601000174, 100000080...    10000010251   \n",
       "4  304576  [6601000050, 6601000055, 6601000174, 100000080...    10000009978   \n",
       "\n",
       "  Region ConstructionType BpType BpClass  \n",
       "0     12                7    161      96  \n",
       "1     12                7    161      96  \n",
       "2     12                7    161      96  \n",
       "3     12                7    161      96  \n",
       "4     12                7    161      96  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df4.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BpID</th>\n",
       "      <th>x_ProductCodes</th>\n",
       "      <th>y_ProductCodes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>304576</td>\n",
       "      <td>[6601000050, 6601000055, 6601000174, 100000080...</td>\n",
       "      <td>[6602300021, 6601000174, 6601000045, 100000102...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>304576</td>\n",
       "      <td>[6601000050, 6601000055, 6601000174, 660230002...</td>\n",
       "      <td>[10000009271, 6600200174, 7400900162]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>304576</td>\n",
       "      <td>[6602300021, 6601000174, 6601000045, 100000102...</td>\n",
       "      <td>[6601000174, 6602300001, 6601000067, 100000076...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>304576</td>\n",
       "      <td>[6602300021, 6601000174, 6601000045, 100000102...</td>\n",
       "      <td>[10000010251]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>304576</td>\n",
       "      <td>[6601000174, 10000010251, 10000009271, 6602300...</td>\n",
       "      <td>[6601000060, 10000009271, 10000007607]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     BpID                                     x_ProductCodes  \\\n",
       "0  304576  [6601000050, 6601000055, 6601000174, 100000080...   \n",
       "1  304576  [6601000050, 6601000055, 6601000174, 660230002...   \n",
       "2  304576  [6602300021, 6601000174, 6601000045, 100000102...   \n",
       "3  304576  [6602300021, 6601000174, 6601000045, 100000102...   \n",
       "4  304576  [6601000174, 10000010251, 10000009271, 6602300...   \n",
       "\n",
       "                                      y_ProductCodes  \n",
       "0  [6602300021, 6601000174, 6601000045, 100000102...  \n",
       "1              [10000009271, 6600200174, 7400900162]  \n",
       "2  [6601000174, 6602300001, 6601000067, 100000076...  \n",
       "3                                      [10000010251]  \n",
       "4             [6601000060, 10000009271, 10000007607]  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2_2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BpID</th>\n",
       "      <th>x_ProductCodes</th>\n",
       "      <th>y_ProductCodes</th>\n",
       "      <th>Region</th>\n",
       "      <th>ConstructionType</th>\n",
       "      <th>BpType</th>\n",
       "      <th>BpClass</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>304576</td>\n",
       "      <td>[6601000050, 6601000055, 6601000174, 100000080...</td>\n",
       "      <td>6602300021</td>\n",
       "      <td>12</td>\n",
       "      <td>7</td>\n",
       "      <td>161</td>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>304576</td>\n",
       "      <td>[6601000050, 6601000055, 6601000174, 100000080...</td>\n",
       "      <td>6601000174</td>\n",
       "      <td>12</td>\n",
       "      <td>7</td>\n",
       "      <td>161</td>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>304576</td>\n",
       "      <td>[6601000050, 6601000055, 6601000174, 100000080...</td>\n",
       "      <td>6601000045</td>\n",
       "      <td>12</td>\n",
       "      <td>7</td>\n",
       "      <td>161</td>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>304576</td>\n",
       "      <td>[6601000050, 6601000055, 6601000174, 100000080...</td>\n",
       "      <td>10000010251</td>\n",
       "      <td>12</td>\n",
       "      <td>7</td>\n",
       "      <td>161</td>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>304576</td>\n",
       "      <td>[6601000050, 6601000055, 6601000174, 100000080...</td>\n",
       "      <td>10000009978</td>\n",
       "      <td>12</td>\n",
       "      <td>7</td>\n",
       "      <td>161</td>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     BpID                                     x_ProductCodes y_ProductCodes  \\\n",
       "0  304576  [6601000050, 6601000055, 6601000174, 100000080...     6602300021   \n",
       "1  304576  [6601000050, 6601000055, 6601000174, 100000080...     6601000174   \n",
       "2  304576  [6601000050, 6601000055, 6601000174, 100000080...     6601000045   \n",
       "3  304576  [6601000050, 6601000055, 6601000174, 100000080...    10000010251   \n",
       "4  304576  [6601000050, 6601000055, 6601000174, 100000080...    10000009978   \n",
       "\n",
       "  Region ConstructionType BpType BpClass  \n",
       "0     12                7    161      96  \n",
       "1     12                7    161      96  \n",
       "2     12                7    161      96  \n",
       "3     12                7    161      96  \n",
       "4     12                7    161      96  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df4.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir = './Trained_models/Models_WnD/rrr/'\n",
    "\n",
    "VocaList = []\n",
    "for ii in df2_2.x_ProductCodes.index:\n",
    "    for jj in df2_2.x_ProductCodes[ii]:\n",
    "        VocaList.append(int(jj))\n",
    "VocaList = list(set(VocaList))\n",
    "\n",
    "ConstructList = list(df4.ConstructionType.unique())\n",
    "RegionList = list(df4.Region.unique())\n",
    "BpTypeList = list(df4.BpType.unique())\n",
    "BpClassList = list(df4.BpClass.unique())\n",
    "LabelList = tuple(df4.y_ProductCodes.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[10000039940,\n",
       " 2801300093,\n",
       " 10000039945,\n",
       " 2801300095,\n",
       " 10000039970,\n",
       " 10000039971,\n",
       " 10000025096,\n",
       " 10000039973,\n",
       " 10000039974,\n",
       " 10000039975,\n",
       " 10000039972,\n",
       " 10000039977,\n",
       " 10000039980,\n",
       " 2801300101,\n",
       " 10000039983,\n",
       " 10000039985,\n",
       " 10000039990,\n",
       " 10000040000,\n",
       " 2801300108,\n",
       " 10000007254,\n",
       " 10000040031,\n",
       " 10000007264,\n",
       " 10000007283,\n",
       " 10000007354,\n",
       " 10000007355,\n",
       " 10000007357,\n",
       " 10000007358,\n",
       " 10000009467,\n",
       " 10000007363,\n",
       " 10000007364,\n",
       " 10000007365,\n",
       " 10000007366,\n",
       " 10000040135,\n",
       " 10000007369,\n",
       " 10000007370,\n",
       " 10000007371,\n",
       " 10000007372,\n",
       " 10000040137,\n",
       " 10000040142,\n",
       " 10000040147,\n",
       " 10000040148,\n",
       " 10000040149,\n",
       " 10000040150,\n",
       " 10000040151,\n",
       " 10000007384,\n",
       " 10000040152,\n",
       " 10000040154,\n",
       " 10000040155,\n",
       " 10000007388,\n",
       " 10000040157,\n",
       " 10000040153,\n",
       " 10000007391,\n",
       " 10000040159,\n",
       " 10000040160,\n",
       " 10000040162,\n",
       " 10000007397,\n",
       " 10000040167,\n",
       " 10000007402,\n",
       " 2800600106,\n",
       " 10000007405,\n",
       " 10000007407,\n",
       " 10000007408,\n",
       " 10000007409,\n",
       " 10000007410,\n",
       " 10000007411,\n",
       " 10000007414,\n",
       " 10000007415,\n",
       " 2801300141,\n",
       " 10000007417,\n",
       " 10000007418,\n",
       " 10000007419,\n",
       " 10000007420,\n",
       " 2801300142,\n",
       " 2801300143,\n",
       " 10000007428,\n",
       " 10000007429,\n",
       " 10000040202,\n",
       " 10000040203,\n",
       " 10000040205,\n",
       " 10000040206,\n",
       " 2801300148,\n",
       " 10000007483,\n",
       " 10000007484,\n",
       " 10000007485,\n",
       " 10000007486,\n",
       " 10000007487,\n",
       " 10000007488,\n",
       " 10000007489,\n",
       " 10000007490,\n",
       " 10000007491,\n",
       " 10000007492,\n",
       " 10000007497,\n",
       " 10000040272,\n",
       " 10000007507,\n",
       " 10000007510,\n",
       " 10000007512,\n",
       " 10000007515,\n",
       " 10000040285,\n",
       " 2800200140,\n",
       " 10000007526,\n",
       " 10000007543,\n",
       " 10000007544,\n",
       " 10000007546,\n",
       " 10000007548,\n",
       " 10000007549,\n",
       " 10000007550,\n",
       " 10000007551,\n",
       " 10000007552,\n",
       " 10000007554,\n",
       " 10000007558,\n",
       " 10000007559,\n",
       " 10000007560,\n",
       " 10000007561,\n",
       " 10000007563,\n",
       " 10000007564,\n",
       " 10000007565,\n",
       " 10000007567,\n",
       " 10000007568,\n",
       " 10000007570,\n",
       " 10000007578,\n",
       " 10000007580,\n",
       " 10000007581,\n",
       " 10000007585,\n",
       " 10000007586,\n",
       " 10000007589,\n",
       " 10000007594,\n",
       " 10000007597,\n",
       " 10000007598,\n",
       " 10000007599,\n",
       " 10000007600,\n",
       " 10000007601,\n",
       " 10000007602,\n",
       " 10000007607,\n",
       " 10000007613,\n",
       " 10000007614,\n",
       " 10000040383,\n",
       " 10000007616,\n",
       " 10000040384,\n",
       " 10000007615,\n",
       " 10000007617,\n",
       " 10000040388,\n",
       " 10000040389,\n",
       " 10000040390,\n",
       " 10000040391,\n",
       " 10000040392,\n",
       " 10000040393,\n",
       " 10000040394,\n",
       " 10000040395,\n",
       " 10000040387,\n",
       " 10000056360,\n",
       " 10000007630,\n",
       " 10000007631,\n",
       " 10000007632,\n",
       " 10000007633,\n",
       " 10000007637,\n",
       " 10000007640,\n",
       " 10000007645,\n",
       " 10000040413,\n",
       " 10000007647,\n",
       " 10000007650,\n",
       " 10000007651,\n",
       " 10000007652,\n",
       " 10000040428,\n",
       " 10000040429,\n",
       " 10000007663,\n",
       " 10000007664,\n",
       " 10000040431,\n",
       " 10000007666,\n",
       " 10000040433,\n",
       " 10000040436,\n",
       " 10000040438,\n",
       " 10000007671,\n",
       " 10000007672,\n",
       " 10000007673,\n",
       " 10000040441,\n",
       " 10000007675,\n",
       " 10000007674,\n",
       " 10000007677,\n",
       " 10000007678,\n",
       " 10000040446,\n",
       " 2801300193,\n",
       " 10000007681,\n",
       " 10000007682,\n",
       " 10000007683,\n",
       " 10000007684,\n",
       " 10000007685,\n",
       " 10000007686,\n",
       " 10000007687,\n",
       " 10000007688,\n",
       " 10000007689,\n",
       " 10000040456,\n",
       " 2801300194,\n",
       " 10000007695,\n",
       " 10000007696,\n",
       " 2801300198,\n",
       " 10000025100,\n",
       " 10000007704,\n",
       " 10000007708,\n",
       " 10000040477,\n",
       " 10000040478,\n",
       " 10000040479,\n",
       " 10000040480,\n",
       " 10000040481,\n",
       " 10000040482,\n",
       " 10000040483,\n",
       " 10000040484,\n",
       " 10000040486,\n",
       " 10000040487,\n",
       " 10000040488,\n",
       " 10000040489,\n",
       " 10000040490,\n",
       " 10000040491,\n",
       " 10000040492,\n",
       " 10000040493,\n",
       " 10000040494,\n",
       " 10000040495,\n",
       " 2801300202,\n",
       " 10000040497,\n",
       " 10000040498,\n",
       " 2801300203,\n",
       " 10000040501,\n",
       " 10000040503,\n",
       " 2801300205,\n",
       " 10000040506,\n",
       " 10000040508,\n",
       " 10000040509,\n",
       " 10000040511,\n",
       " 10000040516,\n",
       " 2801300213,\n",
       " 10000040558,\n",
       " 10000007791,\n",
       " 10000040559,\n",
       " 10000040560,\n",
       " 10000040562,\n",
       " 10000040563,\n",
       " 10000040564,\n",
       " 10000040565,\n",
       " 10000040566,\n",
       " 10000040567,\n",
       " 10000040568,\n",
       " 10000040569,\n",
       " 10000040561,\n",
       " 10000040572,\n",
       " 10000040574,\n",
       " 10000040575,\n",
       " 2801300219,\n",
       " 10000040577,\n",
       " 10000040579,\n",
       " 10000040582,\n",
       " 2800600028,\n",
       " 10000007818,\n",
       " 10000040587,\n",
       " 10000007822,\n",
       " 10000040592,\n",
       " 10000007825,\n",
       " 10000007827,\n",
       " 10000040595,\n",
       " 10000007829,\n",
       " 10000007830,\n",
       " 2801300223,\n",
       " 10000007835,\n",
       " 10000040618,\n",
       " 10000040619,\n",
       " 10000040621,\n",
       " 10000040622,\n",
       " 10000040623,\n",
       " 10000040624,\n",
       " 10000040626,\n",
       " 2801300229,\n",
       " 10000040631,\n",
       " 10000040632,\n",
       " 10000040633,\n",
       " 2800600030,\n",
       " 10000040635,\n",
       " 10000021961,\n",
       " 10000040636,\n",
       " 10000040637,\n",
       " 10000040639,\n",
       " 2801300230,\n",
       " 10000040641,\n",
       " 10000040642,\n",
       " 10000040644,\n",
       " 10000040645,\n",
       " 10000040646,\n",
       " 10000040647,\n",
       " 10000040648,\n",
       " 10000040649,\n",
       " 10000007882,\n",
       " 10000040651,\n",
       " 10000007884,\n",
       " 10000040653,\n",
       " 10000040654,\n",
       " 10000040655,\n",
       " 10000007888,\n",
       " 2801300235,\n",
       " 10000007890,\n",
       " 10000040657,\n",
       " 10000040656,\n",
       " 10000040658,\n",
       " 2801300236,\n",
       " 10000040659,\n",
       " 10000040661,\n",
       " 10000007897,\n",
       " 2801300237,\n",
       " 10000040667,\n",
       " 10000007900,\n",
       " 10000007901,\n",
       " 10000007902,\n",
       " 10000007903,\n",
       " 10000007904,\n",
       " 10000007906,\n",
       " 10000007907,\n",
       " 10000007915,\n",
       " 2801300241,\n",
       " 2800600032,\n",
       " 10000007933,\n",
       " 2801300244,\n",
       " 10000007935,\n",
       " 10000007936,\n",
       " 10000007937,\n",
       " 10000007939,\n",
       " 10000007940,\n",
       " 2801300246,\n",
       " 10000007949,\n",
       " 10000007953,\n",
       " 10000007955,\n",
       " 10000007958,\n",
       " 10000040727,\n",
       " 10000007960,\n",
       " 10000007961,\n",
       " 10000007962,\n",
       " 10000007963,\n",
       " 10000007959,\n",
       " 10000007965,\n",
       " 10000007966,\n",
       " 10000007967,\n",
       " 10000007968,\n",
       " 10000007969,\n",
       " 10000040732,\n",
       " 10000040736,\n",
       " 10000040738,\n",
       " 10000007973,\n",
       " 10000007972,\n",
       " 10000007975,\n",
       " 10000007971,\n",
       " 10000007981,\n",
       " 10000007982,\n",
       " 10000007983,\n",
       " 10000007984,\n",
       " 10000007985,\n",
       " 10000007986,\n",
       " 10000007993,\n",
       " 2800600035,\n",
       " 10000007996,\n",
       " 10000007998,\n",
       " 10000007999,\n",
       " 10000008001,\n",
       " 10000008002,\n",
       " 10000008003,\n",
       " 10000008009,\n",
       " 10000008013,\n",
       " 10000008014,\n",
       " 10000008016,\n",
       " 10000008017,\n",
       " 10000008018,\n",
       " 10000008019,\n",
       " 10000040788,\n",
       " 10000040786,\n",
       " 10000040791,\n",
       " 10000008025,\n",
       " 10000008027,\n",
       " 10000008028,\n",
       " 10000008031,\n",
       " 10000008032,\n",
       " 10000008033,\n",
       " 10000008034,\n",
       " 10000008035,\n",
       " 10000008036,\n",
       " 10000008037,\n",
       " 10000008038,\n",
       " 10000008039,\n",
       " 10000008040,\n",
       " 10000008046,\n",
       " 10000008047,\n",
       " 10000008048,\n",
       " 10000008049,\n",
       " 10000008050,\n",
       " 10000008051,\n",
       " 10000008052,\n",
       " 10000008053,\n",
       " 10000008054,\n",
       " 10000008055,\n",
       " 10000008057,\n",
       " 10000008058,\n",
       " 10000008059,\n",
       " 10000008060,\n",
       " 10000008061,\n",
       " 10000008062,\n",
       " 10000008064,\n",
       " 10000008065,\n",
       " 10000008066,\n",
       " 10000008067,\n",
       " 10000008068,\n",
       " 10000008071,\n",
       " 10000008072,\n",
       " 10000008073,\n",
       " 10000008074,\n",
       " 10000008075,\n",
       " 10000008076,\n",
       " 10000008077,\n",
       " 10000008078,\n",
       " 10000008079,\n",
       " 10000008080,\n",
       " 10000008083,\n",
       " 10000008084,\n",
       " 10000008085,\n",
       " 10000008086,\n",
       " 10000008087,\n",
       " 10000008088,\n",
       " 10000008089,\n",
       " 10000008091,\n",
       " 10000008092,\n",
       " 10000008093,\n",
       " 10000008094,\n",
       " 10000040863,\n",
       " 10000008095,\n",
       " 10000040862,\n",
       " 10000008098,\n",
       " 10000040860,\n",
       " 10000008099,\n",
       " 10000008096,\n",
       " 10000040864,\n",
       " 10000008103,\n",
       " 10000040872,\n",
       " 10000040868,\n",
       " 10000040874,\n",
       " 10000040875,\n",
       " 10000008108,\n",
       " 10000040877,\n",
       " 10000040878,\n",
       " 10000040879,\n",
       " 10000040876,\n",
       " 10000040880,\n",
       " 10000040882,\n",
       " 10000040881,\n",
       " 10000040884,\n",
       " 10000040885,\n",
       " 10000040886,\n",
       " 10000008119,\n",
       " 10000040887,\n",
       " 10000040889,\n",
       " 10000040883,\n",
       " 10000040890,\n",
       " 10000040893,\n",
       " 10000040894,\n",
       " 10000040895,\n",
       " 10000040896,\n",
       " 10000008129,\n",
       " 10000040898,\n",
       " 10000040897,\n",
       " 10000008128,\n",
       " 10000008127,\n",
       " 10000040902,\n",
       " 10000040903,\n",
       " 10000040904,\n",
       " 10000040905,\n",
       " 10000040906,\n",
       " 10000040907,\n",
       " 10000040908,\n",
       " 10000040909,\n",
       " 10000040910,\n",
       " 10000040911,\n",
       " 10000040912,\n",
       " 10000040913,\n",
       " 10000040914,\n",
       " 2800600041,\n",
       " 10000008147,\n",
       " 10000040917,\n",
       " 10000040918,\n",
       " 10000008150,\n",
       " 10000008148,\n",
       " 10000040921,\n",
       " 10000040922,\n",
       " 10000040923,\n",
       " 10000040924,\n",
       " 10000040925,\n",
       " 10000040926,\n",
       " 10000040927,\n",
       " 10000040928,\n",
       " 10000040929,\n",
       " 10000008158,\n",
       " 10000040931,\n",
       " 10000040932,\n",
       " 10000040933,\n",
       " 10000040934,\n",
       " 10000040935,\n",
       " 10000040936,\n",
       " 10000040937,\n",
       " 10000040938,\n",
       " 10000008171,\n",
       " 2800600042,\n",
       " 10000008173,\n",
       " 10000040939,\n",
       " 10000008170,\n",
       " 10000008176,\n",
       " 10000008177,\n",
       " 10000008178,\n",
       " 10000040943,\n",
       " 10000008175,\n",
       " 10000040940,\n",
       " 10000008182,\n",
       " 10000040951,\n",
       " 10000008184,\n",
       " 10000008185,\n",
       " 10000040952,\n",
       " 10000008187,\n",
       " 10000040956,\n",
       " 10000040957,\n",
       " 10000008189,\n",
       " 10000008191,\n",
       " 10000040960,\n",
       " 10000008193,\n",
       " 10000040962,\n",
       " 10000008194,\n",
       " 10000008195,\n",
       " 10000040965,\n",
       " 10000008198,\n",
       " 10000008196,\n",
       " 10000008200,\n",
       " 10000008201,\n",
       " 10000008202,\n",
       " 10000008197,\n",
       " 10000008204,\n",
       " 10000008205,\n",
       " 10000025104,\n",
       " 10000040975,\n",
       " 10000008207,\n",
       " 10000008203,\n",
       " 10000008211,\n",
       " 10000008212,\n",
       " 10000008215,\n",
       " 10000008216,\n",
       " 10000008218,\n",
       " 10000008219,\n",
       " 10000008221,\n",
       " 2800600044,\n",
       " 10000008223,\n",
       " 10000008224,\n",
       " 10000008225,\n",
       " 10000008226,\n",
       " 10000008227,\n",
       " 10000008229,\n",
       " 10000008230,\n",
       " 10000008231,\n",
       " 10000008232,\n",
       " 10000008236,\n",
       " 10000008237,\n",
       " 10000008239,\n",
       " 10000008240,\n",
       " 10000008241,\n",
       " 10000008242,\n",
       " 10000008243,\n",
       " 10000008244,\n",
       " 10000008245,\n",
       " 10000008246,\n",
       " 10000008247,\n",
       " 2800600045,\n",
       " 10000008250,\n",
       " 10000008251,\n",
       " 10000008252,\n",
       " 10000008254,\n",
       " 10000008256,\n",
       " 10000041026,\n",
       " 10000041027,\n",
       " 10000041028,\n",
       " 10000041029,\n",
       " 10000041034,\n",
       " 10000041035,\n",
       " 10000041037,\n",
       " 10000041038,\n",
       " 10000041039,\n",
       " 10000041040,\n",
       " 10000041041,\n",
       " 10000041042,\n",
       " 10000041043,\n",
       " 10000041044,\n",
       " 2800600046,\n",
       " 10000041048,\n",
       " 10000041049,\n",
       " 10000041050,\n",
       " 10000041052,\n",
       " 10000041053,\n",
       " 10000041054,\n",
       " 10000041056,\n",
       " 10000041057,\n",
       " 10000041058,\n",
       " 10000041059,\n",
       " 10000041060,\n",
       " 10000041061,\n",
       " 10000041062,\n",
       " 10000041063,\n",
       " 10000041064,\n",
       " 10000041065,\n",
       " 10000041066,\n",
       " 10000041067,\n",
       " 10000041068,\n",
       " 10000041069,\n",
       " 10000041070,\n",
       " 10000041071,\n",
       " 10000041072,\n",
       " 10000041073,\n",
       " 10000041075,\n",
       " 10000041076,\n",
       " 10000041077,\n",
       " 10000041079,\n",
       " 10000041080,\n",
       " 10000041081,\n",
       " 10000041082,\n",
       " 10000041084,\n",
       " 10000041085,\n",
       " 10000041086,\n",
       " 10000041087,\n",
       " 10000041088,\n",
       " 10000041089,\n",
       " 10000041092,\n",
       " 10000041093,\n",
       " 10000041094,\n",
       " 10000041095,\n",
       " 10000041096,\n",
       " 10000025105,\n",
       " 10000041098,\n",
       " 10000041099,\n",
       " 10000041100,\n",
       " 10000041101,\n",
       " 10000041103,\n",
       " 10000041104,\n",
       " 10000041105,\n",
       " 10000041106,\n",
       " 10000041110,\n",
       " 10000041111,\n",
       " 10000041112,\n",
       " 10000041113,\n",
       " 10000041114,\n",
       " 10000041116,\n",
       " 10000041117,\n",
       " 10000041119,\n",
       " 10000041120,\n",
       " 10000041121,\n",
       " 10000041126,\n",
       " 10000041127,\n",
       " 10000041130,\n",
       " 10000041131,\n",
       " 10000041132,\n",
       " 10000041133,\n",
       " 10000041134,\n",
       " 10000041135,\n",
       " 10000041136,\n",
       " 10000041138,\n",
       " 10000041139,\n",
       " 10000041140,\n",
       " 10000041141,\n",
       " 10000041142,\n",
       " 10000041143,\n",
       " 10000041144,\n",
       " 10000041145,\n",
       " 10000041146,\n",
       " 10000041147,\n",
       " 10000041148,\n",
       " 10000041149,\n",
       " 10000041151,\n",
       " 10000041152,\n",
       " 10000041154,\n",
       " 10000041155,\n",
       " 10000041156,\n",
       " 10000041157,\n",
       " 10000041159,\n",
       " 10000041160,\n",
       " 10000041161,\n",
       " 10000041162,\n",
       " 10000041163,\n",
       " 2800600051,\n",
       " 10000041165,\n",
       " 10000041166,\n",
       " 1201800399,\n",
       " 10000041168,\n",
       " 10000041164,\n",
       " 10000041170,\n",
       " 10000041171,\n",
       " 10000041172,\n",
       " 10000041173,\n",
       " 10000041175,\n",
       " 10000041176,\n",
       " 10000041177,\n",
       " 10000041178,\n",
       " 10000041179,\n",
       " 10000041180,\n",
       " 10000041181,\n",
       " 10000041182,\n",
       " 10000041183,\n",
       " 1201800431,\n",
       " 10000025106,\n",
       " 6600200018,\n",
       " 6600200028,\n",
       " 10000041304,\n",
       " 10000041305,\n",
       " 10000041306,\n",
       " 10000041307,\n",
       " 10000041308,\n",
       " 10000041309,\n",
       " 10000041310,\n",
       " 10000041311,\n",
       " 10000041312,\n",
       " 10000041313,\n",
       " 10000041315,\n",
       " 10000041316,\n",
       " 10000041318,\n",
       " 10000041323,\n",
       " 10000041328,\n",
       " 10000041333,\n",
       " 10000041338,\n",
       " 10000041343,\n",
       " 10000041360,\n",
       " 10000041364,\n",
       " 10000041365,\n",
       " 10000041366,\n",
       " 10000041367,\n",
       " 10000041368,\n",
       " 10000041369,\n",
       " 10000041370,\n",
       " 10000041371,\n",
       " 10000041372,\n",
       " 10000041373,\n",
       " 10000041374,\n",
       " 10000041375,\n",
       " 10000041376,\n",
       " 10000041378,\n",
       " 6600200046,\n",
       " 10000041380,\n",
       " 10000041383,\n",
       " 6600200047,\n",
       " 10000041386,\n",
       " 10000041388,\n",
       " 10000017941,\n",
       " 10000041393,\n",
       " 10000041398,\n",
       " 10000041403,\n",
       " 2800600061,\n",
       " 10000017942,\n",
       " 10000041420,\n",
       " 9900000738,\n",
       " 10000057019,\n",
       " 10000041505,\n",
       " 10000041506,\n",
       " 10000041507,\n",
       " 10000041508,\n",
       " 10000041509,\n",
       " 10000041510,\n",
       " 10000041512,\n",
       " 10000041514,\n",
       " 10000041516,\n",
       " 10000041517,\n",
       " 10000041519,\n",
       " 2800200189,\n",
       " 10000041521,\n",
       " 10000041522,\n",
       " 10000041523,\n",
       " 10000041524,\n",
       " 10000041525,\n",
       " 10000041527,\n",
       " 10000041529,\n",
       " 10000041530,\n",
       " 10000041531,\n",
       " 10000041533,\n",
       " 10000041535,\n",
       " 10000041536,\n",
       " 10000041537,\n",
       " 10000041539,\n",
       " 10000041540,\n",
       " 10000041541,\n",
       " 10000041542,\n",
       " 10000041543,\n",
       " 10000041544,\n",
       " 10000041546,\n",
       " 10000041547,\n",
       " 10000041548,\n",
       " 10000041549,\n",
       " 10000041550,\n",
       " 10000041551,\n",
       " 10000041552,\n",
       " 10000024461,\n",
       " 10000041582,\n",
       " 10000041585,\n",
       " 10000041606,\n",
       " 10000041607,\n",
       " 10000041609,\n",
       " 10000041661,\n",
       " 10000041663,\n",
       " 10000041664,\n",
       " 10000041665,\n",
       " 10000041666,\n",
       " 10000041667,\n",
       " 10000041668,\n",
       " 10000041669,\n",
       " 10000041670,\n",
       " 10000041671,\n",
       " 10000041672,\n",
       " 10000041673,\n",
       " 10000041674,\n",
       " 10000041675,\n",
       " 10000041676,\n",
       " 10000041677,\n",
       " 10000041679,\n",
       " 10000041680,\n",
       " 10000041681,\n",
       " 10000041709,\n",
       " 10000041717,\n",
       " 10000041718,\n",
       " 10000041719,\n",
       " 10000041720,\n",
       " 10000041721,\n",
       " 10000041722,\n",
       " 10000041723,\n",
       " 10000041724,\n",
       " 10000041725,\n",
       " 10000041727,\n",
       " 10000041728,\n",
       " 10000041729,\n",
       " 10000041730,\n",
       " 10000041731,\n",
       " 10000041732,\n",
       " 10000041733,\n",
       " 10000041734,\n",
       " 10000041735,\n",
       " 10000041736,\n",
       " 10000041737,\n",
       " 10000041739,\n",
       " 10000010140,\n",
       " 10000041750,\n",
       " 10000041751,\n",
       " 10000041752,\n",
       " 2800200198,\n",
       " 10000041754,\n",
       " 10000041755,\n",
       " 10000041756,\n",
       " 10000041757,\n",
       " 10000041758,\n",
       " 10000041753,\n",
       " 10000041763,\n",
       " 10000041765,\n",
       " 10000041767,\n",
       " 10000010141,\n",
       " 10000041770,\n",
       " 6600200124,\n",
       " 10000041841,\n",
       " 10000041843,\n",
       " 10000041844,\n",
       " 10000041845,\n",
       " 10000041846,\n",
       " 10000041848,\n",
       " 10000041850,\n",
       " 10000041851,\n",
       " 10000041852,\n",
       " 10000041853,\n",
       " 10000041854,\n",
       " 10000041855,\n",
       " 10000041856,\n",
       " 10000041858,\n",
       " 10000041859,\n",
       " 10000041860,\n",
       " 10000041861,\n",
       " 10000041862,\n",
       " 10000041864,\n",
       " 10000041865,\n",
       " 10000041866,\n",
       " 10000041867,\n",
       " 10000041868,\n",
       " 10000041869,\n",
       " 10000041870,\n",
       " 10000041872,\n",
       " 10000041873,\n",
       " 10000041874,\n",
       " 10000041875,\n",
       " 10000041876,\n",
       " 10000041877,\n",
       " 10000041878,\n",
       " 10000041879,\n",
       " 10000041892,\n",
       " 10000041893,\n",
       " 10000041896,\n",
       " 10000041897,\n",
       " 10000041899,\n",
       " 10000041911,\n",
       " 10000041913,\n",
       " 10000041920,\n",
       " 10000041921,\n",
       " 10000041924,\n",
       " 2800200205,\n",
       " 10000041926,\n",
       " 10000041927,\n",
       " 10000041928,\n",
       " 10000041929,\n",
       " 10000041925,\n",
       " 10000041931,\n",
       " 10000041935,\n",
       " 10000041936,\n",
       " 10000041938,\n",
       " 10000041940,\n",
       " 10000041943,\n",
       " 10000041944,\n",
       " 2800600082,\n",
       " 10000041954,\n",
       " 10000041956,\n",
       " 10000041959,\n",
       " 10000024477,\n",
       " 6600200165,\n",
       " 10000009217,\n",
       " 10000009219,\n",
       " 10000009221,\n",
       " 10000009222,\n",
       " 10000009223,\n",
       " 10000009224,\n",
       " 10000009225,\n",
       " 10000009226,\n",
       " 10000009227,\n",
       " 10000009228,\n",
       " 10000009229,\n",
       " 10000009236,\n",
       " 10000009238,\n",
       " 10000009239,\n",
       " 10000009240,\n",
       " 10000009241,\n",
       " 10000009242,\n",
       " 10000009243,\n",
       " 10000009244,\n",
       " 10000042017,\n",
       " 10000042018,\n",
       " 10000009251,\n",
       " 10000009249,\n",
       " 10000009253,\n",
       " 10000009250,\n",
       " 2800600085,\n",
       " 10000042024,\n",
       " 10000009256,\n",
       " 10000042025,\n",
       " 10000009258,\n",
       " 10000042028,\n",
       " 10000009261,\n",
       " 10000009262,\n",
       " 10000009263,\n",
       " 10000009264,\n",
       " 10000042032,\n",
       " 10000042036,\n",
       " 10000009269,\n",
       " 10000042037,\n",
       " 10000009271,\n",
       " 10000009272,\n",
       " 10000009273,\n",
       " 10000009270,\n",
       " 10000042045,\n",
       " 2800600086,\n",
       " 10000042047,\n",
       " 2800600121,\n",
       " 10000009280,\n",
       " 10000009282,\n",
       " 10000042051,\n",
       " 10000009284,\n",
       " 10000042050,\n",
       " 10000042053,\n",
       " 10000042055,\n",
       " 10000042056,\n",
       " 10000042052,\n",
       " 10000042058,\n",
       " 10000042059,\n",
       " 10000009290,\n",
       " 10000009293,\n",
       " 10000009294,\n",
       " 10000042063,\n",
       " 10000009296,\n",
       " 10000042064,\n",
       " 10000042066,\n",
       " 10000009299,\n",
       " 10000042068,\n",
       " 10000042069,\n",
       " 10000042070,\n",
       " 10000042071,\n",
       " 10000042072,\n",
       " 10000009301,\n",
       " 10000042067,\n",
       " 10000009303,\n",
       " 10000042076,\n",
       " 10000042077,\n",
       " 10000042073,\n",
       " 10000042079,\n",
       " 10000009312,\n",
       " 10000009313,\n",
       " 10000042075,\n",
       " 10000042074,\n",
       " 10000009311,\n",
       " 10000009317,\n",
       " 10000042084,\n",
       " ...]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "VocaList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_Example(row):\n",
    "    example= tf.train.Example(features=tf.train.Features(feature={\n",
    "#         'BpID': tf.train.Feature(bytes_list=tf.train.BytesList(value=[row['BpID'].encode('utf-8')])),\n",
    "        'Region': tf.train.Feature(bytes_list=tf.train.BytesList(value=[row['Region'].encode('utf-8')])),\n",
    "        'BpType': tf.train.Feature(bytes_list=tf.train.BytesList(value=[row['BpType'].encode('utf-8')])),\n",
    "        'BpClass': tf.train.Feature(bytes_list=tf.train.BytesList(value=[row['BpClass'].encode('utf-8')])),\n",
    "        'ConstructionType': tf.train.Feature(bytes_list=tf.train.BytesList(value=[row['ConstructionType'].encode('utf-8')])),\n",
    "        'x_ProductCodes': tf.train.Feature(int64_list=tf.train.Int64List(value= row['x_ProductCodes'])),\n",
    "        'y_ProductCodes': tf.train.Feature(bytes_list=tf.train.BytesList(value=[row['y_ProductCodes'].encode('utf-8')]))\n",
    "    }))\n",
    "    return example\n",
    "\n",
    "def create_tfrecords_file(tf_filename= 'data.tfrecord', input_df=None):\n",
    "    writer = tf.python_io.TFRecordWriter(tf_filename)\n",
    "    print(\"Creating TFRecords file at\", tf_filename, \"...\")\n",
    "    def mk_tfrecords(row):\n",
    "        example = make_Example(row)\n",
    "        content = example.SerializeToString()\n",
    "        writer.write(content)\n",
    "        return example\n",
    "    input_df.apply(mk_tfrecords, axis=1)\n",
    "    writer.close()\n",
    "    print(\"Finish Writing\", tf_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_df = df4.drop(['BpID'],axis=1)\n",
    "\n",
    "input_train, input_test = train_test_split(input_df.values, test_size=0.2)\n",
    "\n",
    "create_tfrecords_file('./Datasets/train.tfrecord', pd.DataFrame(input_train, columns=input_df.columns))\n",
    "create_tfrecords_file('./Datasets/eval.tfrecord', pd.DataFrame(input_test, columns=input_df.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR! Session/line number was not unique in database. History logging moved to new session 687\n"
     ]
    }
   ],
   "source": [
    "# Parsing features\n",
    "read_features = {\n",
    "#         'BpID': tf.FixedLenFeature([], dtype=tf.string),\n",
    "        'Region': tf.FixedLenFeature([], dtype=tf.string),\n",
    "        'BpType': tf.FixedLenFeature([], dtype=tf.string),\n",
    "        'BpClass': tf.FixedLenFeature([], dtype=tf.string),\n",
    "        'ConstructionType': tf.FixedLenFeature([], dtype=tf.string),\n",
    "        'x_ProductCodes': tf.VarLenFeature(dtype=tf.int64),\n",
    "        'y_ProductCodes': tf.FixedLenFeature([], dtype=tf.string)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def input_fn(filename):\n",
    "    def parser(serialized_example):\n",
    "        columns = tf.parse_single_example(\n",
    "            serialized=serialized_example, \n",
    "            features=read_features)\n",
    "        label = columns['y_ProductCodes']\n",
    "        del columns['y_ProductCodes']\n",
    "        features = columns\n",
    "        return features, label\n",
    "    \n",
    "    dataset= tf.data.TFRecordDataset(filenames=filename)\n",
    "    dataset = dataset.apply(tf.contrib.data.shuffle_and_repeat(buffer_size = 100, count = int(5e5)))\n",
    "\n",
    "    dataset = dataset.apply(tf.contrib.data.map_and_batch(\n",
    "            map_func=parser, batch_size=64, num_parallel_calls = 16))\n",
    "\n",
    "    dataset = dataset.cache()\n",
    "    dataset = dataset.prefetch(buffer_size = 50)\n",
    "    iterator = dataset.make_one_shot_iterator()\n",
    "    batch_features, batch_labels = iterator.get_next()\n",
    "    return batch_features, batch_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_input_fn():\n",
    "    return input_fn(filename='./Datasets/train.tfrecord')\n",
    "\n",
    "def eval_input_fn():\n",
    "    return input_fn(filename='./Datasets/eval.tfrecord')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aj901\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\tf_inspect.py:75: DeprecationWarning: inspect.getargspec() is deprecated, use inspect.signature() or inspect.getfullargspec()\n",
      "  return _inspect.getargspec(target)\n",
      "C:\\Users\\aj901\\Anaconda3\\lib\\importlib\\_bootstrap.py:219: ImportWarning: can't resolve package from __spec__ or __package__, falling back on __name__ and __path__\n",
      "  return f(*args, **kwds)\n",
      "C:\\Users\\aj901\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\tf_inspect.py:75: DeprecationWarning: inspect.getargspec() is deprecated, use inspect.signature() or inspect.getfullargspec()\n",
      "  return _inspect.getargspec(target)\n"
     ]
    }
   ],
   "source": [
    "BpClass=tf.contrib.layers.sparse_column_with_hash_bucket(\"BpClass\", hash_bucket_size=300)\n",
    "BpType=tf.contrib.layers.sparse_column_with_hash_bucket(\"BpType\", hash_bucket_size=300)\n",
    "ConstructionType=tf.contrib.layers.sparse_column_with_hash_bucket(\"ConstructionType\", hash_bucket_size=100)\n",
    "Region=tf.contrib.layers.sparse_column_with_hash_bucket(\"Region\", hash_bucket_size=100)\n",
    "X_item = tf.feature_column.categorical_column_with_vocabulary_list(\"x_ProductCodes\",vocabulary_list=VocaList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The default stddev value of initializer was changed from \"1/sqrt(vocab_size)\" to \"1/sqrt(dimension)\" in core implementation (tf.feature_column.embedding_column).\n",
      "WARNING:tensorflow:The default stddev value of initializer was changed from \"1/sqrt(vocab_size)\" to \"1/sqrt(dimension)\" in core implementation (tf.feature_column.embedding_column).\n",
      "WARNING:tensorflow:The default stddev value of initializer was changed from \"1/sqrt(vocab_size)\" to \"1/sqrt(dimension)\" in core implementation (tf.feature_column.embedding_column).\n",
      "WARNING:tensorflow:The default stddev value of initializer was changed from \"1/sqrt(vocab_size)\" to \"1/sqrt(dimension)\" in core implementation (tf.feature_column.embedding_column).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aj901\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\platform\\tf_logging.py:120: DeprecationWarning: The 'warn' method is deprecated, use 'warning' instead\n",
      "  _get_logger().warn(msg, *args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "wide_columns = [\n",
    "    X_item,\n",
    "    ConstructionType,\n",
    "#     tf.feature_column.crossed_column([X_item, X_item], hash_bucket_size=int(1e7)),\n",
    "    tf.contrib.layers.crossed_column([ConstructionType, Region], hash_bucket_size=int(1e3)),\n",
    "    tf.contrib.layers.crossed_column([BpClass, BpType], hash_bucket_size=int(1e5))\n",
    "]\n",
    "deep_columns = [\n",
    "    tf.contrib.layers.embedding_column(BpClass, dimension=8), \n",
    "    tf.contrib.layers.embedding_column(BpType, dimension=8), \n",
    "    tf.contrib.layers.embedding_column(ConstructionType, dimension=8), \n",
    "    tf.contrib.layers.embedding_column(Region, dimension=8)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-49-cca55ae0f206>:9: RunConfig.__init__ (from tensorflow.contrib.learn.python.learn.estimators.run_config) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "When switching to tf.estimator.Estimator, use tf.estimator.RunConfig instead.\n",
      "INFO:tensorflow:Using config: {'_task_type': None, '_task_id': 0, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x000002536349EF28>, '_master': '', '_num_ps_replicas': 0, '_num_worker_replicas': 0, '_environment': 'local', '_is_chief': True, '_evaluation_master': '', '_train_distribute': None, '_eval_distribute': None, '_device_fn': None, '_tf_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 1.0\n",
      "}\n",
      ", '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_secs': None, '_log_step_count_steps': 100, '_protocol': None, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_save_checkpoints_steps': 1000, '_keep_checkpoint_max': 2, '_keep_checkpoint_every_n_hours': 10000, '_model_dir': './Trained_models/Models_WnD/rrr/'}\n",
      "INFO:tensorflow:Not using Distribute Coordinator.\n",
      "INFO:tensorflow:Running training and evaluation locally (non-distributed).\n",
      "INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps 1000 or save_checkpoints_secs None.\n",
      "WARNING:tensorflow:From <ipython-input-44-4e61e6db303e>:12: shuffle_and_repeat (from tensorflow.contrib.data.python.ops.shuffle_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.experimental.shuffle_and_repeat(...)`.\n",
      "WARNING:tensorflow:From <ipython-input-44-4e61e6db303e>:15: map_and_batch (from tensorflow.contrib.data.python.ops.batching) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.experimental.map_and_batch(...)`.\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aj901\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\tf_inspect.py:75: DeprecationWarning: inspect.getargspec() is deprecated, use inspect.signature() or inspect.getfullargspec()\n",
      "  return _inspect.getargspec(target)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\aj901\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\layers\\python\\layers\\feature_column.py:2391: calling sparse_feature_cross (from tensorflow.contrib.layers.python.ops.sparse_feature_cross_op) with hash_key=None is deprecated and will be removed after 2016-11-20.\n",
      "Instructions for updating:\n",
      "The default behavior of sparse_feature_cross is changing, the default\n",
      "value for hash_key will change to SPARSE_FEATURE_CROSS_DEFAULT_HASH_KEY.\n",
      "From that point on sparse_feature_cross will always use FingerprintCat64\n",
      "to concatenate the feature fingerprints. And the underlying\n",
      "_sparse_feature_cross_op.sparse_feature_cross operation will be marked\n",
      "as deprecated.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 0 into ./Trained_models/Models_WnD/rrr/model.ckpt.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-02-12-06:19:56\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from ./Trained_models/Models_WnD/rrr/model.ckpt-0\n"
     ]
    },
    {
     "ename": "OutOfRangeError",
     "evalue": "Read fewer bytes than requested\n\t [[node save/RestoreV2_1 (defined at <ipython-input-49-cca55ae0f206>:25)  = RestoreV2[dtypes=[DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, ..., DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](_arg_save/Const_0_0, save/RestoreV2_1/tensor_names, save/RestoreV2_1/shape_and_slices)]]\n\nCaused by op 'save/RestoreV2_1', defined at:\n  File \"C:\\Users\\aj901\\Anaconda3\\lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"C:\\Users\\aj901\\Anaconda3\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"C:\\Users\\aj901\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"C:\\Users\\aj901\\Anaconda3\\lib\\site-packages\\traitlets\\config\\application.py\", line 658, in launch_instance\n    app.start()\n  File \"C:\\Users\\aj901\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 486, in start\n    self.io_loop.start()\n  File \"C:\\Users\\aj901\\Anaconda3\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 127, in start\n    self.asyncio_loop.run_forever()\n  File \"C:\\Users\\aj901\\Anaconda3\\lib\\asyncio\\base_events.py\", line 422, in run_forever\n    self._run_once()\n  File \"C:\\Users\\aj901\\Anaconda3\\lib\\asyncio\\base_events.py\", line 1432, in _run_once\n    handle._run()\n  File \"C:\\Users\\aj901\\Anaconda3\\lib\\asyncio\\events.py\", line 145, in _run\n    self._callback(*self._args)\n  File \"C:\\Users\\aj901\\Anaconda3\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 117, in _handle_events\n    handler_func(fileobj, events)\n  File \"C:\\Users\\aj901\\Anaconda3\\lib\\site-packages\\tornado\\stack_context.py\", line 276, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"C:\\Users\\aj901\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 450, in _handle_events\n    self._handle_recv()\n  File \"C:\\Users\\aj901\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 480, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"C:\\Users\\aj901\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 432, in _run_callback\n    callback(*args, **kwargs)\n  File \"C:\\Users\\aj901\\Anaconda3\\lib\\site-packages\\tornado\\stack_context.py\", line 276, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"C:\\Users\\aj901\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"C:\\Users\\aj901\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"C:\\Users\\aj901\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"C:\\Users\\aj901\\Anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"C:\\Users\\aj901\\Anaconda3\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"C:\\Users\\aj901\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2662, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"C:\\Users\\aj901\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2785, in _run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"C:\\Users\\aj901\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2909, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"C:\\Users\\aj901\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2963, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-49-cca55ae0f206>\", line 25, in <module>\n    tf.estimator.train_and_evaluate(tot_model, train_spec, eval_spec)\n  File \"C:\\Users\\aj901\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\estimator\\training.py\", line 471, in train_and_evaluate\n    return executor.run()\n  File \"C:\\Users\\aj901\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\estimator\\training.py\", line 610, in run\n    return self.run_local()\n  File \"C:\\Users\\aj901\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\estimator\\training.py\", line 711, in run_local\n    saving_listeners=saving_listeners)\n  File \"C:\\Users\\aj901\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\estimator\\estimator.py\", line 354, in train\n    loss = self._train_model(input_fn, hooks, saving_listeners)\n  File \"C:\\Users\\aj901\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\estimator\\estimator.py\", line 1207, in _train_model\n    return self._train_model_default(input_fn, hooks, saving_listeners)\n  File \"C:\\Users\\aj901\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\estimator\\estimator.py\", line 1241, in _train_model_default\n    saving_listeners)\n  File \"C:\\Users\\aj901\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\estimator\\estimator.py\", line 1471, in _train_with_estimator_spec\n    _, loss = mon_sess.run([estimator_spec.train_op, estimator_spec.loss])\n  File \"C:\\Users\\aj901\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\monitored_session.py\", line 783, in __exit__\n    self._close_internal(exception_type)\n  File \"C:\\Users\\aj901\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\monitored_session.py\", line 816, in _close_internal\n    h.end(self._coordinated_creator.tf_sess)\n  File \"C:\\Users\\aj901\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\basic_session_run_hooks.py\", line 590, in end\n    l.end(session, last_step)\n  File \"C:\\Users\\aj901\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\estimator\\training.py\", line 531, in end\n    self._evaluate(global_step_value)\n  File \"C:\\Users\\aj901\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\estimator\\training.py\", line 537, in _evaluate\n    self._evaluator.evaluate_and_export())\n  File \"C:\\Users\\aj901\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\estimator\\training.py\", line 912, in evaluate_and_export\n    hooks=self._eval_spec.hooks)\n  File \"C:\\Users\\aj901\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\estimator\\estimator.py\", line 478, in evaluate\n    return _evaluate()\n  File \"C:\\Users\\aj901\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\estimator\\estimator.py\", line 467, in _evaluate\n    output_dir=self.eval_dir(name))\n  File \"C:\\Users\\aj901\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\estimator\\estimator.py\", line 1591, in _evaluate_run\n    config=self._session_config)\n  File \"C:\\Users\\aj901\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\evaluation.py\", line 271, in _evaluate_once\n    session_creator=session_creator, hooks=hooks) as session:\n  File \"C:\\Users\\aj901\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\monitored_session.py\", line 921, in __init__\n    stop_grace_period_secs=stop_grace_period_secs)\n  File \"C:\\Users\\aj901\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\monitored_session.py\", line 643, in __init__\n    self._sess = _RecoverableSession(self._coordinated_creator)\n  File \"C:\\Users\\aj901\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\monitored_session.py\", line 1107, in __init__\n    _WrappedSession.__init__(self, self._create_session())\n  File \"C:\\Users\\aj901\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\monitored_session.py\", line 1112, in _create_session\n    return self._sess_creator.create_session()\n  File \"C:\\Users\\aj901\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\monitored_session.py\", line 800, in create_session\n    self.tf_sess = self._session_creator.create_session()\n  File \"C:\\Users\\aj901\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\monitored_session.py\", line 557, in create_session\n    self._scaffold.finalize()\n  File \"C:\\Users\\aj901\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\monitored_session.py\", line 213, in finalize\n    self._saver = training_saver._get_saver_or_default()  # pylint: disable=protected-access\n  File \"C:\\Users\\aj901\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 886, in _get_saver_or_default\n    saver = Saver(sharded=True, allow_empty=True)\n  File \"C:\\Users\\aj901\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 1102, in __init__\n    self.build()\n  File \"C:\\Users\\aj901\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 1114, in build\n    self._build(self._filename, build_save=True, build_restore=True)\n  File \"C:\\Users\\aj901\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 1151, in _build\n    build_save=build_save, build_restore=build_restore)\n  File \"C:\\Users\\aj901\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 789, in _build_internal\n    restore_sequentially, reshape)\n  File \"C:\\Users\\aj901\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 459, in _AddShardedRestoreOps\n    name=\"restore_shard\"))\n  File \"C:\\Users\\aj901\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 406, in _AddRestoreOps\n    restore_sequentially)\n  File \"C:\\Users\\aj901\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 862, in bulk_restore\n    return io_ops.restore_v2(filename_tensor, names, slices, dtypes)\n  File \"C:\\Users\\aj901\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\gen_io_ops.py\", line 1550, in restore_v2\n    shape_and_slices=shape_and_slices, dtypes=dtypes, name=name)\n  File \"C:\\Users\\aj901\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"C:\\Users\\aj901\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py\", line 488, in new_func\n    return func(*args, **kwargs)\n  File \"C:\\Users\\aj901\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3274, in create_op\n    op_def=op_def)\n  File \"C:\\Users\\aj901\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1770, in __init__\n    self._traceback = tf_stack.extract_stack()\n\nOutOfRangeError (see above for traceback): Read fewer bytes than requested\n\t [[node save/RestoreV2_1 (defined at <ipython-input-49-cca55ae0f206>:25)  = RestoreV2[dtypes=[DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, ..., DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](_arg_save/Const_0_0, save/RestoreV2_1/tensor_names, save/RestoreV2_1/shape_and_slices)]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOutOfRangeError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1333\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1334\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1335\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1318\u001b[0m       return self._call_tf_sessionrun(\n\u001b[1;32m-> 1319\u001b[1;33m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[0;32m   1320\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[1;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[0;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1407\u001b[1;33m         run_metadata)\n\u001b[0m\u001b[0;32m   1408\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mOutOfRangeError\u001b[0m: End of sequence\n\t [[{{node IteratorGetNext}} = IteratorGetNext[output_shapes=[[?], [?], [?], [?], <unknown>, [?]], output_types=[DT_STRING, DT_STRING, DT_STRING, DT_STRING, DT_VARIANT, DT_STRING], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](OneShotIterator)]]\n\t [[{{node dnn/input_from_feature_columns/input_layer/BpClass_embedding/DenseToSparseTensor/dense_shape/_107}} = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device_incarnation=1, tensor_name=\"edge_117_d...ense_shape\", tensor_type=DT_INT64, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"]()]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mOutOfRangeError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\estimator\\estimator.py\u001b[0m in \u001b[0;36m_train_with_estimator_spec\u001b[1;34m(self, estimator_spec, worker_hooks, hooks, global_step_tensor, saving_listeners)\u001b[0m\n\u001b[0;32m   1470\u001b[0m       \u001b[1;32mwhile\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mmon_sess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_stop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1471\u001b[1;33m         \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmon_sess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mestimator_spec\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_op\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mestimator_spec\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1472\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    670\u001b[0m                           \u001b[0moptions\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 671\u001b[1;33m                           run_metadata=run_metadata)\n\u001b[0m\u001b[0;32m    672\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1155\u001b[0m                               \u001b[0moptions\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1156\u001b[1;33m                               run_metadata=run_metadata)\n\u001b[0m\u001b[0;32m   1157\u001b[0m       \u001b[1;32mexcept\u001b[0m \u001b[0m_PREEMPTION_ERRORS\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1254\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1255\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0msix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0moriginal_exc_info\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1256\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\six.py\u001b[0m in \u001b[0;36mreraise\u001b[1;34m(tp, value, tb)\u001b[0m\n\u001b[0;32m    692\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 693\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    694\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1239\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1240\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1241\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0m_PREEMPTION_ERRORS\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1311\u001b[0m                                   \u001b[0moptions\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1312\u001b[1;33m                                   run_metadata=run_metadata)\n\u001b[0m\u001b[0;32m   1313\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1075\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1076\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1077\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 929\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    930\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1151\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1152\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1153\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1327\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[1;32m-> 1328\u001b[1;33m                            run_metadata)\n\u001b[0m\u001b[0;32m   1329\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1347\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0merror_interpolation\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minterpolate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1348\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1349\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mOutOfRangeError\u001b[0m: End of sequence\n\t [[node IteratorGetNext (defined at <ipython-input-44-4e61e6db303e>:20)  = IteratorGetNext[output_shapes=[[?], [?], [?], [?], <unknown>, [?]], output_types=[DT_STRING, DT_STRING, DT_STRING, DT_STRING, DT_VARIANT, DT_STRING], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](OneShotIterator)]]\n\t [[{{node dnn/input_from_feature_columns/input_layer/BpClass_embedding/DenseToSparseTensor/dense_shape/_107}} = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device_incarnation=1, tensor_name=\"edge_117_d...ense_shape\", tensor_type=DT_INT64, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"]()]]\n\nCaused by op 'IteratorGetNext', defined at:\n  File \"C:\\Users\\aj901\\Anaconda3\\lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"C:\\Users\\aj901\\Anaconda3\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"C:\\Users\\aj901\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"C:\\Users\\aj901\\Anaconda3\\lib\\site-packages\\traitlets\\config\\application.py\", line 658, in launch_instance\n    app.start()\n  File \"C:\\Users\\aj901\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 486, in start\n    self.io_loop.start()\n  File \"C:\\Users\\aj901\\Anaconda3\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 127, in start\n    self.asyncio_loop.run_forever()\n  File \"C:\\Users\\aj901\\Anaconda3\\lib\\asyncio\\base_events.py\", line 422, in run_forever\n    self._run_once()\n  File \"C:\\Users\\aj901\\Anaconda3\\lib\\asyncio\\base_events.py\", line 1432, in _run_once\n    handle._run()\n  File \"C:\\Users\\aj901\\Anaconda3\\lib\\asyncio\\events.py\", line 145, in _run\n    self._callback(*self._args)\n  File \"C:\\Users\\aj901\\Anaconda3\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 117, in _handle_events\n    handler_func(fileobj, events)\n  File \"C:\\Users\\aj901\\Anaconda3\\lib\\site-packages\\tornado\\stack_context.py\", line 276, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"C:\\Users\\aj901\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 450, in _handle_events\n    self._handle_recv()\n  File \"C:\\Users\\aj901\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 480, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"C:\\Users\\aj901\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 432, in _run_callback\n    callback(*args, **kwargs)\n  File \"C:\\Users\\aj901\\Anaconda3\\lib\\site-packages\\tornado\\stack_context.py\", line 276, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"C:\\Users\\aj901\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"C:\\Users\\aj901\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"C:\\Users\\aj901\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"C:\\Users\\aj901\\Anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"C:\\Users\\aj901\\Anaconda3\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"C:\\Users\\aj901\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2662, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"C:\\Users\\aj901\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2785, in _run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"C:\\Users\\aj901\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2909, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"C:\\Users\\aj901\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2963, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-49-cca55ae0f206>\", line 25, in <module>\n    tf.estimator.train_and_evaluate(tot_model, train_spec, eval_spec)\n  File \"C:\\Users\\aj901\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\estimator\\training.py\", line 471, in train_and_evaluate\n    return executor.run()\n  File \"C:\\Users\\aj901\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\estimator\\training.py\", line 610, in run\n    return self.run_local()\n  File \"C:\\Users\\aj901\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\estimator\\training.py\", line 711, in run_local\n    saving_listeners=saving_listeners)\n  File \"C:\\Users\\aj901\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\estimator\\estimator.py\", line 354, in train\n    loss = self._train_model(input_fn, hooks, saving_listeners)\n  File \"C:\\Users\\aj901\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\estimator\\estimator.py\", line 1207, in _train_model\n    return self._train_model_default(input_fn, hooks, saving_listeners)\n  File \"C:\\Users\\aj901\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\estimator\\estimator.py\", line 1234, in _train_model_default\n    input_fn, model_fn_lib.ModeKeys.TRAIN))\n  File \"C:\\Users\\aj901\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\estimator\\estimator.py\", line 1075, in _get_features_and_labels_from_input_fn\n    self._call_input_fn(input_fn, mode))\n  File \"C:\\Users\\aj901\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\estimator\\estimator.py\", line 1162, in _call_input_fn\n    return input_fn(**kwargs)\n  File \"<ipython-input-45-f1d31810b96c>\", line 2, in train_input_fn\n    return input_fn(filename='./Datasets/train.tfrecord')\n  File \"<ipython-input-44-4e61e6db303e>\", line 20, in input_fn\n    batch_features, batch_labels = iterator.get_next()\n  File \"C:\\Users\\aj901\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\data\\ops\\iterator_ops.py\", line 421, in get_next\n    name=name)), self._output_types,\n  File \"C:\\Users\\aj901\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\gen_dataset_ops.py\", line 2108, in iterator_get_next\n    output_shapes=output_shapes, name=name)\n  File \"C:\\Users\\aj901\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"C:\\Users\\aj901\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py\", line 488, in new_func\n    return func(*args, **kwargs)\n  File \"C:\\Users\\aj901\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3274, in create_op\n    op_def=op_def)\n  File \"C:\\Users\\aj901\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1770, in __init__\n    self._traceback = tf_stack.extract_stack()\n\nOutOfRangeError (see above for traceback): End of sequence\n\t [[node IteratorGetNext (defined at <ipython-input-44-4e61e6db303e>:20)  = IteratorGetNext[output_shapes=[[?], [?], [?], [?], <unknown>, [?]], output_types=[DT_STRING, DT_STRING, DT_STRING, DT_STRING, DT_VARIANT, DT_STRING], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](OneShotIterator)]]\n\t [[{{node dnn/input_from_feature_columns/input_layer/BpClass_embedding/DenseToSparseTensor/dense_shape/_107}} = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device_incarnation=1, tensor_name=\"edge_117_d...ense_shape\", tensor_type=DT_INT64, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"]()]]\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mOutOfRangeError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1333\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1334\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1335\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1318\u001b[0m       return self._call_tf_sessionrun(\n\u001b[1;32m-> 1319\u001b[1;33m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[0;32m   1320\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[1;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[0;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1407\u001b[1;33m         run_metadata)\n\u001b[0m\u001b[0;32m   1408\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mOutOfRangeError\u001b[0m: Read fewer bytes than requested\n\t [[{{node save/RestoreV2_1}} = RestoreV2[dtypes=[DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, ..., DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](_arg_save/Const_0_0, save/RestoreV2_1/tensor_names, save/RestoreV2_1/shape_and_slices)]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mOutOfRangeError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-49-cca55ae0f206>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[0mtrain_spec\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTrainSpec\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrain_input_fn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[0meval_spec\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mEvalSpec\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0meval_input_fn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_and_evaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtot_model\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_spec\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0meval_spec\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m \u001b[1;31m# tot_model.train(input_fn=train_input_fn,max_steps=100000)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\estimator\\training.py\u001b[0m in \u001b[0;36mtrain_and_evaluate\u001b[1;34m(estimator, train_spec, eval_spec)\u001b[0m\n\u001b[0;32m    469\u001b[0m         '(with task id 0).  Given task id {}'.format(config.task_id))\n\u001b[0;32m    470\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 471\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0mexecutor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    472\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    473\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\estimator\\training.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    608\u001b[0m         config.task_type != run_config_lib.TaskType.EVALUATOR):\n\u001b[0;32m    609\u001b[0m       \u001b[0mlogging\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Running training and evaluation locally (non-distributed).'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 610\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_local\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    611\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    612\u001b[0m     \u001b[1;31m# Distributed case.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\estimator\\training.py\u001b[0m in \u001b[0;36mrun_local\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    709\u001b[0m         \u001b[0mmax_steps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_train_spec\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_steps\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    710\u001b[0m         \u001b[0mhooks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrain_hooks\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 711\u001b[1;33m         saving_listeners=saving_listeners)\n\u001b[0m\u001b[0;32m    712\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    713\u001b[0m     eval_result = listener_for_eval.eval_result or _EvalResult(\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\estimator\\estimator.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, input_fn, hooks, steps, max_steps, saving_listeners)\u001b[0m\n\u001b[0;32m    352\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    353\u001b[0m       \u001b[0msaving_listeners\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_check_listeners_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msaving_listeners\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 354\u001b[1;33m       \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_train_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    355\u001b[0m       \u001b[0mlogging\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Loss for final step: %s.'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    356\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\estimator\\estimator.py\u001b[0m in \u001b[0;36m_train_model\u001b[1;34m(self, input_fn, hooks, saving_listeners)\u001b[0m\n\u001b[0;32m   1205\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_train_model_distributed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1206\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1207\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_train_model_default\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1208\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1209\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_train_model_default\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\estimator\\estimator.py\u001b[0m in \u001b[0;36m_train_model_default\u001b[1;34m(self, input_fn, hooks, saving_listeners)\u001b[0m\n\u001b[0;32m   1239\u001b[0m       return self._train_with_estimator_spec(estimator_spec, worker_hooks,\n\u001b[0;32m   1240\u001b[0m                                              \u001b[0mhooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mglobal_step_tensor\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1241\u001b[1;33m                                              saving_listeners)\n\u001b[0m\u001b[0;32m   1242\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1243\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_train_model_distributed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\estimator\\estimator.py\u001b[0m in \u001b[0;36m_train_with_estimator_spec\u001b[1;34m(self, estimator_spec, worker_hooks, hooks, global_step_tensor, saving_listeners)\u001b[0m\n\u001b[0;32m   1469\u001b[0m       \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1470\u001b[0m       \u001b[1;32mwhile\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mmon_sess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_stop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1471\u001b[1;33m         \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmon_sess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mestimator_spec\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_op\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mestimator_spec\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1472\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1473\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\monitored_session.py\u001b[0m in \u001b[0;36m__exit__\u001b[1;34m(self, exception_type, exception_value, traceback)\u001b[0m\n\u001b[0;32m    781\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mexception_type\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    782\u001b[0m       \u001b[0mexception_type\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 783\u001b[1;33m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_close_internal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexception_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    784\u001b[0m     \u001b[1;31m# __exit__ should return True to suppress an exception.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    785\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mexception_type\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\monitored_session.py\u001b[0m in \u001b[0;36m_close_internal\u001b[1;34m(self, exception_type)\u001b[0m\n\u001b[0;32m    814\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mexception_type\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    815\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mh\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_hooks\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 816\u001b[1;33m           \u001b[0mh\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_coordinated_creator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtf_sess\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    817\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    818\u001b[0m       \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\basic_session_run_hooks.py\u001b[0m in \u001b[0;36mend\u001b[1;34m(self, session)\u001b[0m\n\u001b[0;32m    588\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_save\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlast_step\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    589\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_listeners\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 590\u001b[1;33m       \u001b[0ml\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlast_step\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    591\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    592\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_save\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msession\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\estimator\\training.py\u001b[0m in \u001b[0;36mend\u001b[1;34m(self, session, global_step_value)\u001b[0m\n\u001b[0;32m    529\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mglobal_step_value\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_timer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlast_triggered_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    530\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_continuous_eval_listener\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbefore_eval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 531\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_evaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mglobal_step_value\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    532\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_continuous_eval_listener\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mafter_eval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meval_result\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    533\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\estimator\\training.py\u001b[0m in \u001b[0;36m_evaluate\u001b[1;34m(self, global_step_value)\u001b[0m\n\u001b[0;32m    535\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_timer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate_last_triggered_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mglobal_step_value\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    536\u001b[0m     self.eval_result, self.export_results = (\n\u001b[1;32m--> 537\u001b[1;33m         self._evaluator.evaluate_and_export())\n\u001b[0m\u001b[0;32m    538\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meval_result\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatus\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0m_EvalStatus\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mEVALUATED\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    539\u001b[0m       \u001b[1;31m#  This is unexpected; should never happen.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\estimator\\training.py\u001b[0m in \u001b[0;36mevaluate_and_export\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    910\u001b[0m           \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_eval_spec\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    911\u001b[0m           \u001b[0mcheckpoint_path\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlatest_ckpt_path\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 912\u001b[1;33m           hooks=self._eval_spec.hooks)\n\u001b[0m\u001b[0;32m    913\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    914\u001b[0m       \u001b[1;31m# _EvalResult validates the metrics.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\estimator\\estimator.py\u001b[0m in \u001b[0;36mevaluate\u001b[1;34m(self, input_fn, steps, hooks, checkpoint_path, name)\u001b[0m\n\u001b[0;32m    476\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0m_evaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    477\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 478\u001b[1;33m           \u001b[1;32mreturn\u001b[0m \u001b[0m_evaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    479\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    480\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_convert_eval_steps_to_hooks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msteps\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\estimator\\estimator.py\u001b[0m in \u001b[0;36m_evaluate\u001b[1;34m()\u001b[0m\n\u001b[0;32m    465\u001b[0m             \u001b[0meval_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0meval_dict\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    466\u001b[0m             \u001b[0mall_hooks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mall_hooks\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 467\u001b[1;33m             output_dir=self.eval_dir(name))\n\u001b[0m\u001b[0;32m    468\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    469\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGraph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\estimator\\estimator.py\u001b[0m in \u001b[0;36m_evaluate_run\u001b[1;34m(self, checkpoint_path, scaffold, update_op, eval_dict, all_hooks, output_dir)\u001b[0m\n\u001b[0;32m   1589\u001b[0m         \u001b[0mfinal_ops\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0meval_dict\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1590\u001b[0m         \u001b[0mhooks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mall_hooks\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1591\u001b[1;33m         config=self._session_config)\n\u001b[0m\u001b[0;32m   1592\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1593\u001b[0m     \u001b[0mcurrent_global_step\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0meval_results\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGraphKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGLOBAL_STEP\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\evaluation.py\u001b[0m in \u001b[0;36m_evaluate_once\u001b[1;34m(checkpoint_path, master, scaffold, eval_ops, feed_dict, final_ops, final_ops_feed_dict, hooks, config)\u001b[0m\n\u001b[0;32m    269\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    270\u001b[0m   with monitored_session.MonitoredSession(\n\u001b[1;32m--> 271\u001b[1;33m       session_creator=session_creator, hooks=hooks) as session:\n\u001b[0m\u001b[0;32m    272\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0meval_ops\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    273\u001b[0m       \u001b[1;32mwhile\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0msession\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_stop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\monitored_session.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, session_creator, hooks, stop_grace_period_secs)\u001b[0m\n\u001b[0;32m    919\u001b[0m     super(MonitoredSession, self).__init__(\n\u001b[0;32m    920\u001b[0m         \u001b[0msession_creator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshould_recover\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 921\u001b[1;33m         stop_grace_period_secs=stop_grace_period_secs)\n\u001b[0m\u001b[0;32m    922\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    923\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\monitored_session.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, session_creator, hooks, should_recover, stop_grace_period_secs)\u001b[0m\n\u001b[0;32m    641\u001b[0m         stop_grace_period_secs=stop_grace_period_secs)\n\u001b[0;32m    642\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mshould_recover\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 643\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sess\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_RecoverableSession\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_coordinated_creator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    644\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    645\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sess\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_coordinated_creator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate_session\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\monitored_session.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, sess_creator)\u001b[0m\n\u001b[0;32m   1105\u001b[0m     \"\"\"\n\u001b[0;32m   1106\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sess_creator\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msess_creator\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1107\u001b[1;33m     \u001b[0m_WrappedSession\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_create_session\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1108\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1109\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_create_session\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\monitored_session.py\u001b[0m in \u001b[0;36m_create_session\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1110\u001b[0m     \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1111\u001b[0m       \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1112\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sess_creator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate_session\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1113\u001b[0m       \u001b[1;32mexcept\u001b[0m \u001b[0m_PREEMPTION_ERRORS\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1114\u001b[0m         logging.info('An error was raised while a session was being created. '\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\monitored_session.py\u001b[0m in \u001b[0;36mcreate_session\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    798\u001b[0m       \u001b[1;34m\"\"\"Creates a coordinated session.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    799\u001b[0m       \u001b[1;31m# Keep the tf_sess for unit testing.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 800\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtf_sess\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session_creator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate_session\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    801\u001b[0m       \u001b[1;31m# We don't want coordinator to suppress any exception.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    802\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcoord\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcoordinator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCoordinator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclean_stop_exception_types\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\monitored_session.py\u001b[0m in \u001b[0;36mcreate_session\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    564\u001b[0m         \u001b[0minit_op\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_scaffold\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minit_op\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    565\u001b[0m         \u001b[0minit_feed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_scaffold\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minit_feed_dict\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 566\u001b[1;33m         init_fn=self._scaffold.init_fn)\n\u001b[0m\u001b[0;32m    567\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    568\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\session_manager.py\u001b[0m in \u001b[0;36mprepare_session\u001b[1;34m(self, master, init_op, saver, checkpoint_dir, checkpoint_filename_with_path, wait_for_checkpoint, max_wait_secs, config, init_feed_dict, init_fn)\u001b[0m\n\u001b[0;32m    286\u001b[0m         \u001b[0mwait_for_checkpoint\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mwait_for_checkpoint\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    287\u001b[0m         \u001b[0mmax_wait_secs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_wait_secs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 288\u001b[1;33m         config=config)\n\u001b[0m\u001b[0;32m    289\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mis_loaded_from_checkpoint\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    290\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0minit_op\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0minit_fn\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_local_init_op\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\session_manager.py\u001b[0m in \u001b[0;36m_restore_checkpoint\u001b[1;34m(self, master, saver, checkpoint_dir, checkpoint_filename_with_path, wait_for_checkpoint, max_wait_secs, config)\u001b[0m\n\u001b[0;32m    200\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    201\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mcheckpoint_filename_with_path\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 202\u001b[1;33m       \u001b[0msaver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrestore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msess\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcheckpoint_filename_with_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    203\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    204\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\u001b[0m in \u001b[0;36mrestore\u001b[1;34m(self, sess, save_path)\u001b[0m\n\u001b[0;32m   1544\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1545\u001b[0m         sess.run(self.saver_def.restore_op_name,\n\u001b[1;32m-> 1546\u001b[1;33m                  {self.saver_def.filename_tensor_name: save_path})\n\u001b[0m\u001b[0;32m   1547\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mNotFoundError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1548\u001b[0m       \u001b[1;31m# There are three common conditions that might cause this error:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    927\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 929\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    930\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1150\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1151\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1152\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1153\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1154\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1326\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1327\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[1;32m-> 1328\u001b[1;33m                            run_metadata)\n\u001b[0m\u001b[0;32m   1329\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1330\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1346\u001b[0m           \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1347\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0merror_interpolation\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minterpolate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1348\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1349\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1350\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mOutOfRangeError\u001b[0m: Read fewer bytes than requested\n\t [[node save/RestoreV2_1 (defined at <ipython-input-49-cca55ae0f206>:25)  = RestoreV2[dtypes=[DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, ..., DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](_arg_save/Const_0_0, save/RestoreV2_1/tensor_names, save/RestoreV2_1/shape_and_slices)]]\n\nCaused by op 'save/RestoreV2_1', defined at:\n  File \"C:\\Users\\aj901\\Anaconda3\\lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"C:\\Users\\aj901\\Anaconda3\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"C:\\Users\\aj901\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"C:\\Users\\aj901\\Anaconda3\\lib\\site-packages\\traitlets\\config\\application.py\", line 658, in launch_instance\n    app.start()\n  File \"C:\\Users\\aj901\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 486, in start\n    self.io_loop.start()\n  File \"C:\\Users\\aj901\\Anaconda3\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 127, in start\n    self.asyncio_loop.run_forever()\n  File \"C:\\Users\\aj901\\Anaconda3\\lib\\asyncio\\base_events.py\", line 422, in run_forever\n    self._run_once()\n  File \"C:\\Users\\aj901\\Anaconda3\\lib\\asyncio\\base_events.py\", line 1432, in _run_once\n    handle._run()\n  File \"C:\\Users\\aj901\\Anaconda3\\lib\\asyncio\\events.py\", line 145, in _run\n    self._callback(*self._args)\n  File \"C:\\Users\\aj901\\Anaconda3\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 117, in _handle_events\n    handler_func(fileobj, events)\n  File \"C:\\Users\\aj901\\Anaconda3\\lib\\site-packages\\tornado\\stack_context.py\", line 276, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"C:\\Users\\aj901\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 450, in _handle_events\n    self._handle_recv()\n  File \"C:\\Users\\aj901\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 480, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"C:\\Users\\aj901\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 432, in _run_callback\n    callback(*args, **kwargs)\n  File \"C:\\Users\\aj901\\Anaconda3\\lib\\site-packages\\tornado\\stack_context.py\", line 276, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"C:\\Users\\aj901\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"C:\\Users\\aj901\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"C:\\Users\\aj901\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"C:\\Users\\aj901\\Anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"C:\\Users\\aj901\\Anaconda3\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"C:\\Users\\aj901\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2662, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"C:\\Users\\aj901\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2785, in _run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"C:\\Users\\aj901\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2909, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"C:\\Users\\aj901\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2963, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-49-cca55ae0f206>\", line 25, in <module>\n    tf.estimator.train_and_evaluate(tot_model, train_spec, eval_spec)\n  File \"C:\\Users\\aj901\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\estimator\\training.py\", line 471, in train_and_evaluate\n    return executor.run()\n  File \"C:\\Users\\aj901\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\estimator\\training.py\", line 610, in run\n    return self.run_local()\n  File \"C:\\Users\\aj901\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\estimator\\training.py\", line 711, in run_local\n    saving_listeners=saving_listeners)\n  File \"C:\\Users\\aj901\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\estimator\\estimator.py\", line 354, in train\n    loss = self._train_model(input_fn, hooks, saving_listeners)\n  File \"C:\\Users\\aj901\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\estimator\\estimator.py\", line 1207, in _train_model\n    return self._train_model_default(input_fn, hooks, saving_listeners)\n  File \"C:\\Users\\aj901\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\estimator\\estimator.py\", line 1241, in _train_model_default\n    saving_listeners)\n  File \"C:\\Users\\aj901\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\estimator\\estimator.py\", line 1471, in _train_with_estimator_spec\n    _, loss = mon_sess.run([estimator_spec.train_op, estimator_spec.loss])\n  File \"C:\\Users\\aj901\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\monitored_session.py\", line 783, in __exit__\n    self._close_internal(exception_type)\n  File \"C:\\Users\\aj901\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\monitored_session.py\", line 816, in _close_internal\n    h.end(self._coordinated_creator.tf_sess)\n  File \"C:\\Users\\aj901\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\basic_session_run_hooks.py\", line 590, in end\n    l.end(session, last_step)\n  File \"C:\\Users\\aj901\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\estimator\\training.py\", line 531, in end\n    self._evaluate(global_step_value)\n  File \"C:\\Users\\aj901\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\estimator\\training.py\", line 537, in _evaluate\n    self._evaluator.evaluate_and_export())\n  File \"C:\\Users\\aj901\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\estimator\\training.py\", line 912, in evaluate_and_export\n    hooks=self._eval_spec.hooks)\n  File \"C:\\Users\\aj901\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\estimator\\estimator.py\", line 478, in evaluate\n    return _evaluate()\n  File \"C:\\Users\\aj901\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\estimator\\estimator.py\", line 467, in _evaluate\n    output_dir=self.eval_dir(name))\n  File \"C:\\Users\\aj901\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\estimator\\estimator.py\", line 1591, in _evaluate_run\n    config=self._session_config)\n  File \"C:\\Users\\aj901\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\evaluation.py\", line 271, in _evaluate_once\n    session_creator=session_creator, hooks=hooks) as session:\n  File \"C:\\Users\\aj901\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\monitored_session.py\", line 921, in __init__\n    stop_grace_period_secs=stop_grace_period_secs)\n  File \"C:\\Users\\aj901\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\monitored_session.py\", line 643, in __init__\n    self._sess = _RecoverableSession(self._coordinated_creator)\n  File \"C:\\Users\\aj901\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\monitored_session.py\", line 1107, in __init__\n    _WrappedSession.__init__(self, self._create_session())\n  File \"C:\\Users\\aj901\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\monitored_session.py\", line 1112, in _create_session\n    return self._sess_creator.create_session()\n  File \"C:\\Users\\aj901\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\monitored_session.py\", line 800, in create_session\n    self.tf_sess = self._session_creator.create_session()\n  File \"C:\\Users\\aj901\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\monitored_session.py\", line 557, in create_session\n    self._scaffold.finalize()\n  File \"C:\\Users\\aj901\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\monitored_session.py\", line 213, in finalize\n    self._saver = training_saver._get_saver_or_default()  # pylint: disable=protected-access\n  File \"C:\\Users\\aj901\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 886, in _get_saver_or_default\n    saver = Saver(sharded=True, allow_empty=True)\n  File \"C:\\Users\\aj901\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 1102, in __init__\n    self.build()\n  File \"C:\\Users\\aj901\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 1114, in build\n    self._build(self._filename, build_save=True, build_restore=True)\n  File \"C:\\Users\\aj901\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 1151, in _build\n    build_save=build_save, build_restore=build_restore)\n  File \"C:\\Users\\aj901\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 789, in _build_internal\n    restore_sequentially, reshape)\n  File \"C:\\Users\\aj901\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 459, in _AddShardedRestoreOps\n    name=\"restore_shard\"))\n  File \"C:\\Users\\aj901\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 406, in _AddRestoreOps\n    restore_sequentially)\n  File \"C:\\Users\\aj901\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 862, in bulk_restore\n    return io_ops.restore_v2(filename_tensor, names, slices, dtypes)\n  File \"C:\\Users\\aj901\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\gen_io_ops.py\", line 1550, in restore_v2\n    shape_and_slices=shape_and_slices, dtypes=dtypes, name=name)\n  File \"C:\\Users\\aj901\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"C:\\Users\\aj901\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py\", line 488, in new_func\n    return func(*args, **kwargs)\n  File \"C:\\Users\\aj901\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3274, in create_op\n    op_def=op_def)\n  File \"C:\\Users\\aj901\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1770, in __init__\n    self._traceback = tf_stack.extract_stack()\n\nOutOfRangeError (see above for traceback): Read fewer bytes than requested\n\t [[node save/RestoreV2_1 (defined at <ipython-input-49-cca55ae0f206>:25)  = RestoreV2[dtypes=[DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, ..., DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](_arg_save/Const_0_0, save/RestoreV2_1/tensor_names, save/RestoreV2_1/shape_and_slices)]]\n"
     ]
    }
   ],
   "source": [
    "# model config setup for speed up (reference : tensorflow performance guide)\n",
    "# config = tf.ConfigProto()\n",
    "# config.intra_op_parallelism_threads = 256 # 8->16->32->64....\n",
    "# config.inter_op_parallelism_threads = 0 # 0으로 고정\n",
    "_config = tf.contrib.learn.RunConfig(\n",
    "#     session_config=config, \n",
    "    save_checkpoints_secs=None, \n",
    "    save_checkpoints_steps=1000,\n",
    "    keep_checkpoint_max=2)\n",
    "\n",
    "tot_model = tf.estimator.DNNLinearCombinedClassifier(\n",
    "    model_dir=model_dir, \n",
    "    linear_feature_columns=wide_columns, \n",
    "    dnn_feature_columns=deep_columns, \n",
    "    dnn_hidden_units= [1024, 512, 256], \n",
    "    dnn_dropout = 0.5, \n",
    "    n_classes = len(LabelList), \n",
    "    label_vocabulary=LabelList, \n",
    "    batch_norm = True,\n",
    "    config = _config)\n",
    "\n",
    "# https://www.tensorflow.org/api_docs/python/tf/estimator/train_and_evaluate\n",
    "train_spec = tf.estimator.TrainSpec(input_fn=train_input_fn)\n",
    "eval_spec = tf.estimator.EvalSpec(input_fn=eval_input_fn)\n",
    "tf.estimator.train_and_evaluate(tot_model, train_spec, eval_spec)\n",
    "# tot_model.train(input_fn=train_input_fn,max_steps=100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tot_model.evaluate(input_fn=eval_input_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # # 커스텀 평가기준\n",
    "# custom_evaluation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://www.tensorflow.org/performance/datasets_performance\n",
    "#https://www.tensorflow.org/performance/performance_guide\n",
    "#https://www.tensorflow.org/performance/performance_models\n",
    "\"\"\"\n",
    "181109 테스트로 돌려본 모델\n",
    "181108 테스트로 돌려본 모델에서...\n",
    "◆ 와이드 카테고리 컬럼 6가지 모든 조합 크로스 컬럼 추가.\n",
    "◎ \n",
    "################################################\n",
    "181108 퇴근시 돌리고 간 모델\n",
    "181107 퇴근시 돌리고 간 모델에서...\n",
    "◆ 기본적으로 10/31일 스크립트에서 가져옴. 아래는 변동사항.\n",
    "◆ 아담 옵티마이저 적용\n",
    "◆ (와이드, 크로스)사업유형, 사업클래스 포함\n",
    "◆ (딥)모든 임베딩 128차원으로 변경\n",
    "◆ 드랍아웃을 0.65로 변경.(입력은0.35)\n",
    "◎ 성공. 100분당 6분으로 단축.\n",
    "################################################\n",
    "181107 퇴근시 돌리고 간 모델\n",
    "181106 퇴근시 돌리고 간 모델에서...\n",
    "◆ (와이드,딥)배송권역 제외하기\n",
    "◆ (와이드)사업유형, 사업클래스 제외하기\n",
    "◆ (와이드, 크로스)기간 제외하기\n",
    "◆ 히든유닛 [2048,1024, 512, 256]->[500,200]\n",
    "◆ BpClass, BpType : 3 // ConstructionType, Region : 2 차원으로 Embedding_column에서 변경.\n",
    "◎ 결과는 엑셀 참고할것.\n",
    "################################################\n",
    "181106 퇴근시 돌리고 간 모델\n",
    "181106 테스트로 돌려본 모델에서, 변동없음.\n",
    "◎ 성공 15000회, 100회당 7분소요. loss:train : 확인불가.\n",
    "◎ 커스텀 평가결과 [3]:[0.05], [5]:[0.13], [10]:[0.4]개 구매함. 11/5일 기록보다 성적 저조.\n",
    "################################################\n",
    "181106 테스트로 돌려본 모델\n",
    "181105 퇴근시 돌리고 간 모델에서,\n",
    "◆ 기간을 추가. 기간은 Y일자-각각의 X일자의 제곱합. 버켓타이즈하여 와이드, 딥, 크로스에 반영.\n",
    "◆ 와이드 크로스에서 사업장유형, 클래스는 제거. 나머지는 유지\n",
    "◆ 딥유닛수 : [1024, 512, 256]->[2048,1024, 512, 256]\n",
    "◎ 성공.\n",
    "################################################\n",
    "181105 퇴근시 돌리고 간 모델.\n",
    "181102 퇴근시 돌리고 간 모델에서 수정없이 훈련 시도.\n",
    "◆ 배송권역을 개별 텐서로 따로 처리. + 딥과 크로스에 추가.\n",
    "◆ 딥유닛수 : [2000,1000,500]->[1024, 512, 256], buffer_size = 100\n",
    "◎ 성공 - 16000회, 100회당 7분소요. loss:train=5.4/eval=5.9까지 도달.\n",
    "◎ 커스텀 평가결과 [3]:[0.10], [5]:[0.23], [10]:[0.83]개 구매함.성적 매우 저조.\n",
    "################################################\n",
    "181102 퇴근시 돌리고 간 모델\n",
    "181101 퇴근시 돌리고 간 모델에서 아래 부분만 수정해서 테스트 함\n",
    "◆ 배송권역을 개별 텐서로 따로 처리. + 딥과 크로스에 추가.\n",
    "◆ 딥유닛수 : [2000,1000,500]->[1024, 512, 256], buffer_size = 100\n",
    "◎ 주말에 서버 재부팅 한다하여 실행하지 않음. \n",
    "################################################\n",
    "181101 퇴근시 돌리고 간 모델\n",
    "181031 퇴근시 돌리고 간 모델에서 아래 부분만 수정해서 테스트 함\n",
    "◆50, 200, 10 셋팅 -> 아이템 : 3375, 크로스 : 3543, 총 : 7223\n",
    "◆배송권역을 추가함(세션레벨 -> 멀티핫 처리) -> CSV파일들도 재생성.\n",
    "◆배송권역은, 와이드에만 아이템과 묶어서 추가.\n",
    "◆쓰레드 128,0->256,0, 넘패러럴 16, 딥유닛수 [500,200]->[2000,1000,500], 체크포인트맥스 5->2\n",
    "◎ 성공, 15000회, 100회당 7분 소요. loss:train=Unknown/eval=6.1까지 도달.\n",
    "◎ 커스텀 평가결과 [3]:[0.16], [5]:[0.41], [10]:[1.41]개 구매함. 11/1일 기록보다 성적 저조.\n",
    "################################################\n",
    "181031 퇴근시 돌리고 간 모델\n",
    "181031 테스트로 돌려본 모델1에서 아래 부분만 수정해서 테스트 함\n",
    "◆50, 200, 10 셋팅 -> 아이템 : 3375, 크로스 : 3543, 총 : 7223\n",
    "◆구매자 특징 4종을 와이드에 추가함\n",
    "◆구매자 특징 4종을 2종/2종끼리 묶어 크로스 컬럼으로 와이드에 추가함.\n",
    "◆쓰레드 128,0\n",
    "◎ 성공, 13000회, 100회당 7분30초 소요. loss:train=5.3/eval=6.5까지 도달. 특이사항 : 모델용량이 엄청 커짐.\n",
    "◎ 커스텀 평가결과 [3]:[0.26], [5]:[0.63], [10]:[2.16]개 구매함. \n",
    "################################################\n",
    "181031 테스트로 돌려본 모델1\n",
    "181030 퇴근시 돌리고 간 모델에서 아래 부분만 수정해서 테스트 함\n",
    "◆50, 200, 10 셋팅 -> 아이템 : 3375, 크로스 : 3543, 총 : 7223\n",
    "◆하이레벨 텐서 셋팅을 기존 튜토리얼대로 다시 재구성함.\n",
    "◆parse_csv부분도 튜토리얼에서 재검증하여 재구성함.\n",
    "◆쓰레드 64,0\n",
    "◎텐서보드 확인결과 dnn 0에서 움직이지 않음. 그러나 움직이지 않은 원인 파악 성공. 앞으로는 무시\n",
    "################################################\n",
    "181030 퇴근시 돌리고 간 모델\n",
    "181029 퇴근시 돌리고 간 모델에서 아래 부분만 수정해서 테스트 함\n",
    "50, 200, 10 셋팅 -> 아이템 : 3375, 크로스 : 3543, 총 : 7223\n",
    "D2V컬럼을 tf.string_split->SparseTensor로 변경.\n",
    "doc2vec 컬럼 모두 비활성화후 훈련시킴.\n",
    "성공, 14000회, 100회당 7분 소요. loss:train=5.9/eval=6.2까지 도달, 텐서보드 확인결과 dnn 0에서 움직이지 않음.\n",
    "################################################\n",
    "181030 테스트로 돌려본 모델2\n",
    "181029 퇴근시 돌리고 간 모델에서 아래 부분만 수정해서 테스트 함\n",
    "50, 200, 10 셋팅 -> 아이템 : 3375, 크로스 : 3543, 총 : 7223\n",
    "D2V컬럼을 tf.string_split->SparseTensor로 변경.\n",
    "카테고리 컬럼 모두 비활성화후 훈련시킴.\n",
    "성공, 12000회, 100회당 ?분 소요. 로스트 ?까지 도달, 텐서보드 확인결과 dnn 0에서 움직이지 않음\n",
    "################################################\n",
    "181030 테스트로 돌려본 모델1\n",
    "181029 퇴근시 돌리고 간 모델에서 아래 부분만 수정해서 테스트 함\n",
    "50, 200, 10 셋팅 -> 아이템 : 3375, 크로스 : 3543, 총 : 7223\n",
    "D2V컬럼을 tf.string_split->SparseTensor로 변경.\n",
    "텐서보드 확인결과 dnn 0에서 움직이지 않음\n",
    "################################################\n",
    "181029 퇴근시 돌리고 간 모델...\n",
    "181026 퇴근시 돌리고 간 모델에서 아래 부분만 수정해서 테스트 함\n",
    "50, 200, 10 셋팅 -> 아이템 : 3375, 크로스 : 3543, 총 : 7223\n",
    "D2V컬럼을 reshape하고 훈련함.\n",
    "성공, 12000회, 100회당 7분 소요. loss:train=5.5/eval=6.8까지 도달, 텐서보드 확인결과 dnn 0에서 움직이지 않음.\n",
    "################################################\n",
    "181026 퇴근시 돌리고 간 모델...**********************************************************\n",
    "181026 테스트로 돌려본 모델1을 기반으로 셋팅을 확장해서 테스트함.\n",
    "50, 200, 10 셋팅 -> 아이템 : 3375, 크로스 : 3543, 총 : 7223\n",
    "num_parallel_calls = 16, 쓰레드 32,0, 액티베이션 = elu, 히든레이어 1000추가, 옵티마이저 =아담, 러닝레이트 0.001\n",
    "성공, 56000회(금요일 6시 ~ 월요일 9시), 100회당 7분소요. 로스틑 6.1까지 도달. \n",
    "################################################\n",
    "181026 테스트로 돌려본 모델6\n",
    "181026 테스트로 돌려본 모델1을 기반으로 셋팅을 확장해서 테스트함.\n",
    "50, 200, 10 셋팅 -> 아이템 : 3375, 크로스 : 3543, 총 : 7223\n",
    "num_parallel_calls = 16, 쓰레드 32,0, 액티베이션 = elu, 선형모델 부분은 None 처리하고 DNN만 돌려본다.\n",
    "최적화 되는데?\n",
    "################################################\n",
    "181026 테스트로 돌려본 모델5\n",
    "181026 테스트로 돌려본 모델1을 기반으로 셋팅을 확장해서 테스트함.\n",
    "50, 200, 10 셋팅 -> 아이템 : 3375, 크로스 : 3543, 총 : 7223\n",
    "num_parallel_calls = 16, 쓰레드 32,0, 액티베이션 = elu\n",
    "텐서보드상에서 DNN은 계속 0인 상태임.\n",
    "################################################\n",
    "181026 테스트로 돌려본 모델4\n",
    "181026 테스트로 돌려본 모델1을 기반으로 셋팅을 확장해서 테스트함.\n",
    "50, 200, 10 셋팅 -> 아이템 : 3375, 크로스 : 3543, 총 : 7223\n",
    "100회에 430초 소요\n",
    "대충 7500~ 8000사이까지가 현재상태에서는 컬럼수 최대치인듯.\n",
    "################################################\n",
    "181026 테스트로 돌려본 모델3\n",
    "181026 테스트로 돌려본 모델1을 기반으로 셋팅을 확장해서 테스트함.\n",
    "30, 200, 10 셋팅 -> 아이템 : 4421, 크로스 : 3543, 총 : 8269\n",
    "num_parallel_calls = 16, 쓰레드 8,0\n",
    "뻑남.... \n",
    "################################################\n",
    "181026 테스트로 돌려본 모델2\n",
    "181026 테스트로 돌려본 모델1을 기반으로 셋팅을 확장해서 테스트함.\n",
    "30, 100, 10 셋팅 -> 아이템 : 4421, 크로스 : 10646, 총 : 15372\n",
    "num_parallel_calls = 16, 쓰레드 0,0\n",
    "뻑남....\n",
    "################################################\n",
    "181026 테스트로 돌려본 모델1\n",
    "아이템과 크로스 컬럼에 해당하는 tensor들을 input_fn에서 stack해 주고 2차원 매트릭스 형태로\n",
    "real-valued column -> bucketized column에 넣어줌.\n",
    "doc2vec 300차원을 1개의 high level tensor로 변형한건 유지\n",
    "100, 300, 10 셋팅 -> 아이템 : 2111, 크로스 : 1848, 총 : 4264\n",
    "num_parallel_calls = 16, 쓰레드 256, 256. -> 쓰레드 0,0\n",
    "속도가 엄청나게 빨라진다.... 특징 컬럼의 수가 증가함에 따라 속도가 증가한다는걸 깨달음.\n",
    "Cross -> TF Crosscolumn 사용 시도하였으나 feature수의 폭증으로 취소\n",
    "-> decode_csv에서 100차원을 표현하기 위해 100개의 tensor가 자동으로 만들어지기 때문에 속았다!\n",
    "-> 100차원을 표현하기위해 100개의 tensor를 만들기 보다 100차원의 1개 텐서를 만드는게 옳다.\n",
    "성공\n",
    "################################################\n",
    "181025 퇴근시 돌리고 간 모델...\n",
    "100, 300, 10 셋팅 -> 아이템 : 2111, 크로스 : 1848, 총 : 4264\n",
    "num_parallel_calls = 16, 쓰레드 256, 256.\n",
    "doc2vec 300차원을 1개의 high level tensor로 변형하여 트레이닝 함.\n",
    "6000회 훈련에 약 14시간 소요되었고 \n",
    "train-loss : 7.0 / eval-loss : 7.8\n",
    "좀더 loss값 감소의 여지는 있으나 거의 수렴.\n",
    "################################################\n",
    "181025 테스트로 돌려본 모델2\n",
    "50,100,10 셋팅 -> 아이템 : 3375, 크로스 : 10646, 총 : 14326\n",
    "num_parallel_calls = 16, 쓰레드 256, 256.\n",
    "NFO:tensorflow:Calling model_fn.\n",
    "INFO:tensorflow:Done calling model_fn.\n",
    "INFO:tensorflow:Create CheckpointSaverHook.\n",
    "INFO:tensorflow:Graph was finalized.\n",
    "INFO:tensorflow:Running local_init_op.\n",
    "INFO:tensorflow:Done running local_init_op.\n",
    "INFO:tensorflow:Saving checkpoints for 0 into ./Trained_models/Models_WnD/StartDate_181025/model.ckpt.\n",
    "INFO:tensorflow:loss = 545.25824, step = 1\n",
    "INFO:tensorflow:global_step/sec: 0.0117695\n",
    "INFO:tensorflow:loss = 10360.906, step = 101 (8496.533 sec) # 처음 100회에 2시간 반 소요..........\n",
    "이후 커널뻑남.....\n",
    "################################################\n",
    "181025 테스트로 돌려본 모델(간략버전)\n",
    "파일 불러오는 스크립트 오류. 수정완료.\n",
    "num_parallel_calls = 8, 쓰레드 128, 128.\n",
    "doc2vec 300차원을 1개의 high level tensor로 변형하여 트레이닝 함.\n",
    "테스트 성공\n",
    "################################################\n",
    "181024 퇴근시 돌리고 간 모델...\n",
    "100, 300, 10 셋팅 -> 아이템 : 2111, 크로스 : 1848, 총 : 4264\n",
    "num_parallel_calls = 8, 쓰레드 128, 128.\n",
    "doc2vec 300차원을 1개의 high level tensor로 변형하여 트레이닝 함.\n",
    "작동하지 않음. 원인은? 300차원을 1개의 high level tensor에 넣어서 텐서가 2GB 용량 제한에 걸린건가?\n",
    "22일 기준으로 원복.\n",
    "################################################\n",
    "181024 업무시간에 돌려본 모델...\n",
    "100, 300, 10 셋팅\n",
    "num_parallel_calls = 2 -> 8로 변경, 쓰레드 256, 256 적용.\n",
    "이전 모델보다 훨씬 느리다. 다른 작업들이 수행중인게 있어서 그런 것인가?\n",
    "INFO:tensorflow:Calling model_fn.\n",
    "INFO:tensorflow:Done calling model_fn.\n",
    "INFO:tensorflow:Create CheckpointSaverHook.\n",
    "INFO:tensorflow:Graph was finalized.\n",
    "INFO:tensorflow:Running local_init_op.\n",
    "INFO:tensorflow:Done running local_init_op.\n",
    "INFO:tensorflow:Saving checkpoints for 0 into ./Trained_models/Models_WnD/StartDate_181024/model.ckpt.\n",
    "INFO:tensorflow:loss = 540.76764, step = 1\n",
    "INFO:tensorflow:global_step/sec: 0.0727103\n",
    "INFO:tensorflow:loss = 1890.2057, step = 101 (1375.334 sec)\n",
    "INFO:tensorflow:global_step/sec: 0.129333\n",
    "INFO:tensorflow:loss = 1187.8994, step = 201 (773.200 sec)\n",
    "################################################\n",
    "181023 퇴근시 돌리고 간 모델...\n",
    "100, 300, 10 셋팅\n",
    "인풋은 넘파이에서 바로(num_parallel_calls 옵션 없음.)\n",
    "쓰레드 128, 128 적용.\n",
    "작동 하지 않음.\n",
    "################################################\n",
    "181022 퇴근시 돌리고 간 모델...\n",
    "100, 300, 10 셋팅\n",
    "num_parallel_calls = 2 -> 8로 변경, 배치 100->64로 변경, 쓰레드 64, 64 적용.\n",
    "100 iter 당 10분 소요.\n",
    "9000회 훈련에 약 14시간 소요되었고 \n",
    "train-loss : 6.7 / eval-loss : 7.6\n",
    "거의 수렴함.\n",
    "################################################\n",
    "20181022 16:00 작업시작~15:00 작업종료건. 100, 300, 10 셋팅\n",
    "INFO:tensorflow:Calling model_fn.\n",
    "INFO:tensorflow:Done calling model_fn.\n",
    "INFO:tensorflow:Create CheckpointSaverHook.\n",
    "INFO:tensorflow:Graph was finalized.\n",
    "INFO:tensorflow:Running local_init_op.\n",
    "INFO:tensorflow:Done running local_init_op.\n",
    "INFO:tensorflow:Saving checkpoints for 0 into ./Trained_models/Models_WnD/StartDate_181022/model.ckpt.\n",
    "INFO:tensorflow:loss = 853.93884, step = 1\n",
    "INFO:tensorflow:global_step/sec: 0.0862069\n",
    "INFO:tensorflow:loss = 3197.085, step = 101 (1160.012 sec)\n",
    "INFO:tensorflow:global_step/sec: 0.158939\n",
    "INFO:tensorflow:loss = 1942.4188, step = 201 (629.164 sec)\n",
    "INFO:tensorflow:global_step/sec: 0.156028\n",
    "INFO:tensorflow:loss = 1513.222, step = 301 (640.913 sec)\n",
    "INFO:tensorflow:global_step/sec: 0.153983\n",
    "INFO:tensorflow:loss = 1389.647, step = 401 (649.430 sec)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 181025일 기준\n",
    "# D2V -> 1 하이레벨텐서로 묶음."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def input_fn(data_files, num_epochs, batch_size):\n",
    "    def parse_csv(value):\n",
    "        columns = tf.decode_csv(value, record_defaults=iK['_csv_col_defaults'])\n",
    "        feature_ex_d2v = columns[:-301] #레이블 포함 마지막 301개 컬럼은 항상 d2v + 1label여야 한다.\n",
    "        tmp_zip1 = dict(zip(iK['featurenm'][:-300], feature_ex_d2v))\n",
    "        feature_d2v = columns[-301:-1] # 마지막 300개 features = d2v\n",
    "        tmp_zip2 = {'d2v': tf.stack(feature_d2v, axis = -1)}\n",
    "        label = columns[-1]\n",
    "        d = dict(**tmp_zip1, **tmp_zip2), label\n",
    "        return d\n",
    "    \n",
    "    dataset = tf.data.TextLineDataset(data_files)\n",
    "    dataset = dataset.apply(tf.contrib.data.shuffle_and_repeat(buffer_size = 400000, count = num_epochs))\n",
    "    dataset = dataset.apply(tf.contrib.data.map_and_batch(map_func=parse_csv, \n",
    "                                                          batch_size=batch_size, \n",
    "                                                          num_parallel_calls = 16))\n",
    "    dataset = dataset.cache()\n",
    "    dataset = dataset.prefetch(buffer_size = 50)\n",
    "    iterator = dataset.make_one_shot_iterator()\n",
    "    batch_features, batch_labels = iterator.get_next()\n",
    "    return batch_features, batch_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] 지정된 경로를 찾을 수 없습니다: './Datasets/'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-51-7c92b4bfa974>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mfilenames\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m\"./Datasets/\"\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mf_name\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mf_name\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'./Datasets/'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mf_name\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'dataset'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mf_name\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mfilename_split\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_eval_filesplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilenames\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfilenames\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_rate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.8\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mtrain_input_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minput_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_files\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfilename_split\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'train_files'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1e6\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m64\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] 지정된 경로를 찾을 수 없습니다: './Datasets/'"
     ]
    }
   ],
   "source": [
    "filenames = [\"./Datasets/\"+f_name for f_name in os.listdir('./Datasets/') if f_name.startswith('dataset') and f_name.endswith('.csv')]\n",
    "filename_split = train_eval_filesplit(filenames = filenames, train_rate=0.8)\n",
    "\n",
    "def train_input_fn():\n",
    "    return input_fn(data_files=filename_split['train_files'], num_epochs=int(1e6), batch_size=64)\n",
    "\n",
    "def eval_input_fn():\n",
    "    return input_fn(data_files=filename_split['eval_files'], num_epochs=1, batch_size=1)\n",
    "\n",
    "print(filename_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# item + 크로스 컬럼을 아래와 같이?\n",
    "# test = tf.contrib.layers.real_valued_column(column_name=test, dimension=???, dtype=tf.int64)\n",
    "# test_buckets = tf.contrib.layers.bucketized_column(test, boundaries=[1])\n",
    "# 또는 위를 아이템만 하고\n",
    "# tf.contrib.layers.crossed_column([test_buckets, test_buckets], hash_bucket_size=?1??int(1e4))\n",
    "\n",
    "def TensorGenerator(w_co_item, w_co_cros, w_ca_else, d_co_d2v, d_ca_else):\n",
    "    wide_cont_item=[tf.contrib.layers.sparse_column_with_integerized_feature(column_name=ii, bucket_size=1) for ii in w_co_item]\n",
    "    wide_cont_cros=[tf.contrib.layers.sparse_column_with_integerized_feature(column_name=jj, bucket_size=1) for jj in w_co_cros]\n",
    "    wide_cate_else=tf.contrib.layers.sparse_column_with_keys(column_name=w_ca_else, keys=iK[w_ca_else])\n",
    "    \n",
    "    deep_cont_d2v =tf.contrib.layers.real_valued_column(column_name=d_co_d2v, dimension=300, dtype=tf.float64)\n",
    "    deep_cate_else=[tf.contrib.layers.sparse_column_with_keys(column_name=ll, keys=iK[ll]) for ll in d_ca_else]\n",
    "    deep_cate_else=[tf.contrib.layers.embedding_column(\n",
    "            sparse_id_column = deep_cate_else[mm], \n",
    "            dimension = len(iK[d_ca_else[mm]])) for mm in range(len(d_ca_else))]\n",
    "    \n",
    "    wide_columns = wide_cont_item + wide_cont_cros + [wide_cate_else]\n",
    "    deep_columns = [deep_cont_d2v] + deep_cate_else\n",
    "    return {'wide_columns' : wide_columns, 'deep_columns' : deep_columns}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TensorList = TensorGenerator(\n",
    "    w_co_item = iK['x_item_colnm'], \n",
    "    w_co_cros = iK['x_cross_colnm'],\n",
    "    w_ca_else = 'ConstructionType',\n",
    "    d_co_d2v = 'd2v', \n",
    "    d_ca_else = iK['x_else_colnm'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model config setup for speed up (reference : tensorflow performance guide)\n",
    "config = tf.ConfigProto()\n",
    "config.intra_op_parallelism_threads = 256# 256->512->1024\n",
    "config.inter_op_parallelism_threads = 256# 256->512->1024\n",
    "_config = tf.contrib.learn.RunConfig(\n",
    "    session_config=config, \n",
    "    save_checkpoints_secs=None, \n",
    "    save_checkpoints_steps=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tot_model = tf.estimator.DNNLinearCombinedClassifier(\n",
    "    model_dir=model_dir, \n",
    "    linear_feature_columns=TensorList['wide_columns'],\n",
    "    dnn_feature_columns=TensorList['deep_columns'],\n",
    "    dnn_hidden_units= [500, 200], dnn_dropout = 0.5, \n",
    "    n_classes = len(iK['y_classes']), label_vocabulary=iK['y_classes'], batch_norm = True,\n",
    "    config = _config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.tensorflow.org/api_docs/python/tf/estimator/train_and_evaluate\n",
    "train_spec = tf.estimator.TrainSpec(input_fn=train_input_fn)\n",
    "eval_spec = tf.estimator.EvalSpec(input_fn=eval_input_fn)\n",
    "tf.estimator.train_and_evaluate(tot_model, train_spec, eval_spec)\n",
    "# 30,100,0은 뻑남. ---소요시간 반나절.\n",
    "# 50,100,10은 뻑남 ---소요시간 하루종일 -> 100번까지 돌다가 뻑남.\n",
    "# 100,300,10은 --- 돌아간다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #플레이스 홀더 초기화 포함한 코드... 점검 안해봄.\n",
    "\n",
    "# # https://stackoverflow.com/questions/45620449/initialization-of-tf-contrib-data-iterator-with-tf-estimator\n",
    "# class IteratorInitHook(tf.train.SessionRunHook):\n",
    "#     def after_create_session(self, session, coord):\n",
    "#         session.run(self.iterator_init_op)\n",
    "\n",
    "# def train_input_fn():\n",
    "#     init_hook = IteratorInitHook()\n",
    "#     _input = input_fn(X=X_train, y=y_train, num_epochs=int(1e6), batch_size=64, buffer_size=len(X_train))\n",
    "#     return _input, init_hook\n",
    "\n",
    "# def eval_input_fn():\n",
    "#     init_hook = IteratorInitHook()\n",
    "#     _input = input_fn(X=X_test, y=y_test, num_epochs=1, batch_size=64, buffer_size=len(X_test))\n",
    "#     return _input, init_hook\n",
    "\n",
    "# train_input_fn, train_init_hook = train_input_fn()\n",
    "# test_input_fn, test_init_hook = eval_input_fn()\n",
    "\n",
    "# train_spec = tf.estimator.TrainSpec(input_fn=train_input_fn, hooks = train_init_hook)\n",
    "# eval_spec = tf.estimator.EvalSpec(input_fn=eval_input_fn, hooks = test_init_hook)\n",
    "# tf.estimator.train_and_evaluate(tot_model, train_spec, eval_spec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 데일리 예측 결과 뽑기용\n",
    "# prediction = tot_model.predict(input_fn=eval_input_fn)\n",
    "# prediction_result = []\n",
    "# for num, item in enumerate(prediction):\n",
    "#     if num % 10 ==0:\n",
    "#         print(num)\n",
    "#     if num >= 100: #eval01.shape[0]:\n",
    "#         break\n",
    "#     else:\n",
    "#         prediction_result.append(item['probabilities'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 평가용 - 구매아이템 A가 추천 아이템 3  or 5 or 10개중에 포함될 확률\n",
    "# eval_threshold = 10\n",
    "# eval01 = np.loadtxt(fname=\"./Datasets/dataset4.csv\",delimiter=',',dtype='str')\n",
    "# eval02 = pd.Series(iK['y_classes'])\n",
    "\n",
    "# # 예측 결과 출력\n",
    "# prediction = tot_model.predict(input_fn=eval_input_fn)\n",
    "# result = []\n",
    "# for num, item in enumerate(prediction):\n",
    "#     if num >= 100: #eval01.shape[0]:\n",
    "#         break\n",
    "#     else:\n",
    "#         rateeval1 = pd.Series(item['probabilities']).sort_values(ascending = False).iloc[:eval_threshold] # 가장높은 확률 K개\n",
    "#         rateeval2 = eval02[eval02.index.isin(rateeval1.index)].values # 가장높은 확률에 해당하는 아이템 리스트업\n",
    "#         result.append(int(eval01[:,-1][ii] in rateeval2)) # 정답과 비교\n",
    "#         print(result[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#### 과거 스트립트\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction format\n",
    "# 181012\n",
    "#이전 n개의 기록으로 k개의 장바구니를 예측(k와n 사이 최소기간 p-day\n",
    "\"\"\"\n",
    "일 기준으로 리스트 업 하려면 아래 코드 사용.\n",
    "df1['OrderTime'] = df1['OrderTime'].dt.date\n",
    "df02 = df1.groupby(['BpID','OrderTime']).agg({\n",
    "        'OrderNum': lambda x: list(x), \n",
    "        'ProductCode' : lambda x: list(x)}).reset_index()\n",
    "오전/오후 구분하여 적용하려면 아래 코드 사용하여 groupby\n",
    "df1['afternoonTF'] = (df1['OrderTime'].dt.time > datetime.time(12)).astype('int')\n",
    "주문건 기준으로 리스트업 하려면 아래 코드 사용\n",
    "df1 = df[['BpID','OrderTime','OrderNum','ProductCode']].drop_duplicates(keep='first')\n",
    "df1['OrderTime'] = pd.to_datetime(df1['OrderTime'])\n",
    "df1 = df1.sort_values(['BpID','OrderTime']).reset_index(drop = True)\n",
    "df2 = df1.groupby(['BpID','OrderTime','OrderNum'])['ProductCode'].apply(list).reset_index()\n",
    "        \n",
    "\"\"\"\n",
    "nx =  3 # 이전 기록 갯수(X)\n",
    "ny = 1 # 이후 기록 갯수(Y)\n",
    "df2_1 = {\n",
    "    'BpID':[], 'OrderTime':[],\n",
    "    'x_OrderNums':[], 'y_OrderNums':[],\n",
    "    'x_ProductCodes':[], 'y_ProductCodes':[]\n",
    "}\n",
    "print('Loop start!!')\n",
    "start = datetime.datetime.now()\n",
    "for ii in range(len(df2)-nx):\n",
    "    targetdata = df2.iloc[ii:ii+nx+ny,].reset_index(drop=True)\n",
    "    if len(targetdata['BpID'].unique())==1 and len(targetdata) == nx+ny: # 앞 nx+ny 가 모두 같은 사업장이고 사이즈가 nx+ny인 경우\n",
    "        tmpdata1 = targetdata['OrderNum'].tolist()\n",
    "        tmpdata2 = targetdata['ProductCode'].tolist()\n",
    "        df2_1['BpID'].append(targetdata['BpID'][0])\n",
    "        df2_1['OrderTime'].append(targetdata['OrderTime'][nx-ny])\n",
    "        df2_1['x_OrderNums'].append([','.join(tmpdata1[0:nx])])\n",
    "        df2_1['y_OrderNums'].append([','.join(tmpdata1[nx:nx+ny])])\n",
    "        df2_1['x_ProductCodes'].append([','.join(list(chain.from_iterable(tmpdata2[0:nx])))])\n",
    "        df2_1['y_ProductCodes'].append([','.join(list(chain.from_iterable(tmpdata2[nx:nx+ny])))])\n",
    "    if ii % 10000 == 0:\n",
    "        duration = datetime.datetime.now()-start;m, s = divmod(duration.seconds, 60)\n",
    "        h, m = divmod(m, 60);print(\"[%d]/[%d]-----[%02d:%02d:%02d]\" %(ii, len(df2)-nx, h, m, s)) \n",
    "df3 = pd.DataFrame(df2_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 아이템 임베딩\n",
    "# 데이터를 one-hot 임베딩 작업 -- 181010\n",
    "# dataset_X\n",
    "X_data['x_items'] = [ii.split(',') for ii in X_data.tmp_x_items]\n",
    "mlb = MultiLabelBinarizer()\n",
    "x_item_embed = pd.DataFrame(mlb.fit_transform(X_data['x_items']), columns=mlb.classes_, index=X_data['x_items'].index)\n",
    "x_item_embed.columns = [\"x_\" + ii for ii in x_item_embed.columns.tolist()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 이하 데이터 불필요건 제거 작업\n",
    "set_size = 1000 # n개씩 끊어서 처리\n",
    "print_size = 50 # 진행과정 확인 주기\n",
    "threshold = 30 # n회 미만 구매이력 있는 아이템의 경우는 제거하자\n",
    "data_len = int(x_item_embed.shape[0]/set_size)+2\n",
    "\n",
    "# 한방에는 너무 오래걸리니 나눠서 한다.\n",
    "tmp02 = np.zeros(x_item_embed.shape[1])\n",
    "for ii in range(data_len):\n",
    "    if ii % print_size ==0:\n",
    "        print(ii, data_len)\n",
    "    tmp01 = x_item_embed.iloc[ii*set_size:ii*set_size+set_size,].values.sum(axis=0)\n",
    "    tmp02 += tmp01\n",
    "tmp03 = tmp02 > threshold\n",
    "%time x_item_embed_1 = x_item_embed.loc[:,tmp03]\n",
    "print(x_item_embed.shape, '-->', x_item_embed_1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# n회 미만 구매이력 있는 아이템을 제거하면 구매이력이 없어지는 데이터를 X,y에서 제거하자.\n",
    "drop_target_index = x_item_embed_1[x_item_embed_1.sum(axis = 1) ==0].index\n",
    "\n",
    "X_data = X_data.drop(drop_target_index, axis = 0)\n",
    "x_item_embed_1 = x_item_embed_1.drop(drop_target_index, axis = 0)\n",
    "y_item_embed = y_item_embed.drop(drop_target_index, axis = 0)\n",
    "x_cross_embed = x_cross_embed.drop(drop_target_index, axis = 0)\n",
    "print('x_item:', x_item_embed_1.shape,  '\\n', 'x_cross:', x_cross_embed.shape, '\\n', 'y_item:', y_item_embed.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_list1 = [ii.split(',') for ii in X_data.tmp_y_items]\n",
    "\n",
    "aa = []\n",
    "bb = []\n",
    "for ii, jj in pd.Series(y_list1).iteritems():\n",
    "    aa.extend(np.repeat(ii,len(jj)))\n",
    "    bb.extend(jj)\n",
    "    \n",
    "y_df = pd.DataFrame({'index': aa, 'y_items' : bb})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# from imblearn.over_sampling import RandomOverSampler # 복잡한 샘플링은 메모리 부족ㅠㅠ\n",
    "\n",
    "# even_target1 = model_df03[model_df03.ConstructionType.isin(['SKT 전송선로', 'SKB 1군', 'SKT A망 1군'])]\n",
    "# pre_y = even_target1.ConstructionType\n",
    "# pre_X = even_target1.drop(['ConstructionType'],axis = 1)\n",
    "# y = pre_y.tolist()\n",
    "# X = pre_X.values.tolist()\n",
    "\n",
    "# ros = RandomOverSampler(random_state=0)\n",
    "# X_resampled, y_resampled = ros.fit_sample(X, y)\n",
    "\n",
    "# print(\"asis : [%s] -->\\n tobe : [%s]\" %(sorted(Counter(y).items()), sorted(Counter(y_resampled).items())))\n",
    "\n",
    "# even_data_X = pd.DataFrame(X_resampled, columns= pre_X.columns)\n",
    "# even_data_y = pd.DataFrame({'ConstructionType' : y_resampled})\n",
    "# even_data = pd.merge(even_data_X, even_data_y, left_index=True, right_index=True)\n",
    "\n",
    "# ex_index = set(model_df03.index) - set(even_target1.index)\n",
    "# model_df03 = pd.concat([even_data, model_df03.loc[ex_index,:]], sort= True)\n",
    "# model_df03.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Doc2Vec(data, d2v_size, model_loc, epoch, trainTF = False):\n",
    "    \"\"\"\n",
    "    data : DataFrame([['DocID','Item']])\n",
    "    \"\"\"\n",
    "    data.columns = ['docID','item']\n",
    "    data1 = [(str(row['item']).split(), row['docID']) for idx, row in data.iterrows()]\n",
    "    data2 = namedtuple('TaggedDocument', 'words tags')\n",
    "    tagged_data2 = [data2(d, [c]) for d, c in data1]\n",
    "    \n",
    "    if trainTF:\n",
    "        model = Doc2Vec(\n",
    "            dm = 0,  # 0 : PV-DBOW\n",
    "            dbow_words = 0,  # 0 : train doc-vec only(faster)\n",
    "            window = 8, vector_size = d2v_size, alpha = 0.025, min_alpha = 0.025, seed = 0, sample= 1e-5, min_count=3, \n",
    "            workers=multiprocessing.cpu_count(), hs = 0, negative = 10)\n",
    "        model.build_vocab(tagged_data2)\n",
    "        print('New model training started')\n",
    "        model.train(documents  = tagged_data2, total_examples = data.shape[0], epochs = epoch)\n",
    "        model.save(model_loc)\n",
    "        print('New model training done. check--',model_loc)\n",
    "    else:\n",
    "        model=Doc2Vec.load(model_loc)\n",
    "        embedding_df = pd.DataFrame(\n",
    "            data = [model.infer_vector(doc.words) for doc in tagged_data2], \n",
    "            columns = [\"d2v\"+str(i) for i in range(d2v_size)])\n",
    "        return embedding_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Doc2Vec 임베딩 생성\n",
    "d2v_data = df3[['BpID','tmp_x_items']]\n",
    "file_dir = './Trained_models/Models_Doc2Vec/skts_model_doc2vec_%s.model' %(datetime.datetime.now().strftime(\"%y%m%d_%H%M\"))\n",
    "d2v_embedding = Doc2Vec(data=d2v_data, d2v_size=300, epoch=500, trainTF=False, model_loc=file_dir)\n",
    "\n",
    "# 기존데이터에 Doc2Vec 처리된 데이터 추가\n",
    "df4 = pd.merge(df3, d2v_embedding, left_index=True, right_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 크로스 컬럼\n",
    "def CrossColumnGenerator(data, threshold = 5):\n",
    "    \"\"\"\n",
    "    data : Data format must be pandas Series with rows having list of items.\n",
    "              reset_index() required.\n",
    "              example : '6601000010,6601000024,....,6601000001'\n",
    "    threshold : To exclude super sparse case of cross columns\n",
    "    dependencies : collections.Counter\n",
    "                              sklearn.feature_extraction.text.CountVectorizer\n",
    "    \"\"\"\n",
    "    cross_cnt = Counter()\n",
    "    for ii, jj in data.iteritems():\n",
    "        litem = sorted(set(jj.split(',')))\n",
    "        cross_cnt.update([str(kk + '_' + ll) for kk, ll in combinations(litem, 2)])\n",
    "        \n",
    "    target_lcross = set({x : cross_cnt[x] for x in cross_cnt if cross_cnt[x] >= threshold}.keys()) \n",
    "    \n",
    "    cross_feature = []\n",
    "    for ii, jj in X_data.tmp_x_items.iteritems():\n",
    "        litem = sorted(set(jj.split(',')))\n",
    "        lcross = set([str(kk + '_' + ll) for kk, ll in combinations(litem, 2)]).intersection(target_lcross)\n",
    "        cross_feature.append(lcross)\n",
    "\n",
    "    lcross_feature = map(lambda x:' '.join(x), cross_feature)\n",
    "    vect = CountVectorizer(tokenizer=str.split)\n",
    "    mcross_feature = vect.fit_transform(lcross_feature)\n",
    "    return pd.DataFrame(mcross_feature.todense(), columns=vect.get_feature_names())\n",
    "\n",
    "# 크로스 컬럼 생성\n",
    "# x_cross_embed = CrossColumnGenerator(X_data.tmp_x_items, threshold=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 컬럼명 정리\n",
    "x_else = ['ConstructionType', 'BusinessType', 'Regionnm']\n",
    "x_d2v = [\"d2v\"+str(ii) for ii in range(300)]\n",
    "\n",
    "x_item_colnames = x_item_embed_1.columns.tolist()\n",
    "x_cross_colnames = x_cross_embed.columns.tolist()\n",
    "y_item_colnames = y_item_embed.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 데이터 뒤섞기\n",
    "# 테이블 별로 따로 셔플햇기 때문에 인덱스가 꼬일수 있겠으나\n",
    "# random_state = 0으로 햇기 때문에 모두 같은 index로 셔플되었다? 검증!\n",
    "X_data = X_data.sample(frac = 1, random_state=0).reset_index(drop = True)\n",
    "x_cross_embed = x_cross_embed.sample(frac = 1, random_state=0).reset_index(drop = True)\n",
    "x_item_embed_1 = x_item_embed_1.sample(frac = 1, random_state=0).reset_index(drop = True)\n",
    "y_item_embed = y_item_embed.sample(frac = 1, random_state=0).reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "    if ii >= int(df_cnt*Train_volumn):\n",
    "        tfrecords_name = \"./Datasets/eval_dataset\"+str(ii - int(df_cnt*Train_volumn))+\".tfrecord\"\n",
    "    else:\n",
    "        tfrecords_name = \"./Datasets/train_dataset\"+str(ii)+\".tfrecord\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 분할 저장\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 인풋 함수\n",
    "X_else_keys = {\n",
    "    \"ConstructionType\":X_data.ConstructionType.unique(), \n",
    "    \"BusinessType\":X_data.BusinessType.unique(), \n",
    "    \"Regionnm\":X_data.Regionnm.unique()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# def input_fn(data_files, num_epochs, batch_size):\n",
    "#     def parse_csv(value):\n",
    "#         columns = tf.decode_csv(value, record_defaults=iK['_csv_col_defaults'])\n",
    "#         label = columns[-1]\n",
    "#         del columns[-1]\n",
    "#         features = columns\n",
    "#         d = dict(zip(iK['featurenm'], features)), label\n",
    "#         return d\n",
    "#     # 최적화 이전 버전\n",
    "#     dataset = (tf.data.TextLineDataset(data_files).skip(1).map(parse_csv, num_parallel_calls = 2))\n",
    "#     dataset = dataset.prefetch(buffer_size = 50)\n",
    "#     dataset = dataset.shuffle(400000)\n",
    "#     dataset = dataset.repeat(num_epochs)\n",
    "#     dataset = dataset.batch(batch_size)\n",
    "#     iterator = dataset.make_one_shot_iterator()\n",
    "#     batch_features, batch_labels = iterator.get_next()\n",
    "#     return batch_features, batch_labels\n",
    "\n",
    "# # files = tf.data.Dataset.list_files(data_files)\n",
    "# # dataset = files.apply(tf.contrib.data.parallel_interleave(tf.data.TextLineDataset, cycle_length=4))\n",
    "# # 또는 아래와 같은 방식? 위에는 베스트프랙티스 서머리에서 아래는 interleave 함수매뉴얼에서.\n",
    "# # dataset = files.apply(tf.contrib.data.parallel_interleave(\n",
    "# # lambda filename : tf.data.TextLineDataset(filename),cycle_length=4))\n",
    "# #     dataset = dataset.shuffle(buffer_size)\n",
    "# #     dataset = dataset.shuffle(buffer_size, reshuffle_each_iteration=True).repeat(num_epochs)\n",
    "# #     dataset = dataset.prefetch(50) # datasize/batchsize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# https://www.tensorflow.org/api_docs/python/tf/estimator/train_and_evaluate\n",
    "# train_spec = tf.estimator.TrainSpec(input_fn=train_input_fn)\n",
    "# eval_spec = tf.estimator.EvalSpec(input_fn=eval_input_fn)\n",
    "\n",
    "# tf.estimator.train_and_evaluate(estimator, train_spec, eval_spec)\n",
    "\n",
    "# test_dataset = full_dataset.skip(int(0.7 * DATASET_SIZE))\n",
    "# val_dataset = test_dataset.skip(int(0.15 * DATASET_SIZE))\n",
    "# test_dataset = test_dataset.take(int(0.15 * DATASET_SIZE))\n",
    "\n",
    "tot_model.train(input_fn=train_input_fn)\n",
    "# 181019 10:42시작 - 최종 메세지로 보이는 지속 시간.\n",
    "# INFO:tensorflow:Calling model_fn 30분 -> 17분\n",
    "# INFO:tensorflow:Done calling model_fn\n",
    "# INFO:tensorflow:Create CheckpointSaverHook 10분\n",
    "# INFO:tensorflow:Graph was finalized 5분\n",
    "# INFO:tensorflow:Running local_init_op \n",
    "# INFO:tensorflow:Done running local_init_op 5분\n",
    "# INFO:tensorflow:Saving checkpoints for 0 into ./Trained_models/Models_WnD/StartDate_181018/model.ckpt"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
