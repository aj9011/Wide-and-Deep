{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 변동사항\n",
    "### Doc2Vec 모델 수정\n",
    "### Doc2Vec 모델 인풋 수정\n",
    "### utf-8로 변환하는 것을 후방으로 뺌"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil, os, warnings, re, datetime, multiprocessing\n",
    "warnings.filterwarnings(action='ignore')\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import _pickle as pickle\n",
    "from functools import partial\n",
    "import matplotlib.pyplot as plt\n",
    "from gensim.models import Doc2Vec\n",
    "from itertools import chain, combinations\n",
    "from collections import namedtuple, Counter\n",
    "from manipul import manipul_df as manipulation\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "warnings.filterwarnings(action='default')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def myDoc2Vec(data, d2v_size, model_loc, epoch=None, trainTF = False):\n",
    "    \"\"\"\n",
    "    data : DataFrame([['DocID','Item']]) item : ['a','b',...,'z'] element in string type\n",
    "    \"\"\"\n",
    "    data.columns = ['docID','item']\n",
    "    data1 = [((row['item']), row['docID']) for idx, row in data.iterrows()]\n",
    "    print(data1[0])\n",
    "    data2 = namedtuple('TaggedDocument', 'words tags')\n",
    "    tagged_data2 = [data2(d, [c]) for d, c in data1]\n",
    "    \n",
    "    if trainTF:\n",
    "        model = Doc2Vec(\n",
    "            dm = 0,  # 0 : PV-DBOW\n",
    "            dbow_words = 0,  # 0 : train doc-vec only(faster)\n",
    "            window = 8, vector_size = d2v_size, alpha = 0.025, min_alpha = 0.025, seed = 0, sample= 1e-5, \n",
    "            min_count=3, workers=multiprocessing.cpu_count(), hs = 0, negative = 10)\n",
    "        model.build_vocab(tagged_data2)\n",
    "        print('Doc2Vec training step--started')\n",
    "        model.train(documents  = tagged_data2, total_examples = data.shape[0], epochs = epoch)\n",
    "        model.save(model_loc)\n",
    "        print('Doc2Vec training step--done. check--',model_loc)\n",
    "    else:\n",
    "        model=Doc2Vec.load(model_loc)\n",
    "        print('Doc2Vec inference step--started')\n",
    "        embedding_df = pd.DataFrame(\n",
    "            data = [model.infer_vector(doc.words) for doc in tagged_data2], \n",
    "            columns = [\"d2v\"+str(i) for i in range(d2v_size)])\n",
    "        print('Doc2Vec inference step--done')\n",
    "        return embedding_df\n",
    "    \n",
    "    \n",
    "def Listelement_str_to_byte(strlist, dim=2):\n",
    "    if dim==2:\n",
    "        result = []\n",
    "        for ii in range(len(strlist)):\n",
    "            tmp = []\n",
    "            for jj in range(len(strlist[ii])):\n",
    "                tmp.append(strlist[ii][jj].encode('utf-8'))\n",
    "            result.append(tmp)\n",
    "    elif dim==1:\n",
    "        result = []\n",
    "        for ii in range(len(strlist)):\n",
    "            result.append(strlist[ii].encode('utf-8'))\n",
    "    else:\n",
    "        print('pz make custom function')\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0 0 0 0 0 0 0 0\n",
      "ALL nesessary data imported\n"
     ]
    }
   ],
   "source": [
    "# 신규데이터 import\n",
    "rawdata_loc = \"./Datasets/Sourcefiles/181212/\"\n",
    "\n",
    "n주문 = pd.read_csv(rawdata_loc+\"Order.csv\", encoding = 'utf-8', dtype = 'str')\n",
    "n주문상품 = pd.read_csv(rawdata_loc+\"OrderProduct.csv\", encoding = 'utf-8', dtype = 'str')\n",
    "n주문상품출하 = pd.read_csv(rawdata_loc+\"OrderProductShip.csv\", encoding = 'utf-8', dtype = 'str')\n",
    "n조마 = pd.read_csv(rawdata_loc+\"info_Team.csv\", encoding = 'utf-8', dtype = 'str')\n",
    "n사업장 = pd.read_csv(rawdata_loc+\"info_Bp.csv\", encoding = 'utf-8', dtype = 'str')\n",
    "n공유 = pd.read_csv(rawdata_loc+\"info_ConstructionType.csv\", encoding = 'utf-8', dtype = 'str')\n",
    "n상마 = pd.read_csv(rawdata_loc+\"info_Product.csv\", encoding = 'utf-8', dtype = 'str')\n",
    "n상품진열이력 = pd.read_csv(rawdata_loc+\"hist_ProductView.csv\", encoding = 'utf-8', dtype = 'str')\n",
    "n상품공급사 = pd.read_csv(rawdata_loc+\"info_ProductSupply.csv\", encoding = 'utf-8', dtype = 'str')\n",
    "\n",
    "# 기존데이터 Import\n",
    "주문_2014 = pd.read_csv('./Datasets/Sourcefiles/Order_2014.csv', encoding = 'utf-8', dtype = 'str')\n",
    "주문_2015 = pd.read_csv('./Datasets/Sourcefiles/Order_2015.csv', encoding = 'utf-8', dtype = 'str')\n",
    "주문_2016 = pd.read_csv('./Datasets/Sourcefiles/Order_2016.csv', encoding = 'utf-8', dtype = 'str')\n",
    "주문_2017 = pd.read_csv('./Datasets/Sourcefiles/Order_2017.csv', encoding = 'utf-8', dtype = 'str')\n",
    "주문_2018 = pd.read_csv('./Datasets/Sourcefiles/Order_2018.csv', encoding = 'utf-8', dtype = 'str')\n",
    "주문상품_2014 = pd.read_csv('./Datasets/Sourcefiles/OrderProduct_2014.csv', encoding = 'utf-8', dtype = 'str')\n",
    "주문상품_2015 = pd.read_csv('./Datasets/Sourcefiles/OrderProduct_2015.csv', encoding = 'utf-8', dtype = 'str')\n",
    "주문상품_2016 = pd.read_csv('./Datasets/Sourcefiles/OrderProduct_2016.csv', encoding = 'utf-8', dtype = 'str')\n",
    "주문상품_2017 = pd.read_csv('./Datasets/Sourcefiles/OrderProduct_2017.csv', encoding = 'utf-8', dtype = 'str')\n",
    "주문상품_2018 = pd.read_csv('./Datasets/Sourcefiles/OrderProduct_2018.csv', encoding = 'utf-8', dtype = 'str')\n",
    "주문상품출하_2014 = pd.read_csv('./Datasets/Sourcefiles/OrderProductShip_2014.csv', encoding = 'utf-8', dtype = 'str')\n",
    "주문상품출하_2015 = pd.read_csv('./Datasets/Sourcefiles/OrderProductShip_2015.csv', encoding = 'utf-8', dtype = 'str')\n",
    "주문상품출하_2016 = pd.read_csv('./Datasets/Sourcefiles/OrderProductShip_2016.csv', encoding = 'utf-8', dtype = 'str')\n",
    "주문상품출하_2017 = pd.read_csv('./Datasets/Sourcefiles/OrderProductShip_2017.csv', encoding = 'utf-8', dtype = 'str')\n",
    "주문상품출하_2018 = pd.read_csv('./Datasets/Sourcefiles/OrderProductShip_2018.csv', encoding = 'utf-8', dtype = 'str')\n",
    "조마=pd.read_csv('./Datasets/Sourcefiles/info_Team.csv',encoding ='utf-8',dtype = 'str')\n",
    "사업장=pd.read_csv('./Datasets/Sourcefiles/info_Bp.csv',encoding ='utf-8',dtype = 'str')\n",
    "공유=pd.read_csv('./Datasets/Sourcefiles/info_ConstructionType.csv',encoding ='utf-8',dtype = 'str')\n",
    "상마=pd.read_csv('./Datasets/Sourcefiles/info_Product.csv',encoding ='utf-8',dtype = 'str')\n",
    "상품공급사 = pd.read_csv('./Datasets/Sourcefiles/info_ProductSupply.csv',encoding='utf-8',dtype='str')\n",
    "상품진열이력 = pd.read_csv('./Datasets/Sourcefiles/hist_item_open.csv', dtype = 'str') # 상품진열 히스토리\n",
    "\n",
    "# 컬럼명 비교\n",
    "print(\n",
    "    sum(n주문.columns != 주문_2018.columns),\n",
    "    sum(n주문상품.columns != 주문상품_2018.columns),\n",
    "    sum(n주문상품출하.columns != 주문상품출하_2018.columns),\n",
    "    \n",
    "    sum(n조마.columns != 조마.columns),\n",
    "    sum(n사업장.columns != 사업장.columns),\n",
    "    sum(n공유.columns != 공유.columns),\n",
    "    sum(n상마.columns != 상마.columns),\n",
    "    sum(n상품공급사.columns != 상품공급사.columns),\n",
    "    sum(n상품진열이력.columns != 상품진열이력.columns)\n",
    ")\n",
    "\n",
    "### info, hist류의 데이터는 신규 데이터로 업데이트 하고 주문 데이터는 날짜 별로 업데이트 한다.\n",
    "조마 = n조마.copy()\n",
    "사업장 = n사업장.copy()\n",
    "공유 = n공유.copy()\n",
    "상마 = n상마.copy()\n",
    "상품공급사 = n상품공급사.copy()\n",
    "상품진열이력 = n상품진열이력.copy()\n",
    "\n",
    "경계일 = \"2018-09-01\" # 기존, 신규 사이 경계일\n",
    "전일 = \"2018-12-12\" # 데이터 만료일+1 일\n",
    "\n",
    "주문_2018 = 주문_2018[주문_2018.REGI_DATE_TIME<str(pd.to_datetime(경계일))]\n",
    "n주문 = n주문[(\n",
    "    (n주문.REGI_DATE_TIME>=str(pd.to_datetime(경계일)))&\n",
    "    (n주문.REGI_DATE_TIME<str(pd.to_datetime(전일)))\n",
    ")]\n",
    "\n",
    "# Stage1 주문처리\n",
    "주문 = pd.concat([주문_2014, 주문_2015, 주문_2016, 주문_2017, 주문_2018, n주문])\n",
    "주문상품 = pd.concat([주문상품_2014, 주문상품_2015, 주문상품_2016, 주문상품_2017, 주문상품_2018, n주문상품])\n",
    "주상출 = pd.concat([주문상품출하_2014, 주문상품출하_2015, 주문상품출하_2016, 주문상품출하_2017, 주문상품출하_2018,n주문상품출하])\n",
    "print(\"ALL nesessary data imported\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "주문 = 주문[주문.GROUPID!='101'][[\n",
    "    'ORDE_IDEN_NUMB', 'CONS_IDEN_NAME', 'GROUPID', 'CLIENTID', 'BRANCHID',\n",
    "    'DELI_AREA_CODE','REGI_DATE_TIME','ORDE_USER_ID'\n",
    "]].drop_duplicates(keep='first').reset_index(drop=True).fillna(\"\")\n",
    "\n",
    "주문상품 = 주문상품[[\n",
    "    'ORDE_IDEN_NUMB', 'ORDE_SEQU_NUMB','GOOD_IDEN_NUMB',\n",
    "    'VENDORID','ORDE_REQU_QUAN', 'DELI_MINI_DAY','REQU_DELI_DATE'\n",
    "]].drop_duplicates(keep='first').reset_index(drop=True).dropna()\n",
    "\n",
    "주상출 = 주상출[['ORDE_IDEN_NUMB','ORDE_SEQU_NUMB','DELI_STAT_FLAG',\n",
    "           'DELI_DEGR_DATE']].drop_duplicates(keep='first').reset_index(drop=True)\n",
    "\n",
    "주상출.ORDE_SEQU_NUMB = 주상출.ORDE_SEQU_NUMB.astype('int64')\n",
    "주문상품.ORDE_SEQU_NUMB = 주문상품.ORDE_SEQU_NUMB.astype('int64')\n",
    "\n",
    "주문주상 = pd.merge(주문,주문상품,on='ORDE_IDEN_NUMB',how='left')\n",
    "주문주상출하 = pd.merge(주문주상,주상출,on=['ORDE_IDEN_NUMB','ORDE_SEQU_NUMB'],\n",
    "                  how='left')\n",
    "\n",
    "주문_total = 주문주상출하[주문주상출하.DELI_STAT_FLAG == '70'].drop(\n",
    "    'DELI_STAT_FLAG', axis=1).reset_index(drop=True)\n",
    "\n",
    "# Stage2 사업장 처리\n",
    "사업장 = pd.concat([\n",
    "        사업장[['BRANCHID','AREATYPE','BRANCHBUSITYPE','BRANCHBUSICLAS','WORKID']].rename(columns={'BRANCHID':'BORGID'}), \n",
    "        사업장[['BRANCHCD','AREATYPE','BRANCHBUSITYPE','BRANCHBUSICLAS','WORKID']].rename(columns={'BRANCHCD':'BORGID'})\n",
    "    ], axis=0).drop_duplicates(keep='first')\n",
    "\n",
    "공사유형_사업장 = pd.merge(\n",
    "    사업장, \n",
    "    공유[['WORKID','WORKNM']].drop_duplicates(keep='first'), \n",
    "    how = 'left', on = 'WORKID')\n",
    "\n",
    "조직마스터 = 조마[(조마.BORGTYPECD == 'BCH') & (조마.SVCTYPECD == 'BUY')]\n",
    "조직마스터 = pd.concat([\n",
    "        조직마스터[['BORGID','BORGNM']], \n",
    "        조직마스터[['BORGCD','BORGNM']].rename(columns={'BORGCD':'BORGID'})\n",
    "    ], axis=0).drop_duplicates(keep='first')\n",
    "\n",
    "조직_total = pd.merge(\n",
    "    조직마스터, 공사유형_사업장, how = 'left', on = 'BORGID').rename(\n",
    "    columns={'BORGID':'BRANCHID'}).fillna(\"\")\n",
    "\n",
    "주조_total = pd.merge(주문_total,조직_total,\n",
    "              how='left',left_on='BRANCHID',right_on='BRANCHID').dropna()\n",
    "\n",
    "\n",
    "상품마스터 = 상마[['good_iden_numb','good_name','good_spec',\n",
    "                   'good_type','repre_good']].drop_duplicates(keep='first')\n",
    "\n",
    "df_init = pd.merge(주조_total, 상품마스터, \n",
    "                   left_on = 'GOOD_IDEN_NUMB', right_on = 'good_iden_numb', \n",
    "                   how = 'left')\n",
    "df_init = df_init[df_init.repre_good==\"N\"].reset_index(drop=True)\n",
    "\n",
    "df_init = df_init.drop([\n",
    "    \"ORDE_SEQU_NUMB\",\"GROUPID\",\"ORDE_USER_ID\",\"DELI_DEGR_DATE\",\"DELI_MINI_DAY\",\n",
    "    \"REQU_DELI_DATE\",\"ORDE_REQU_QUAN\",\"good_type\",\"good_spec\",\"good_name\",\n",
    "    \"DELI_AREA_CODE\",\"BORGNM\",\"CONS_IDEN_NAME\",\"repre_good\",\"CLIENTID\",\n",
    "    \"VENDORID\",\"good_iden_numb\",\"WORKNM\"],\n",
    "    axis=1)\n",
    "\n",
    "df = df_init.rename(columns={\n",
    "    \"ORDE_IDEN_NUMB\":\"OrderNum\", \n",
    "    \"GOOD_IDEN_NUMB\":\"ProductCode\",\n",
    "    \"BRANCHID\":\"BpID\",\n",
    "    \"REGI_DATE_TIME\":\"OrderTime\",\n",
    "    \"AREATYPE\":\"Region\",\n",
    "    \"BRANCHBUSITYPE\":\"BpType\",\n",
    "    \"BRANCHBUSICLAS\":\"BpClass\",\n",
    "    \"WORKID\":\"ConstructionType\"\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(111280, 8)\n"
     ]
    }
   ],
   "source": [
    "df['OrderTime'] =  pd.to_datetime(df['OrderTime'])\n",
    "df['OrderDate'] =  df['OrderTime'].dt.date\n",
    "df = df.drop_duplicates(keep='first').reset_index(drop=True)\n",
    "\n",
    "ActiveProduct = pd.read_csv(\n",
    "    './Datasets/Sourcefiles/info_ProductSupply.csv',\n",
    "    encoding='utf-8',\n",
    "    dtype='str')#상품공급사\n",
    "df['ProductActiveTF'] = df.ProductCode.isin(\n",
    "    list(set(ActiveProduct[ActiveProduct.isUse==\"1\"].good_iden_numb)))\n",
    "\n",
    "thres1 = Counter(df.ProductCode)\n",
    "thres2 = {x : thres1[x] for x in thres1 if thres1[x]>10} # frequently purchased\n",
    "thres3 = {x : thres1[x] for x in thres1 if thres1[x]<=10} # seldomly purchased\n",
    "\n",
    "conditions = [\n",
    "    (df['ProductCode'].isin(list(thres2.keys()))) & (df['ProductActiveTF']==True), # 자주 구매하면서 active\n",
    "    (df['ProductCode'].isin(list(thres2.keys()))) & (df['ProductActiveTF']==False),# 자주 구매하면서 inactive ~99\n",
    "    (df['ProductCode'].isin(list(thres3.keys())))# 덜 구매 ~98\n",
    "]\n",
    "choices = [df.ProductCode,\"99999999999\",\"99999999998\"]\n",
    "df['GrpProductCode'] = np.select(conditions,choices,default='none')\n",
    "\n",
    "df1 = df.drop(['OrderNum','ProductActiveTF'],axis = 1)\n",
    "df1 = df1.drop([\"ProductCode\"],axis=1).rename(columns={\"GrpProductCode\":\"ProductCode\"}) # 제품코드를 교체"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./Datasets/VocaList_181218_final.pkl','rb') as f:\n",
    "    vL = pickle.load(f)\n",
    "    \n",
    "ListProductCode = [ii.decode('utf-8') for ii in vL['yv']]\n",
    "# 기존에 있는 자재만 필터링\n",
    "df1 = df1[df1.ProductCode.isin(ListProductCode)].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(108254, 8)\n"
     ]
    }
   ],
   "source": [
    "df1_1 = df1.groupby(['OrderDate','BpID','Region','ConstructionType','BpType','BpClass']).agg({\n",
    "    \"ProductCode\":list,\"OrderTime\":\"max\"}).reset_index()\n",
    "df2 = df1_1.sort_values(['BpID','OrderTime']).reset_index(drop = True)\n",
    "print(df2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Original\n",
    "# # df = pd.read_csv('./Datasets/total_table_MainTotal.csv', dtype='str', encoding='utf-8')\n",
    "# ActiveProduct = pd.read_csv('./Datasets/item_supply.csv',encoding='utf-8',dtype='str')#상품공급사\n",
    "# ConstType = pd.read_csv('./Datasets/ConstructionType.csv',encoding='utf-8',dtype='str')#공사유형\n",
    "# ConstType  = ConstType.rename(columns={\"WORKNM\":\"ConstructionType\"})\n",
    "# ConstType = ConstType[[\"ConstructionType\",\"WORKID\"]].drop_duplicates()\n",
    "# df = pd.merge(df, ConstType, on=\"ConstructionType\", how=\"left\").drop(\n",
    "#     [\"ConstructionType\"],axis=1).rename(columns={\"WORKID\":\"ConstructionType\"})\n",
    "\n",
    "# df = df[df.Option_rep==\"N\"].dropna()\n",
    "# df['OrderTime'] =  pd.to_datetime(df['OrderTime'])\n",
    "# df['OrderDate'] =  df['OrderTime'].dt.date\n",
    "# df = df.drop(['SubOrderNum','GroupID','OrderAccount','ShipDate','DeliDate',\n",
    "# 'RequestDeliDate','SupplyID','Supplynm','CompanyID','Companynm','Option_rep',\n",
    "# 'Constructionnm','Bpnm','Region','Productnm','ProductSize','ProductType1',\n",
    "# 'LCategory','MCategory','SCategory','OrderAmt','UnitPrice'], axis =1)\n",
    "# df = df.rename(columns={'BpRegion':'Region'})\n",
    "# df = df.drop_duplicates(keep='first')\n",
    "\n",
    "# df['ProductActiveTF'] = df.ProductCode.isin(list(set(ActiveProduct[ActiveProduct.isUse==\"1\"].good_iden_numb)))\n",
    "\n",
    "# thres1 = Counter(df.ProductCode)\n",
    "# thres2 = {x : thres1[x] for x in thres1 if thres1[x]>10} # frequently purchased\n",
    "# thres3 = {x : thres1[x] for x in thres1 if thres1[x]<=10} # seldomly purchased\n",
    "\n",
    "# conditions = [\n",
    "#     (df['ProductCode'].isin(list(thres2.keys()))) & (df['ProductActiveTF']==True), # 자주 구매하면서 active\n",
    "#     (df['ProductCode'].isin(list(thres2.keys()))) & (df['ProductActiveTF']==False),# 자주 구매하면서 inactive ~99\n",
    "#     (df['ProductCode'].isin(list(thres3.keys())))# 덜 구매 ~98\n",
    "# ]\n",
    "# choices = [df.ProductCode,\"99999999999\",\"99999999998\"]\n",
    "# df['GrpProductCode'] = np.select(conditions,choices,default='none')\n",
    "\n",
    "# df1 = df.drop(['OrderNum','ProductActiveTF'],axis = 1)\n",
    "# df1 = df1.drop([\"ProductCode\"],axis=1).rename(columns={\"GrpProductCode\":\"ProductCode\"}) # 제품코드를 교체\n",
    "# df1 = df1.groupby(['OrderDate','BpID','Region','ConstructionType','BpType','BpClass']).agg({\n",
    "#     \"ProductCode\":list,\"OrderTime\":\"max\"}).reset_index()\n",
    "# df2 = df1.sort_values(['BpID','OrderTime']).reset_index(drop = True)\n",
    "# print(df2.shape)\n",
    "# Original end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2['OrderYear'] =  df2.OrderTime.dt.year\n",
    "loopindex = df2[['BpID', 'OrderYear']].drop_duplicates().sort_values(by=['BpID','OrderYear']).values\n",
    "df2_1 = { 'BpID':[], 'OrderTime':[], 'x_ProductCodes':[],  'y_ProductCodes':[]}\n",
    "\n",
    "for ii,jj in loopindex:\n",
    "    looph1 = df2[(df2['BpID']==ii) & (df2[\"OrderYear\"]==jj)].reset_index(drop=True)\n",
    "    for kk in range(looph1.shape[0]):\n",
    "        yy = looph1.iloc[kk+1:kk+2,:]\n",
    "        xx = looph1.iloc[0:kk+1,:]\n",
    "        if len(yy['ProductCode']) == 1:\n",
    "            df2_1['x_ProductCodes'].append(list(set(chain.from_iterable(xx['ProductCode'].tolist()))))\n",
    "            df2_1['y_ProductCodes'].append(list(set(chain.from_iterable(yy['ProductCode'].tolist()))))\n",
    "            df2_1['OrderTime'].append(xx.OrderTime.max())\n",
    "            df2_1['BpID'].append(ii)\n",
    "            \n",
    "df2_2 = pd.DataFrame(df2_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(105253, 4)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2_2.shape # (108204, 4) ->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(['99999999999', '6601000067', '6601000010', '6601000053', '6601000174', '6601000024'], '304576')\n",
      "Doc2Vec inference step--started\n",
      "Doc2Vec inference step--done\n"
     ]
    }
   ],
   "source": [
    "# Doc2Vec 임베딩 생성\n",
    "start = datetime.datetime.now()\n",
    "model_loc=\"./Trained_models/Models_Doc2Vec/Recommendation_15d2v_model_1207.model\"\n",
    "x_d2v_embed = myDoc2Vec(data=df2_2[['BpID','x_ProductCodes']], d2v_size=15,\n",
    "                        trainTF=False, model_loc=model_loc)\n",
    "x_d2v_embed2 = pd.DataFrame(pd.Series(x_d2v_embed.values.tolist()), columns=['d2v'])\n",
    "duration = datetime.datetime.now()-start;m, s = divmod(duration.seconds, 60)\n",
    "h, m = divmod(m, 60);print(\"[%02d:%02d:%02d]\" %(h, m, s)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y아이템은 row단위로\n",
    "y_ProductCodes = []\n",
    "for ii in df2_2.y_ProductCodes.index:\n",
    "    for jj in df2_2.y_ProductCodes[ii]:\n",
    "        y_ProductCodes.append((ii, jj))\n",
    "df3_2 = pd.DataFrame(y_ProductCodes, columns=['index','y_ProductCodes']).set_index('index')\n",
    "\n",
    "# 전체 재통합\n",
    "df3 = pd.merge(\n",
    "    pd.concat([df2_2[[\"BpID\",\"OrderTime\",\"x_ProductCodes\"]], x_d2v_embed2, df3_2], axis=1), \n",
    "    df2[['BpID','Region','ConstructionType','BpType','BpClass']].drop_duplicates(),\n",
    "    on='BpID').reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3_3 = 상품진열이력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 없는자재 제거\n",
    "ListProductCode2 = [ii.decode('utf-8') for ii in vL['showv']]\n",
    "df3_3 = df3_3[df3_3.GOOD_IDEN_NUMB.isin(ListProductCode2)].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 노출 상품중 구매하지 않은 상품 리스트 추가하기. - Lookup table만들어 적용.\n",
    "# df3_3 = pd.read_csv('./Datasets/hist_item_open.csv', dtype = 'str') # 상품진열 히스토리\n",
    "df3_3 = df3_3[['GOOD_IDEN_NUMB','WORKINFO_ID_ARR','HIST_INSERT_DATE']].dropna()\n",
    "df3_3['HIST_INSERT_DATE'] = pd.to_datetime(df3_3['HIST_INSERT_DATE'])\n",
    "\n",
    "df3_3 = df3_3[df3_3.GOOD_IDEN_NUMB.isin(choices[0].tolist())].reset_index(drop=True)\n",
    "df3_3['WorkList'] = df3_3['WORKINFO_ID_ARR'].str.split(',')\n",
    "\n",
    "df3_4 =  df3_3.drop(['WORKINFO_ID_ARR'],axis=1).sort_values(\n",
    "    by=['GOOD_IDEN_NUMB','HIST_INSERT_DATE']).reset_index(drop=True)\n",
    "df3_4['HIST_FINISH_DATE'] = df3_4.HIST_INSERT_DATE.shift(-1)\n",
    "df3_4['GOOD_IDEN_NUMB2'] = df3_4.GOOD_IDEN_NUMB.shift(-1)\n",
    "\n",
    "df3_51 = df3_4[df3_4.GOOD_IDEN_NUMB == df3_4.GOOD_IDEN_NUMB2]\n",
    "df3_52 = df3_4[df3_4.GOOD_IDEN_NUMB !=  df3_4.GOOD_IDEN_NUMB2]\n",
    "df3_52 = df3_52.drop([\"HIST_FINISH_DATE\"],axis=1).insert(0,\"HIST_FINISH_DATE\",pd.datetime.now())\n",
    "\n",
    "df3_6 = pd.concat([df3_51,df3_52]).sort_values(\n",
    "    by=['GOOD_IDEN_NUMB','HIST_INSERT_DATE']).reset_index(drop=True)\n",
    "df3_6 = df3_6[['GOOD_IDEN_NUMB','HIST_INSERT_DATE','HIST_FINISH_DATE','WorkList']]\n",
    "\n",
    "df4 = pd.concat([\n",
    "        pd.DataFrame(sum([list(zip([ii]*len(df3_6.WorkList[ii]),df3_6.WorkList[ii])) for ii in range(\n",
    "                        df3_6.shape[0])],[])).set_index(0).rename(columns={1:'ConstructionType'}),\n",
    "        df3_6[['GOOD_IDEN_NUMB','HIST_INSERT_DATE','HIST_FINISH_DATE']]], \n",
    "          axis =1)\n",
    "\n",
    "df4_1 = df4.groupby('GOOD_IDEN_NUMB')['HIST_INSERT_DATE'].min().reset_index()\n",
    "df4_2 = pd.merge(df4_1, df4, on=['GOOD_IDEN_NUMB','HIST_INSERT_DATE'], how='left')\n",
    "init_ConstList = df4_2.groupby('ConstructionType')['GOOD_IDEN_NUMB'].apply(list).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:04:55]\n"
     ]
    }
   ],
   "source": [
    "# 오래 걸리는 전처리 부분을 multiprocessing을 통해서 빠르게 처리\n",
    "start = datetime.datetime.now()\n",
    "num_cores = multiprocessing.cpu_count()-1#한개는 남겨둠.\n",
    "num_partitions = num_cores\n",
    "df_split = np.array_split(df3[['ConstructionType','OrderTime']], num_partitions)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    with multiprocessing.Pool(num_cores) as pool:\n",
    "        func = partial(manipulation, df4, init_ConstList)\n",
    "        mapped = pool.map(func, df_split)\n",
    "        result = pd.DataFrame(pd.Series(list(chain.from_iterable(mapped))),columns =['Items'])\n",
    "result.head()\n",
    "duration = datetime.datetime.now()-start;m, s = divmod(duration.seconds, 60)\n",
    "h, m = divmod(m, 60);print(\"[%02d:%02d:%02d]\" %(h, m, s)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4_5= pd.merge(df3,result,left_index=True,right_index=True)\n",
    "df4_5['show_ProductCodes'] = pd.Series([list(set(df4_5['Items'][ii]) - set(df4_5['x_ProductCodes'][ii])) for ii in range(df4_5.shape[0])])\n",
    "df5 = df4_5.drop(['Items'], axis = 1)\n",
    "\n",
    "# x거래일자와 현재의 일자 차이 weight로 사용\n",
    "daygap = (datetime.datetime.now() - df5.OrderTime).dt.days \n",
    "df5['daygap'] = 1-((daygap-min(daygap))/(max(daygap)-min(daygap))) # 0-1 normalization\n",
    "\n",
    "df5 = df5[df5.y_ProductCodes !=\"99999999998\"].reset_index(drop=True) # Y에서 덜 구매건은 아예 제외 함\n",
    "\n",
    "##### item은 binary로 만들기.#### 추가\n",
    "df5['x_ProductCodes'] = pd.Series(Listelement_str_to_byte(df5.x_ProductCodes.tolist(), dim=2))\n",
    "df5['y_ProductCodes'] = pd.Series(Listelement_str_to_byte(df5.y_ProductCodes.tolist(), dim=1))\n",
    "df5['show_ProductCodes'] = pd.Series(Listelement_str_to_byte(df5.show_ProductCodes.tolist(), dim=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(335494, 11)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BpID</th>\n",
       "      <th>OrderTime</th>\n",
       "      <th>x_ProductCodes</th>\n",
       "      <th>d2v</th>\n",
       "      <th>y_ProductCodes</th>\n",
       "      <th>Region</th>\n",
       "      <th>ConstructionType</th>\n",
       "      <th>BpType</th>\n",
       "      <th>BpClass</th>\n",
       "      <th>show_ProductCodes</th>\n",
       "      <th>daygap</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>304576</td>\n",
       "      <td>2014-03-05 10:49:56.520</td>\n",
       "      <td>[b'99999999999', b'6601000067', b'6601000010',...</td>\n",
       "      <td>[-0.2364179939031601, -1.1428827047348022, 1.8...</td>\n",
       "      <td>b'6601000055'</td>\n",
       "      <td>12</td>\n",
       "      <td>7</td>\n",
       "      <td>정보통신서비스</td>\n",
       "      <td>서비스</td>\n",
       "      <td>[b'2900900001', b'7000200010', b'6601000076', ...</td>\n",
       "      <td>0.034444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>304576</td>\n",
       "      <td>2014-03-05 10:49:56.520</td>\n",
       "      <td>[b'99999999999', b'6601000067', b'6601000010',...</td>\n",
       "      <td>[-0.2364179939031601, -1.1428827047348022, 1.8...</td>\n",
       "      <td>b'99999999999'</td>\n",
       "      <td>12</td>\n",
       "      <td>7</td>\n",
       "      <td>정보통신서비스</td>\n",
       "      <td>서비스</td>\n",
       "      <td>[b'2900900001', b'7000200010', b'6601000076', ...</td>\n",
       "      <td>0.034444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>304576</td>\n",
       "      <td>2014-03-05 10:49:56.520</td>\n",
       "      <td>[b'99999999999', b'6601000067', b'6601000010',...</td>\n",
       "      <td>[-0.2364179939031601, -1.1428827047348022, 1.8...</td>\n",
       "      <td>b'6601000067'</td>\n",
       "      <td>12</td>\n",
       "      <td>7</td>\n",
       "      <td>정보통신서비스</td>\n",
       "      <td>서비스</td>\n",
       "      <td>[b'2900900001', b'7000200010', b'6601000076', ...</td>\n",
       "      <td>0.034444</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     BpID               OrderTime  \\\n",
       "0  304576 2014-03-05 10:49:56.520   \n",
       "1  304576 2014-03-05 10:49:56.520   \n",
       "2  304576 2014-03-05 10:49:56.520   \n",
       "\n",
       "                                      x_ProductCodes  \\\n",
       "0  [b'99999999999', b'6601000067', b'6601000010',...   \n",
       "1  [b'99999999999', b'6601000067', b'6601000010',...   \n",
       "2  [b'99999999999', b'6601000067', b'6601000010',...   \n",
       "\n",
       "                                                 d2v  y_ProductCodes Region  \\\n",
       "0  [-0.2364179939031601, -1.1428827047348022, 1.8...   b'6601000055'     12   \n",
       "1  [-0.2364179939031601, -1.1428827047348022, 1.8...  b'99999999999'     12   \n",
       "2  [-0.2364179939031601, -1.1428827047348022, 1.8...   b'6601000067'     12   \n",
       "\n",
       "  ConstructionType   BpType BpClass  \\\n",
       "0                7  정보통신서비스     서비스   \n",
       "1                7  정보통신서비스     서비스   \n",
       "2                7  정보통신서비스     서비스   \n",
       "\n",
       "                                   show_ProductCodes    daygap  \n",
       "0  [b'2900900001', b'7000200010', b'6601000076', ...  0.034444  \n",
       "1  [b'2900900001', b'7000200010', b'6601000076', ...  0.034444  \n",
       "2  [b'2900900001', b'7000200010', b'6601000076', ...  0.034444  "
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df5.shape) #(337388, 11)\n",
    "df5.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./Datasets/VocaList_181218_final.pkl','rb') as f:\n",
    "    vL = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2324"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vL['yv'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[b'10000000052' b'10000000053' b'10000000055' ... b'7400900176'\n",
      " b'7400900179' b'99999999999']\n"
     ]
    }
   ],
   "source": [
    "# vL = {\"xv\":list(set(chain.from_iterable(df5.x_ProductCodes))-{b\"99999999998\"}),\n",
    "#       \"showv\":list(set(chain.from_iterable(df5.show_ProductCodes))), # show에서는 빼지 않는다. (취지와도 안맞고 빼면 []이 됨.)\n",
    "#       \"yv\":tuple(df5.y_ProductCodes.unique())}\n",
    "\n",
    "# print(np.array(sorted(vL[\"xv\"]))) # 99999999998이 없어야 함.\n",
    "\n",
    "# with open('./Datasets/df5_tmp.pkl','wb') as f:\n",
    "#     pickle.dump(df5, f)\n",
    "# with open('./Datasets/VocaList.pkl','wb') as f:\n",
    "#     pickle.dump(vL, f)\n",
    "\n",
    "# with open('./Datasets/VocaList.pkl','rb') as f:\n",
    "#     vL = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_Example(row):\n",
    "    example= tf.train.Example(features=tf.train.Features(feature={\n",
    "        'Region':tf.train.Feature(bytes_list=tf.train.BytesList(value=[row['Region'].encode('utf-8')])),\n",
    "        'BpType':tf.train.Feature(bytes_list=tf.train.BytesList(value=[row['BpType'].encode('utf-8')])),\n",
    "        'BpClass':tf.train.Feature(bytes_list=tf.train.BytesList(value=[row['BpClass'].encode('utf-8')])),\n",
    "        'ConstructionType':tf.train.Feature(bytes_list=tf.train.BytesList(\n",
    "            value=[row['ConstructionType'].encode('utf-8')])),\n",
    "        'd2v':tf.train.Feature(float_list=tf.train.FloatList(value=row['d2v'])),\n",
    "        'daygap':tf.train.Feature(float_list=tf.train.FloatList(value=[row['daygap']])),\n",
    "        'show_ProductCodes':tf.train.Feature(bytes_list=tf.train.BytesList(value= row['show_ProductCodes'])),\n",
    "        'x_ProductCodes':tf.train.Feature(bytes_list=tf.train.BytesList(value= row['x_ProductCodes'])),\n",
    "        'y_ProductCodes':tf.train.Feature(bytes_list=tf.train.BytesList(value=[row['y_ProductCodes']]))\n",
    "    }))\n",
    "    return example\n",
    "\n",
    "def create_tfrecords_file(tf_filename= 'data.tfrecord', input_df=None):\n",
    "    writer = tf.python_io.TFRecordWriter(tf_filename)\n",
    "    print(\"Creating TFRecords file at\", tf_filename, \"...\")\n",
    "    def mk_tfrecords(row):\n",
    "        example = make_Example(row)\n",
    "        content = example.SerializeToString()\n",
    "        writer.write(content)\n",
    "        return example\n",
    "    input_df.apply(mk_tfrecords, axis=1)\n",
    "    writer.close()\n",
    "    print(\"Finish Writing\", tf_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'train': 300264, 'eval': 35230})\n",
      "Entropy of train set : [12.690]\n",
      "Entropy of eval set : [12.381]\n",
      "Creating TFRecords file at ./Datasets/train_181218_final.tfrecord ...\n",
      "Finish Writing ./Datasets/train_181218_final.tfrecord\n",
      "Creating TFRecords file at ./Datasets/eval_181218_final.tfrecord ...\n",
      "Finish Writing ./Datasets/eval_181218_final.tfrecord\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(seed=0)\n",
    "sampleidx = np.random.choice(df5[df5['OrderTime']>=\"2018-06-01\"].index,size=10000,replace=False) # size 변경 필.\n",
    "\n",
    "conditions = [(df5['OrderTime']>='2018-06-01') & (~df5.index.isin(sampleidx)),\n",
    "              (df5['OrderTime']<\"2018-06-01\") | ((df5['OrderTime']>=\"2018-06-01\") & (df5.index.isin(sampleidx)))]\n",
    "choices = ['eval','train']\n",
    "\n",
    "df5['usage'] = np.select(conditions,choices,default='none')\n",
    "print(Counter(df5['usage']))\n",
    "\n",
    "for etp in df5['usage'].unique():\n",
    "    tmp_df = df5[df5['usage']==etp]\n",
    "    tmp_p_dist = tmp_df.y_ProductCodes.value_counts()/tmp_df.shape[0]\n",
    "    print(\"Entropy of %s set : [%.3f]\"%(etp, -np.log2(tmp_p_dist).mean()))\n",
    "\n",
    "for ii in df5.usage.unique():\n",
    "    tmp_df = df5[df5.usage==ii].drop(['BpID','OrderTime','usage'],axis=1)\n",
    "    filename = './Datasets/'+ii+'_181218_final.tfrecord'\n",
    "    create_tfrecords_file(filename, tmp_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('./Datasets/test_xwd_d2v.pkl','wb') as f:\n",
    "#     pickle.dump(df5[df5.usage=='test'], f)\n",
    "with open('./Datasets/eval_181218_final.pkl','wb') as f:\n",
    "    pickle.dump(df5[df5.usage=='eval'], f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "read_f = {\n",
    "    'Region': tf.FixedLenFeature([], dtype=tf.string),\n",
    "    'BpType': tf.FixedLenFeature([], dtype=tf.string),\n",
    "    'BpClass': tf.FixedLenFeature([], dtype=tf.string),\n",
    "    'ConstructionType': tf.FixedLenFeature([], dtype=tf.string),\n",
    "    'd2v':tf.FixedLenFeature([15], dtype=tf.float32),\n",
    "    'daygap':tf.FixedLenFeature([], dtype=tf.float32),\n",
    "    'show_ProductCodes': tf.VarLenFeature(dtype=tf.string),\n",
    "    'x_ProductCodes': tf.VarLenFeature(dtype=tf.string),\n",
    "    'y_ProductCodes': tf.FixedLenFeature([], dtype=tf.string)\n",
    "}\n",
    "\n",
    "def input_fn(filename, predict=False):\n",
    "    def parser(serialized_exp):\n",
    "        columns = tf.parse_single_example(serialized=serialized_exp,features=read_f)\n",
    "        label = columns['y_ProductCodes']\n",
    "        del columns['y_ProductCodes']\n",
    "        features = columns\n",
    "        return features, label\n",
    "    dataset= tf.data.TFRecordDataset(filenames=filename)\n",
    "    if predict == False:\n",
    "        dataset = dataset.apply(tf.data.experimental.shuffle_and_repeat(buffer_size=100,count=-1))\n",
    "    dataset = dataset.apply(tf.data.experimental.map_and_batch(\n",
    "            map_func=parser, batch_size=64, num_parallel_batches = 16))\n",
    "    # BP:number of elements / batches consumed by a training step\n",
    "    dataset = dataset.cache().prefetch(buffer_size = 50) \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_input_fn():\n",
    "    return input_fn(filename='./Datasets/train_181218_final.tfrecord')\n",
    "\n",
    "def eval_input_fn():\n",
    "    return input_fn(filename='./Datasets/eval_181218_final.tfrecord')\n",
    "\n",
    "def pred_input_fn():\n",
    "    return input_fn(filename='./Datasets/eval_181218_final.tfrecord', predict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "BpClass=tf.feature_column.categorical_column_with_hash_bucket(\"BpClass\", hash_bucket_size=300)\n",
    "BpType=tf.feature_column.categorical_column_with_hash_bucket(\"BpType\", hash_bucket_size=300)\n",
    "ConstructionType=tf.feature_column.categorical_column_with_hash_bucket(\n",
    "    \"ConstructionType\", hash_bucket_size=100)\n",
    "Region=tf.feature_column.categorical_column_with_hash_bucket(\"Region\", hash_bucket_size=100)\n",
    "d2v = tf.feature_column.numeric_column('d2v',shape=[15], dtype=tf.float64)\n",
    "daygap = tf.feature_column.numeric_column('daygap',dtype=tf.float64)\n",
    "X_item = tf.feature_column.categorical_column_with_vocabulary_list(\n",
    "    key=\"x_ProductCodes\",vocabulary_list=vL[\"xv\"])\n",
    "Show_item = tf.feature_column.categorical_column_with_vocabulary_list(\n",
    "    key=\"show_ProductCodes\",vocabulary_list=vL[\"showv\"])\n",
    "\n",
    "wide_columns = [\n",
    "    X_item,\n",
    "    Show_item,\n",
    "    ConstructionType,\n",
    "    tf.feature_column.crossed_column([\"ConstructionType\", \"Region\"], hash_bucket_size=int(1e3))\n",
    "]\n",
    "deep_columns = [\n",
    "    d2v,\n",
    "    tf.feature_column.embedding_column(BpClass, dimension=16), \n",
    "    tf.feature_column.embedding_column(BpType, dimension=16), \n",
    "    tf.feature_column.embedding_column(ConstructionType, dimension=16), \n",
    "    tf.feature_column.embedding_column(Region, dimension=16)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using config: {'_num_worker_replicas': 1, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fdbfaabcc50>, '_tf_random_seed': None, '_eval_distribute': None, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_save_summary_steps': 100, '_service': None, '_evaluation_master': '', '_task_type': 'worker', '_experimental_distribute': None, '_device_fn': None, '_keep_checkpoint_max': 2, '_protocol': None, '_global_id_in_cluster': 0, '_is_chief': True, '_keep_checkpoint_every_n_hours': 10000, '_train_distribute': None, '_num_ps_replicas': 0, '_task_id': 0, '_save_checkpoints_secs': None, '_master': '', '_model_dir': './Trained_models/Models_WnD/xwd2/', '_save_checkpoints_steps': 1000, '_log_step_count_steps': 100}\n"
     ]
    }
   ],
   "source": [
    "_config = tf.estimator.RunConfig(\n",
    "    save_checkpoints_secs=None,save_checkpoints_steps=1000,keep_checkpoint_max=2)\n",
    "\n",
    "tot_model = tf.estimator.DNNLinearCombinedClassifier(\n",
    "    model_dir=\"./Trained_models/Models_WnD/xwd2/\",\n",
    "    linear_feature_columns=wide_columns,\n",
    "    dnn_feature_columns=deep_columns,\n",
    "    dnn_hidden_units=[2048,512,128],\n",
    "    dnn_dropout = 0.3,\n",
    "    n_classes = len(vL[\"yv\"]),\n",
    "    label_vocabulary= vL[\"yv\"],\n",
    "    weight_column = daygap,\n",
    "    batch_norm = True,\n",
    "    warm_start_from=\"./Trained_models/Models_WnD/xwd2/\",\n",
    "    config = _config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/util/tf_inspect.py:75: DeprecationWarning: inspect.getargspec() is deprecated, use inspect.signature() instead\n",
      "  return _inspect.getargspec(target)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Warm-starting with WarmStartSettings: WarmStartSettings(ckpt_to_initialize_from='./Trained_models/Models_WnD/xwd2/', vars_to_warm_start='.*', var_name_to_vocab_info={}, var_name_to_prev_var_name={})\n",
      "INFO:tensorflow:Warm-starting from: ('./Trained_models/Models_WnD/xwd2/',)\n",
      "INFO:tensorflow:Warm-starting variable: dnn/hiddenlayer_1/kernel; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: linear/linear_model/ConstructionType/weights; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: dnn/hiddenlayer_0/bias; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: dnn/input_from_feature_columns/input_layer/BpType_embedding/embedding_weights; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: linear/linear_model/x_ProductCodes/weights; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: dnn/hiddenlayer_2/batchnorm_2/beta; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: dnn/hiddenlayer_1/batchnorm_1/beta; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: dnn/hiddenlayer_0/batchnorm_0/beta; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: dnn/hiddenlayer_2/batchnorm_2/gamma; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: linear/linear_model/ConstructionType_X_Region/weights; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: dnn/hiddenlayer_1/batchnorm_1/gamma; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: linear/linear_model/bias_weights; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: dnn/input_from_feature_columns/input_layer/ConstructionType_embedding/embedding_weights; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: dnn/hiddenlayer_0/kernel; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: dnn/hiddenlayer_1/bias; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: dnn/hiddenlayer_0/batchnorm_0/gamma; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: dnn/logits/kernel; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: linear/linear_model/show_ProductCodes/weights; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: dnn/hiddenlayer_2/kernel; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: dnn/logits/bias; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: dnn/input_from_feature_columns/input_layer/BpClass_embedding/embedding_weights; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: dnn/hiddenlayer_2/bias; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: dnn/input_from_feature_columns/input_layer/Region_embedding/embedding_weights; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from ./Trained_models/Models_WnD/xwd2/model.ckpt-471000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 471000 into ./Trained_models/Models_WnD/xwd2/model.ckpt.\n",
      "INFO:tensorflow:loss = 57.432068, step = 471001\n",
      "INFO:tensorflow:global_step/sec: 9.30045\n",
      "INFO:tensorflow:loss = 37.695396, step = 471101 (10.757 sec)\n",
      "INFO:tensorflow:global_step/sec: 9.5918\n",
      "INFO:tensorflow:loss = 73.73013, step = 471201 (10.427 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.52479\n",
      "INFO:tensorflow:loss = 56.474525, step = 471301 (11.742 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.0976\n",
      "INFO:tensorflow:loss = 71.23065, step = 471401 (12.340 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.35178\n",
      "INFO:tensorflow:loss = 96.742195, step = 471501 (11.972 sec)\n",
      "INFO:tensorflow:global_step/sec: 9.34887\n",
      "INFO:tensorflow:loss = 142.86047, step = 471601 (10.706 sec)\n",
      "INFO:tensorflow:global_step/sec: 9.05736\n",
      "INFO:tensorflow:loss = 87.332504, step = 471701 (11.032 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.2795\n",
      "INFO:tensorflow:loss = 175.8867, step = 471801 (8.874 sec)\n",
      "INFO:tensorflow:global_step/sec: 12.9094\n",
      "INFO:tensorflow:loss = 220.64983, step = 471901 (7.738 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 472000 into ./Trained_models/Models_WnD/xwd2/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 8.45691\n",
      "INFO:tensorflow:loss = 130.1305, step = 472001 (11.819 sec)\n",
      "INFO:tensorflow:global_step/sec: 20.4676\n",
      "INFO:tensorflow:loss = 160.17592, step = 472101 (4.895 sec)\n",
      "INFO:tensorflow:global_step/sec: 17.9283\n",
      "INFO:tensorflow:loss = 187.71259, step = 472201 (5.581 sec)\n",
      "INFO:tensorflow:global_step/sec: 14.6274\n",
      "INFO:tensorflow:loss = 206.36945, step = 472301 (6.824 sec)\n",
      "INFO:tensorflow:global_step/sec: 15.2548\n",
      "INFO:tensorflow:loss = 190.87024, step = 472401 (6.559 sec)\n",
      "INFO:tensorflow:global_step/sec: 14.5437\n",
      "INFO:tensorflow:loss = 168.82379, step = 472501 (6.874 sec)\n",
      "INFO:tensorflow:global_step/sec: 12.3689\n",
      "INFO:tensorflow:loss = 126.733734, step = 472601 (8.089 sec)\n",
      "INFO:tensorflow:global_step/sec: 7.1474\n",
      "INFO:tensorflow:loss = 247.38766, step = 472701 (13.992 sec)\n",
      "INFO:tensorflow:global_step/sec: 7.49522\n",
      "INFO:tensorflow:loss = 120.18772, step = 472801 (13.344 sec)\n",
      "INFO:tensorflow:global_step/sec: 7.15019\n",
      "INFO:tensorflow:loss = 152.73868, step = 472901 (13.980 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 473000 into ./Trained_models/Models_WnD/xwd2/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 5.95079\n",
      "INFO:tensorflow:loss = 128.80984, step = 473001 (16.806 sec)\n",
      "INFO:tensorflow:global_step/sec: 7.72005\n",
      "INFO:tensorflow:loss = 140.64914, step = 473101 (12.955 sec)\n",
      "INFO:tensorflow:global_step/sec: 7.47334\n",
      "INFO:tensorflow:loss = 165.36987, step = 473201 (13.382 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.17324\n",
      "INFO:tensorflow:loss = 145.54814, step = 473301 (12.239 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.28862\n",
      "INFO:tensorflow:loss = 43.049717, step = 473401 (12.059 sec)\n",
      "INFO:tensorflow:global_step/sec: 9.13562\n",
      "INFO:tensorflow:loss = 62.075855, step = 473501 (10.945 sec)\n",
      "INFO:tensorflow:global_step/sec: 9.01231\n",
      "INFO:tensorflow:loss = 71.644455, step = 473601 (11.105 sec)\n",
      "INFO:tensorflow:global_step/sec: 9.94912\n",
      "INFO:tensorflow:loss = 121.40018, step = 473701 (10.042 sec)\n",
      "INFO:tensorflow:global_step/sec: 9.41392\n",
      "INFO:tensorflow:loss = 26.144209, step = 473801 (10.623 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.22173\n",
      "INFO:tensorflow:loss = 98.83126, step = 473901 (12.163 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 474000 into ./Trained_models/Models_WnD/xwd2/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 6.98932\n",
      "INFO:tensorflow:loss = 176.04025, step = 474001 (14.310 sec)\n",
      "INFO:tensorflow:global_step/sec: 7.75425\n",
      "INFO:tensorflow:loss = 228.04459, step = 474101 (12.890 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.52843\n",
      "INFO:tensorflow:loss = 90.89064, step = 474201 (11.732 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.9032\n",
      "INFO:tensorflow:loss = 180.82538, step = 474301 (9.168 sec)\n",
      "INFO:tensorflow:global_step/sec: 9.00983\n",
      "INFO:tensorflow:loss = 184.55286, step = 474401 (11.114 sec)\n",
      "INFO:tensorflow:global_step/sec: 7.7068\n",
      "INFO:tensorflow:loss = 40.72366, step = 474501 (12.963 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.40865\n",
      "INFO:tensorflow:loss = 123.8958, step = 474601 (11.892 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.1933\n",
      "INFO:tensorflow:loss = 190.50296, step = 474701 (9.817 sec)\n",
      "INFO:tensorflow:global_step/sec: 7.9847\n",
      "INFO:tensorflow:loss = 123.7637, step = 474801 (12.515 sec)\n",
      "INFO:tensorflow:global_step/sec: 7.87647\n",
      "INFO:tensorflow:loss = 78.029625, step = 474901 (12.697 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 475000 into ./Trained_models/Models_WnD/xwd2/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 7.45787\n",
      "INFO:tensorflow:loss = 141.82275, step = 475001 (13.406 sec)\n",
      "INFO:tensorflow:global_step/sec: 9.66111\n",
      "INFO:tensorflow:loss = 57.074318, step = 475101 (10.361 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.7446\n",
      "INFO:tensorflow:loss = 179.00885, step = 475201 (9.295 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.0863\n",
      "INFO:tensorflow:loss = 218.41382, step = 475301 (12.380 sec)\n",
      "INFO:tensorflow:global_step/sec: 9.35263\n",
      "INFO:tensorflow:loss = 132.4075, step = 475401 (10.681 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.3214\n",
      "INFO:tensorflow:loss = 94.59834, step = 475501 (8.843 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.99003\n",
      "INFO:tensorflow:loss = 116.5334, step = 475601 (11.116 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 8.37939\n",
      "INFO:tensorflow:loss = 36.34574, step = 475701 (11.933 sec)\n",
      "INFO:tensorflow:global_step/sec: 9.51285\n",
      "INFO:tensorflow:loss = 155.42328, step = 475801 (10.512 sec)\n",
      "INFO:tensorflow:global_step/sec: 9.44494\n",
      "INFO:tensorflow:loss = 94.04799, step = 475901 (10.589 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 476000 into ./Trained_models/Models_WnD/xwd2/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 6.84199\n",
      "INFO:tensorflow:loss = 152.21445, step = 476001 (14.610 sec)\n",
      "INFO:tensorflow:global_step/sec: 7.98139\n",
      "INFO:tensorflow:loss = 161.14508, step = 476101 (12.542 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.4843\n",
      "INFO:tensorflow:loss = 80.31291, step = 476201 (11.782 sec)\n",
      "INFO:tensorflow:global_step/sec: 9.77145\n",
      "INFO:tensorflow:loss = 212.03044, step = 476301 (10.227 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.90235\n",
      "INFO:tensorflow:loss = 129.65103, step = 476401 (11.236 sec)\n",
      "INFO:tensorflow:global_step/sec: 12.0773\n",
      "INFO:tensorflow:loss = 177.96786, step = 476501 (8.282 sec)\n",
      "INFO:tensorflow:global_step/sec: 13.0242\n",
      "INFO:tensorflow:loss = 202.35904, step = 476601 (7.682 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.3692\n",
      "INFO:tensorflow:loss = 110.66887, step = 476701 (8.789 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.7525\n",
      "INFO:tensorflow:loss = 89.41008, step = 476801 (4.392 sec)\n",
      "INFO:tensorflow:global_step/sec: 17.4868\n",
      "INFO:tensorflow:loss = 199.10023, step = 476901 (5.717 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 477000 into ./Trained_models/Models_WnD/xwd2/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 11.6833\n",
      "INFO:tensorflow:loss = 212.22731, step = 477001 (8.560 sec)\n",
      "INFO:tensorflow:global_step/sec: 15.8916\n",
      "INFO:tensorflow:loss = 187.85974, step = 477101 (6.296 sec)\n",
      "INFO:tensorflow:global_step/sec: 15.0293\n",
      "INFO:tensorflow:loss = 158.7822, step = 477201 (6.653 sec)\n",
      "INFO:tensorflow:global_step/sec: 12.6229\n",
      "INFO:tensorflow:loss = 55.184017, step = 477301 (7.926 sec)\n",
      "INFO:tensorflow:global_step/sec: 7.30999\n",
      "INFO:tensorflow:loss = 77.62581, step = 477401 (13.678 sec)\n",
      "INFO:tensorflow:global_step/sec: 7.50653\n",
      "INFO:tensorflow:loss = 75.34307, step = 477501 (13.321 sec)\n",
      "INFO:tensorflow:global_step/sec: 7.0226\n",
      "INFO:tensorflow:loss = 169.8601, step = 477601 (14.239 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.72812\n",
      "INFO:tensorflow:loss = 195.72136, step = 477701 (14.872 sec)\n",
      "INFO:tensorflow:global_step/sec: 7.48499\n",
      "INFO:tensorflow:loss = 98.439575, step = 477801 (13.353 sec)\n",
      "INFO:tensorflow:global_step/sec: 7.85923\n",
      "INFO:tensorflow:loss = 194.34354, step = 477901 (12.732 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 478000 into ./Trained_models/Models_WnD/xwd2/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 6.94277\n",
      "INFO:tensorflow:loss = 70.42842, step = 478001 (14.391 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.65476\n",
      "INFO:tensorflow:loss = 189.79016, step = 478101 (11.558 sec)\n",
      "INFO:tensorflow:global_step/sec: 9.62418\n",
      "INFO:tensorflow:loss = 139.26877, step = 478201 (10.394 sec)\n",
      "INFO:tensorflow:global_step/sec: 9.50779\n",
      "INFO:tensorflow:loss = 117.036026, step = 478301 (10.513 sec)\n",
      "INFO:tensorflow:global_step/sec: 9.77873\n",
      "INFO:tensorflow:loss = 224.49365, step = 478401 (10.228 sec)\n",
      "INFO:tensorflow:global_step/sec: 9.35544\n",
      "INFO:tensorflow:loss = 80.40297, step = 478501 (10.690 sec)\n",
      "INFO:tensorflow:global_step/sec: 7.54931\n",
      "INFO:tensorflow:loss = 136.43741, step = 478601 (13.246 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.44339\n",
      "INFO:tensorflow:loss = 94.98708, step = 478701 (11.844 sec)\n",
      "INFO:tensorflow:global_step/sec: 7.87054\n",
      "INFO:tensorflow:loss = 103.41734, step = 478801 (12.705 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.65814\n",
      "INFO:tensorflow:loss = 47.500237, step = 478901 (11.559 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 479000 into ./Trained_models/Models_WnD/xwd2/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 8.85743\n",
      "INFO:tensorflow:loss = 74.278015, step = 479001 (11.278 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.7081\n",
      "INFO:tensorflow:loss = 62.445656, step = 479101 (11.487 sec)\n",
      "INFO:tensorflow:global_step/sec: 7.72915\n",
      "INFO:tensorflow:loss = 124.093376, step = 479201 (12.936 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.72802\n",
      "INFO:tensorflow:loss = 213.67639, step = 479301 (11.459 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.9114\n",
      "INFO:tensorflow:loss = 68.2308, step = 479401 (9.165 sec)\n",
      "INFO:tensorflow:global_step/sec: 7.96347\n",
      "INFO:tensorflow:loss = 99.5952, step = 479501 (12.567 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.14805\n",
      "INFO:tensorflow:loss = 43.87952, step = 479601 (12.264 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.51895\n",
      "INFO:tensorflow:loss = 54.66146, step = 479701 (11.748 sec)\n",
      "INFO:tensorflow:global_step/sec: 9.8578\n",
      "INFO:tensorflow:loss = 87.01898, step = 479801 (10.136 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.3558\n",
      "INFO:tensorflow:loss = 108.85899, step = 479901 (9.656 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 480000 into ./Trained_models/Models_WnD/xwd2/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 6.76616\n",
      "INFO:tensorflow:loss = 236.32584, step = 480001 (14.778 sec)\n",
      "INFO:tensorflow:global_step/sec: 9.57618\n",
      "INFO:tensorflow:loss = 187.85983, step = 480101 (10.453 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.1315\n",
      "INFO:tensorflow:loss = 196.28687, step = 480201 (8.972 sec)\n",
      "INFO:tensorflow:global_step/sec: 9.40168\n",
      "INFO:tensorflow:loss = 149.1351, step = 480301 (10.639 sec)\n",
      "INFO:tensorflow:global_step/sec: 7.98753\n",
      "INFO:tensorflow:loss = 125.27449, step = 480401 (12.520 sec)\n",
      "INFO:tensorflow:global_step/sec: 9.80301\n",
      "INFO:tensorflow:loss = 46.19387, step = 480501 (10.200 sec)\n",
      "INFO:tensorflow:global_step/sec: 9.35906\n",
      "INFO:tensorflow:loss = 58.387188, step = 480601 (10.695 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.89301\n",
      "INFO:tensorflow:loss = 221.5709, step = 480701 (11.234 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.26105\n",
      "INFO:tensorflow:loss = 109.6886, step = 480801 (12.107 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.70974\n",
      "INFO:tensorflow:loss = 97.599365, step = 480901 (11.483 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 481000 into ./Trained_models/Models_WnD/xwd2/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 121.806366.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2018-12-19-08:10:09\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from ./Trained_models/Models_WnD/xwd2/model.ckpt-481000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [50/500]\n",
      "INFO:tensorflow:Evaluation [100/500]\n",
      "INFO:tensorflow:Evaluation [150/500]\n",
      "INFO:tensorflow:Evaluation [200/500]\n",
      "INFO:tensorflow:Evaluation [250/500]\n",
      "INFO:tensorflow:Evaluation [300/500]\n",
      "INFO:tensorflow:Evaluation [350/500]\n",
      "INFO:tensorflow:Evaluation [400/500]\n",
      "INFO:tensorflow:Evaluation [450/500]\n",
      "INFO:tensorflow:Evaluation [500/500]\n",
      "INFO:tensorflow:Finished evaluation at 2018-12-19-08:10:19\n",
      "INFO:tensorflow:Saving dict for global step 481000: accuracy = 0.06757731, average_loss = 4.746667, global_step = 481000, loss = 287.4818\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 481000: ./Trained_models/Models_WnD/xwd2/model.ckpt-481000\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Warm-starting with WarmStartSettings: WarmStartSettings(ckpt_to_initialize_from='./Trained_models/Models_WnD/xwd2/', vars_to_warm_start='.*', var_name_to_vocab_info={}, var_name_to_prev_var_name={})\n",
      "INFO:tensorflow:Warm-starting from: ('./Trained_models/Models_WnD/xwd2/',)\n",
      "INFO:tensorflow:Warm-starting variable: dnn/hiddenlayer_1/kernel; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: linear/linear_model/ConstructionType/weights; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: dnn/hiddenlayer_0/bias; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: dnn/input_from_feature_columns/input_layer/BpType_embedding/embedding_weights; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: linear/linear_model/x_ProductCodes/weights; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: dnn/hiddenlayer_2/batchnorm_2/beta; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: dnn/hiddenlayer_1/batchnorm_1/beta; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: dnn/hiddenlayer_0/batchnorm_0/beta; prev_var_name: Unchanged\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Warm-starting variable: dnn/hiddenlayer_2/batchnorm_2/gamma; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: linear/linear_model/ConstructionType_X_Region/weights; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: dnn/hiddenlayer_1/batchnorm_1/gamma; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: linear/linear_model/bias_weights; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: dnn/input_from_feature_columns/input_layer/ConstructionType_embedding/embedding_weights; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: dnn/hiddenlayer_0/kernel; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: dnn/hiddenlayer_1/bias; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: dnn/hiddenlayer_0/batchnorm_0/gamma; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: dnn/logits/kernel; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: linear/linear_model/show_ProductCodes/weights; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: dnn/hiddenlayer_2/kernel; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: dnn/logits/bias; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: dnn/input_from_feature_columns/input_layer/BpClass_embedding/embedding_weights; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: dnn/hiddenlayer_2/bias; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: dnn/input_from_feature_columns/input_layer/Region_embedding/embedding_weights; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from ./Trained_models/Models_WnD/xwd2/model.ckpt-481000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 481000 into ./Trained_models/Models_WnD/xwd2/model.ckpt.\n",
      "INFO:tensorflow:loss = 54.60704, step = 481001\n",
      "INFO:tensorflow:global_step/sec: 8.32439\n",
      "INFO:tensorflow:loss = 35.844227, step = 481101 (12.022 sec)\n",
      "INFO:tensorflow:global_step/sec: 9.63208\n",
      "INFO:tensorflow:loss = 79.44549, step = 481201 (10.384 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.38695\n",
      "INFO:tensorflow:loss = 47.85105, step = 481301 (11.919 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.09207\n",
      "INFO:tensorflow:loss = 66.90249, step = 481401 (12.359 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.36721\n",
      "INFO:tensorflow:loss = 94.82013, step = 481501 (11.949 sec)\n",
      "INFO:tensorflow:global_step/sec: 9.32883\n",
      "INFO:tensorflow:loss = 151.85342, step = 481601 (10.719 sec)\n",
      "INFO:tensorflow:global_step/sec: 9.12954\n",
      "INFO:tensorflow:loss = 88.00482, step = 481701 (10.957 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.1811\n",
      "INFO:tensorflow:loss = 177.19624, step = 481801 (8.939 sec)\n",
      "INFO:tensorflow:global_step/sec: 13.3243\n",
      "INFO:tensorflow:loss = 228.26222, step = 481901 (7.508 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 482000 into ./Trained_models/Models_WnD/xwd2/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 8.59733\n",
      "INFO:tensorflow:loss = 126.992355, step = 482001 (11.634 sec)\n",
      "INFO:tensorflow:global_step/sec: 20.9246\n",
      "INFO:tensorflow:loss = 169.60349, step = 482101 (4.772 sec)\n",
      "INFO:tensorflow:global_step/sec: 17.8342\n",
      "INFO:tensorflow:loss = 192.10245, step = 482201 (5.617 sec)\n",
      "INFO:tensorflow:global_step/sec: 15.4245\n",
      "INFO:tensorflow:loss = 205.41388, step = 482301 (6.481 sec)\n",
      "INFO:tensorflow:global_step/sec: 15.6053\n",
      "INFO:tensorflow:loss = 186.52768, step = 482401 (6.403 sec)\n",
      "INFO:tensorflow:global_step/sec: 15.6703\n",
      "INFO:tensorflow:loss = 165.72633, step = 482501 (6.384 sec)\n",
      "INFO:tensorflow:global_step/sec: 12.9068\n",
      "INFO:tensorflow:loss = 129.73428, step = 482601 (7.757 sec)\n",
      "INFO:tensorflow:global_step/sec: 7.18844\n",
      "INFO:tensorflow:loss = 247.20078, step = 482701 (13.900 sec)\n",
      "INFO:tensorflow:global_step/sec: 7.72704\n",
      "INFO:tensorflow:loss = 114.97465, step = 482801 (12.954 sec)\n",
      "INFO:tensorflow:global_step/sec: 7.13647\n",
      "INFO:tensorflow:loss = 153.30923, step = 482901 (14.000 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 483000 into ./Trained_models/Models_WnD/xwd2/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 5.83916\n",
      "INFO:tensorflow:loss = 130.26779, step = 483001 (17.124 sec)\n",
      "INFO:tensorflow:global_step/sec: 7.7325\n",
      "INFO:tensorflow:loss = 142.42433, step = 483101 (12.934 sec)\n",
      "INFO:tensorflow:global_step/sec: 7.23658\n",
      "INFO:tensorflow:loss = 171.93509, step = 483201 (13.820 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.13654\n",
      "INFO:tensorflow:loss = 151.18222, step = 483301 (12.303 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.57875\n",
      "INFO:tensorflow:loss = 48.476845, step = 483401 (11.646 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.99979\n",
      "INFO:tensorflow:loss = 59.081657, step = 483501 (11.111 sec)\n",
      "INFO:tensorflow:global_step/sec: 9.44661\n",
      "INFO:tensorflow:loss = 82.8473, step = 483601 (10.586 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.4493\n",
      "INFO:tensorflow:loss = 131.39561, step = 483701 (9.565 sec)\n",
      "INFO:tensorflow:global_step/sec: 9.45475\n",
      "INFO:tensorflow:loss = 25.111362, step = 483801 (10.579 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.14631\n",
      "INFO:tensorflow:loss = 98.1935, step = 483901 (12.276 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 484000 into ./Trained_models/Models_WnD/xwd2/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 6.94423\n",
      "INFO:tensorflow:loss = 181.65433, step = 484001 (14.396 sec)\n",
      "INFO:tensorflow:global_step/sec: 7.55113\n",
      "INFO:tensorflow:loss = 241.37805, step = 484101 (13.244 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.18613\n",
      "INFO:tensorflow:loss = 81.34037, step = 484201 (12.220 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.739\n",
      "INFO:tensorflow:loss = 154.3927, step = 484301 (9.308 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.81102\n",
      "INFO:tensorflow:loss = 183.36816, step = 484401 (11.361 sec)\n",
      "INFO:tensorflow:global_step/sec: 7.65246\n",
      "INFO:tensorflow:loss = 55.13658, step = 484501 (13.059 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.4199\n",
      "INFO:tensorflow:loss = 133.1838, step = 484601 (11.877 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.3355\n",
      "INFO:tensorflow:loss = 179.87167, step = 484701 (9.671 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.17178\n",
      "INFO:tensorflow:loss = 111.251205, step = 484801 (12.242 sec)\n",
      "INFO:tensorflow:global_step/sec: 7.96638\n",
      "INFO:tensorflow:loss = 77.88895, step = 484901 (12.563 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 485000 into ./Trained_models/Models_WnD/xwd2/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 7.59524\n",
      "INFO:tensorflow:loss = 136.86336, step = 485001 (13.151 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.2072\n",
      "INFO:tensorflow:loss = 48.4741, step = 485101 (9.801 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.7219\n",
      "INFO:tensorflow:loss = 168.19888, step = 485201 (9.325 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.063\n",
      "INFO:tensorflow:loss = 218.68779, step = 485301 (12.404 sec)\n",
      "INFO:tensorflow:global_step/sec: 9.42668\n",
      "INFO:tensorflow:loss = 128.74335, step = 485401 (10.606 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.2966\n",
      "INFO:tensorflow:loss = 96.24356, step = 485501 (8.864 sec)\n",
      "INFO:tensorflow:global_step/sec: 9.06377\n",
      "INFO:tensorflow:loss = 121.966934, step = 485601 (11.023 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.30894\n",
      "INFO:tensorflow:loss = 34.906334, step = 485701 (12.034 sec)\n",
      "INFO:tensorflow:global_step/sec: 9.58738\n",
      "INFO:tensorflow:loss = 163.95755, step = 485801 (10.440 sec)\n",
      "INFO:tensorflow:global_step/sec: 9.57987\n",
      "INFO:tensorflow:loss = 80.46793, step = 485901 (10.431 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 486000 into ./Trained_models/Models_WnD/xwd2/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 6.86549\n",
      "INFO:tensorflow:loss = 145.97029, step = 486001 (14.560 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.21565\n",
      "INFO:tensorflow:loss = 158.52293, step = 486101 (12.176 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.58723\n",
      "INFO:tensorflow:loss = 79.44333, step = 486201 (11.648 sec)\n",
      "INFO:tensorflow:global_step/sec: 9.75588\n",
      "INFO:tensorflow:loss = 202.00803, step = 486301 (10.245 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.71445\n",
      "INFO:tensorflow:loss = 133.74109, step = 486401 (11.479 sec)\n",
      "INFO:tensorflow:global_step/sec: 12.5105\n",
      "INFO:tensorflow:loss = 166.26744, step = 486501 (7.987 sec)\n",
      "INFO:tensorflow:global_step/sec: 13.3506\n",
      "INFO:tensorflow:loss = 204.7128, step = 486601 (7.495 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.6025\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 103.151566, step = 486701 (8.627 sec)\n",
      "INFO:tensorflow:global_step/sec: 24.148\n",
      "INFO:tensorflow:loss = 87.92922, step = 486801 (4.135 sec)\n",
      "INFO:tensorflow:global_step/sec: 17.3551\n",
      "INFO:tensorflow:loss = 195.93466, step = 486901 (5.757 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 487000 into ./Trained_models/Models_WnD/xwd2/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 11.6365\n",
      "INFO:tensorflow:loss = 203.7011, step = 487001 (8.593 sec)\n",
      "INFO:tensorflow:global_step/sec: 15.9943\n",
      "INFO:tensorflow:loss = 195.7439, step = 487101 (6.253 sec)\n",
      "INFO:tensorflow:global_step/sec: 15.0332\n",
      "INFO:tensorflow:loss = 158.59024, step = 487201 (6.656 sec)\n",
      "INFO:tensorflow:global_step/sec: 13.089\n",
      "INFO:tensorflow:loss = 61.29579, step = 487301 (7.634 sec)\n",
      "INFO:tensorflow:global_step/sec: 7.14752\n",
      "INFO:tensorflow:loss = 65.636826, step = 487401 (13.997 sec)\n",
      "INFO:tensorflow:global_step/sec: 7.575\n",
      "INFO:tensorflow:loss = 75.00537, step = 487501 (13.199 sec)\n",
      "INFO:tensorflow:global_step/sec: 7.5568\n",
      "INFO:tensorflow:loss = 170.88701, step = 487601 (13.233 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.78009\n",
      "INFO:tensorflow:loss = 194.29413, step = 487701 (14.750 sec)\n",
      "INFO:tensorflow:global_step/sec: 7.47653\n",
      "INFO:tensorflow:loss = 93.39189, step = 487801 (13.382 sec)\n",
      "INFO:tensorflow:global_step/sec: 7.90058\n",
      "INFO:tensorflow:loss = 198.33778, step = 487901 (12.657 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 488000 into ./Trained_models/Models_WnD/xwd2/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 7.05915\n",
      "INFO:tensorflow:loss = 76.15328, step = 488001 (14.156 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.79681\n",
      "INFO:tensorflow:loss = 190.96202, step = 488101 (11.373 sec)\n",
      "INFO:tensorflow:global_step/sec: 9.64183\n",
      "INFO:tensorflow:loss = 142.43411, step = 488201 (10.369 sec)\n",
      "INFO:tensorflow:global_step/sec: 9.47344\n",
      "INFO:tensorflow:loss = 114.84265, step = 488301 (10.559 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.3209\n",
      "INFO:tensorflow:loss = 218.42, step = 488401 (9.685 sec)\n",
      "INFO:tensorflow:global_step/sec: 9.67567\n",
      "INFO:tensorflow:loss = 84.033424, step = 488501 (10.338 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.01074\n",
      "INFO:tensorflow:loss = 141.3067, step = 488601 (12.484 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.48794\n",
      "INFO:tensorflow:loss = 85.04169, step = 488701 (11.792 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.13926\n",
      "INFO:tensorflow:loss = 100.46017, step = 488801 (12.277 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.43238\n",
      "INFO:tensorflow:loss = 50.177284, step = 488901 (11.857 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 489000 into ./Trained_models/Models_WnD/xwd2/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 9.10554\n",
      "INFO:tensorflow:loss = 73.67986, step = 489001 (10.978 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.81755\n",
      "INFO:tensorflow:loss = 66.59158, step = 489101 (11.346 sec)\n",
      "INFO:tensorflow:global_step/sec: 7.7016\n",
      "INFO:tensorflow:loss = 120.35324, step = 489201 (12.986 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.72457\n",
      "INFO:tensorflow:loss = 220.24564, step = 489301 (11.456 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.368\n",
      "INFO:tensorflow:loss = 71.66223, step = 489401 (9.648 sec)\n",
      "INFO:tensorflow:global_step/sec: 7.97296\n",
      "INFO:tensorflow:loss = 95.87124, step = 489501 (12.542 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.39313\n",
      "INFO:tensorflow:loss = 52.986687, step = 489601 (11.915 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.96043\n",
      "INFO:tensorflow:loss = 56.291283, step = 489701 (11.160 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.2095\n",
      "INFO:tensorflow:loss = 84.64832, step = 489801 (9.794 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.5659\n",
      "INFO:tensorflow:loss = 113.97081, step = 489901 (9.474 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 490000 into ./Trained_models/Models_WnD/xwd2/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 6.85192\n",
      "INFO:tensorflow:loss = 233.49818, step = 490001 (14.581 sec)\n",
      "INFO:tensorflow:global_step/sec: 9.96838\n",
      "INFO:tensorflow:loss = 183.39369, step = 490101 (10.043 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.3106\n",
      "INFO:tensorflow:loss = 195.45541, step = 490201 (8.831 sec)\n",
      "INFO:tensorflow:global_step/sec: 9.11807\n",
      "INFO:tensorflow:loss = 137.60426, step = 490301 (10.982 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.06458\n",
      "INFO:tensorflow:loss = 118.739716, step = 490401 (12.388 sec)\n",
      "INFO:tensorflow:global_step/sec: 9.74859\n",
      "INFO:tensorflow:loss = 45.359474, step = 490501 (10.255 sec)\n",
      "INFO:tensorflow:global_step/sec: 9.29753\n",
      "INFO:tensorflow:loss = 64.51744, step = 490601 (10.763 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.87765\n",
      "INFO:tensorflow:loss = 226.01962, step = 490701 (11.258 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.33316\n",
      "INFO:tensorflow:loss = 101.440186, step = 490801 (12.002 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.65513\n",
      "INFO:tensorflow:loss = 92.464645, step = 490901 (11.554 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 491000 into ./Trained_models/Models_WnD/xwd2/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 114.66461.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2018-12-19-08:29:00\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from ./Trained_models/Models_WnD/xwd2/model.ckpt-491000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [50/500]\n",
      "INFO:tensorflow:Evaluation [100/500]\n",
      "INFO:tensorflow:Evaluation [150/500]\n",
      "INFO:tensorflow:Evaluation [200/500]\n",
      "INFO:tensorflow:Evaluation [250/500]\n",
      "INFO:tensorflow:Evaluation [300/500]\n",
      "INFO:tensorflow:Evaluation [350/500]\n",
      "INFO:tensorflow:Evaluation [400/500]\n",
      "INFO:tensorflow:Evaluation [450/500]\n",
      "INFO:tensorflow:Evaluation [500/500]\n",
      "INFO:tensorflow:Finished evaluation at 2018-12-19-08:29:10\n",
      "INFO:tensorflow:Saving dict for global step 491000: accuracy = 0.06766528, average_loss = 4.7516584, global_step = 491000, loss = 287.78244\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 491000: ./Trained_models/Models_WnD/xwd2/model.ckpt-491000\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Warm-starting with WarmStartSettings: WarmStartSettings(ckpt_to_initialize_from='./Trained_models/Models_WnD/xwd2/', vars_to_warm_start='.*', var_name_to_vocab_info={}, var_name_to_prev_var_name={})\n",
      "INFO:tensorflow:Warm-starting from: ('./Trained_models/Models_WnD/xwd2/',)\n",
      "INFO:tensorflow:Warm-starting variable: dnn/hiddenlayer_1/kernel; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: linear/linear_model/ConstructionType/weights; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: dnn/hiddenlayer_0/bias; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: dnn/input_from_feature_columns/input_layer/BpType_embedding/embedding_weights; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: linear/linear_model/x_ProductCodes/weights; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: dnn/hiddenlayer_2/batchnorm_2/beta; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: dnn/hiddenlayer_1/batchnorm_1/beta; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: dnn/hiddenlayer_0/batchnorm_0/beta; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: dnn/hiddenlayer_2/batchnorm_2/gamma; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: linear/linear_model/ConstructionType_X_Region/weights; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: dnn/hiddenlayer_1/batchnorm_1/gamma; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: linear/linear_model/bias_weights; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: dnn/input_from_feature_columns/input_layer/ConstructionType_embedding/embedding_weights; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: dnn/hiddenlayer_0/kernel; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: dnn/hiddenlayer_1/bias; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: dnn/hiddenlayer_0/batchnorm_0/gamma; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: dnn/logits/kernel; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: linear/linear_model/show_ProductCodes/weights; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: dnn/hiddenlayer_2/kernel; prev_var_name: Unchanged\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Warm-starting variable: dnn/logits/bias; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: dnn/input_from_feature_columns/input_layer/BpClass_embedding/embedding_weights; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: dnn/hiddenlayer_2/bias; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: dnn/input_from_feature_columns/input_layer/Region_embedding/embedding_weights; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from ./Trained_models/Models_WnD/xwd2/model.ckpt-491000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 491000 into ./Trained_models/Models_WnD/xwd2/model.ckpt.\n",
      "INFO:tensorflow:loss = 65.76087, step = 491001\n",
      "INFO:tensorflow:global_step/sec: 8.87821\n",
      "INFO:tensorflow:loss = 37.21707, step = 491101 (11.270 sec)\n",
      "INFO:tensorflow:global_step/sec: 9.42525\n",
      "INFO:tensorflow:loss = 83.30576, step = 491201 (10.616 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.90971\n",
      "INFO:tensorflow:loss = 59.60591, step = 491301 (11.219 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.19456\n",
      "INFO:tensorflow:loss = 70.12239, step = 491401 (12.201 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.89882\n",
      "INFO:tensorflow:loss = 97.293655, step = 491501 (11.235 sec)\n",
      "INFO:tensorflow:global_step/sec: 9.7017\n",
      "INFO:tensorflow:loss = 148.54012, step = 491601 (10.307 sec)\n",
      "INFO:tensorflow:global_step/sec: 9.25924\n",
      "INFO:tensorflow:loss = 85.32214, step = 491701 (10.804 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.9206\n",
      "INFO:tensorflow:loss = 166.67891, step = 491801 (8.387 sec)\n",
      "INFO:tensorflow:global_step/sec: 13.1175\n",
      "INFO:tensorflow:loss = 220.06372, step = 491901 (7.621 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 492000 into ./Trained_models/Models_WnD/xwd2/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 8.72384\n",
      "INFO:tensorflow:loss = 103.4778, step = 492001 (11.461 sec)\n",
      "INFO:tensorflow:global_step/sec: 20.8081\n",
      "INFO:tensorflow:loss = 143.56384, step = 492101 (4.812 sec)\n",
      "INFO:tensorflow:global_step/sec: 18.4495\n",
      "INFO:tensorflow:loss = 198.37016, step = 492201 (5.415 sec)\n",
      "INFO:tensorflow:global_step/sec: 15.734\n",
      "INFO:tensorflow:loss = 208.13095, step = 492301 (6.371 sec)\n",
      "INFO:tensorflow:global_step/sec: 16.01\n",
      "INFO:tensorflow:loss = 189.61879, step = 492401 (6.230 sec)\n",
      "INFO:tensorflow:global_step/sec: 15.6194\n",
      "INFO:tensorflow:loss = 155.2373, step = 492501 (6.407 sec)\n",
      "INFO:tensorflow:global_step/sec: 13.2748\n",
      "INFO:tensorflow:loss = 125.7148, step = 492601 (7.543 sec)\n",
      "INFO:tensorflow:global_step/sec: 7.35678\n",
      "INFO:tensorflow:loss = 238.56723, step = 492701 (13.584 sec)\n",
      "INFO:tensorflow:global_step/sec: 7.33239\n",
      "INFO:tensorflow:loss = 120.04706, step = 492801 (13.638 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.78561\n",
      "INFO:tensorflow:loss = 150.74554, step = 492901 (14.744 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 493000 into ./Trained_models/Models_WnD/xwd2/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 5.67502\n",
      "INFO:tensorflow:loss = 121.460205, step = 493001 (17.610 sec)\n",
      "INFO:tensorflow:global_step/sec: 7.28027\n",
      "INFO:tensorflow:loss = 145.81493, step = 493101 (13.738 sec)\n",
      "INFO:tensorflow:global_step/sec: 7.4798\n",
      "INFO:tensorflow:loss = 158.25255, step = 493201 (13.369 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.07714\n",
      "INFO:tensorflow:loss = 145.25635, step = 493301 (12.383 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.5209\n",
      "INFO:tensorflow:loss = 52.955624, step = 493401 (11.748 sec)\n",
      "INFO:tensorflow:global_step/sec: 9.02618\n",
      "INFO:tensorflow:loss = 56.36617, step = 493501 (11.066 sec)\n",
      "INFO:tensorflow:global_step/sec: 9.10986\n",
      "INFO:tensorflow:loss = 94.570435, step = 493601 (10.984 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.634\n",
      "INFO:tensorflow:loss = 131.60712, step = 493701 (9.395 sec)\n",
      "INFO:tensorflow:global_step/sec: 9.1855\n",
      "INFO:tensorflow:loss = 41.500343, step = 493801 (10.889 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.20288\n",
      "INFO:tensorflow:loss = 97.56649, step = 493901 (12.192 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 494000 into ./Trained_models/Models_WnD/xwd2/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 6.8892\n",
      "INFO:tensorflow:loss = 171.93121, step = 494001 (14.510 sec)\n",
      "INFO:tensorflow:global_step/sec: 7.87621\n",
      "INFO:tensorflow:loss = 220.12152, step = 494101 (12.705 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.57916\n",
      "INFO:tensorflow:loss = 75.28606, step = 494201 (11.653 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.38\n",
      "INFO:tensorflow:loss = 187.82613, step = 494301 (8.785 sec)\n",
      "INFO:tensorflow:global_step/sec: 9.36332\n",
      "INFO:tensorflow:loss = 183.50781, step = 494401 (10.680 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.12826\n",
      "INFO:tensorflow:loss = 47.071068, step = 494501 (12.315 sec)\n",
      "INFO:tensorflow:global_step/sec: 9.03108\n",
      "INFO:tensorflow:loss = 120.175064, step = 494601 (11.069 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.9177\n",
      "INFO:tensorflow:loss = 185.06384, step = 494701 (9.152 sec)\n",
      "INFO:tensorflow:global_step/sec: 9.2108\n",
      "INFO:tensorflow:loss = 139.21634, step = 494801 (10.853 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.35432\n",
      "INFO:tensorflow:loss = 84.62907, step = 494901 (11.973 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 495000 into ./Trained_models/Models_WnD/xwd2/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 7.29659\n",
      "INFO:tensorflow:loss = 139.26799, step = 495001 (13.701 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.3009\n",
      "INFO:tensorflow:loss = 52.419937, step = 495101 (9.714 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.4958\n",
      "INFO:tensorflow:loss = 173.05061, step = 495201 (8.698 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.4758\n",
      "INFO:tensorflow:loss = 223.5467, step = 495301 (11.797 sec)\n",
      "INFO:tensorflow:global_step/sec: 9.68844\n",
      "INFO:tensorflow:loss = 129.03911, step = 495401 (10.322 sec)\n",
      "INFO:tensorflow:global_step/sec: 12.1759\n",
      "INFO:tensorflow:loss = 97.91443, step = 495501 (8.213 sec)\n",
      "INFO:tensorflow:global_step/sec: 9.61921\n",
      "INFO:tensorflow:loss = 118.71709, step = 495601 (10.404 sec)\n",
      "INFO:tensorflow:global_step/sec: 9.11501\n",
      "INFO:tensorflow:loss = 34.923035, step = 495701 (10.973 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.2975\n",
      "INFO:tensorflow:loss = 159.67227, step = 495801 (9.703 sec)\n",
      "INFO:tensorflow:global_step/sec: 9.94483\n",
      "INFO:tensorflow:loss = 89.88672, step = 495901 (10.055 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 496000 into ./Trained_models/Models_WnD/xwd2/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 7.5818\n",
      "INFO:tensorflow:loss = 151.11652, step = 496001 (13.185 sec)\n",
      "INFO:tensorflow:global_step/sec: 9.00049\n",
      "INFO:tensorflow:loss = 168.48422, step = 496101 (11.113 sec)\n",
      "INFO:tensorflow:global_step/sec: 9.15041\n",
      "INFO:tensorflow:loss = 74.495285, step = 496201 (10.932 sec)\n",
      "INFO:tensorflow:global_step/sec: 9.92932\n",
      "INFO:tensorflow:loss = 201.34155, step = 496301 (10.067 sec)\n",
      "INFO:tensorflow:global_step/sec: 9.58696\n",
      "INFO:tensorflow:loss = 137.57932, step = 496401 (10.435 sec)\n",
      "INFO:tensorflow:global_step/sec: 13.4252\n",
      "INFO:tensorflow:loss = 162.57811, step = 496501 (7.441 sec)\n",
      "INFO:tensorflow:global_step/sec: 14.0029\n",
      "INFO:tensorflow:loss = 207.06763, step = 496601 (7.148 sec)\n",
      "INFO:tensorflow:global_step/sec: 12.2332\n",
      "INFO:tensorflow:loss = 105.83866, step = 496701 (8.172 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.2172\n",
      "INFO:tensorflow:loss = 84.643814, step = 496801 (3.961 sec)\n",
      "INFO:tensorflow:global_step/sec: 18.516\n",
      "INFO:tensorflow:loss = 186.76242, step = 496901 (5.407 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 497000 into ./Trained_models/Models_WnD/xwd2/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 11.8539\n",
      "INFO:tensorflow:loss = 200.61774, step = 497001 (8.430 sec)\n",
      "INFO:tensorflow:global_step/sec: 16.8525\n",
      "INFO:tensorflow:loss = 197.76868, step = 497101 (5.941 sec)\n",
      "INFO:tensorflow:global_step/sec: 16.2335\n",
      "INFO:tensorflow:loss = 157.27736, step = 497201 (6.159 sec)\n",
      "INFO:tensorflow:global_step/sec: 13.8457\n",
      "INFO:tensorflow:loss = 53.690994, step = 497301 (7.221 sec)\n",
      "INFO:tensorflow:global_step/sec: 7.50236\n",
      "INFO:tensorflow:loss = 70.69267, step = 497401 (13.330 sec)\n",
      "INFO:tensorflow:global_step/sec: 7.44458\n",
      "INFO:tensorflow:loss = 71.58464, step = 497501 (13.443 sec)\n",
      "INFO:tensorflow:global_step/sec: 7.56548\n",
      "INFO:tensorflow:loss = 174.11823, step = 497601 (13.207 sec)\n",
      "INFO:tensorflow:global_step/sec: 7.27274\n",
      "INFO:tensorflow:loss = 192.96394, step = 497701 (13.753 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 8.23331\n",
      "INFO:tensorflow:loss = 93.58241, step = 497801 (12.145 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.29093\n",
      "INFO:tensorflow:loss = 198.85219, step = 497901 (12.061 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 498000 into ./Trained_models/Models_WnD/xwd2/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 7.19366\n",
      "INFO:tensorflow:loss = 83.065475, step = 498001 (13.896 sec)\n",
      "INFO:tensorflow:global_step/sec: 9.06512\n",
      "INFO:tensorflow:loss = 189.79453, step = 498101 (11.035 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.2606\n",
      "INFO:tensorflow:loss = 123.04342, step = 498201 (9.754 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.235\n",
      "INFO:tensorflow:loss = 120.75604, step = 498301 (9.767 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.6089\n",
      "INFO:tensorflow:loss = 222.1394, step = 498401 (9.423 sec)\n",
      "INFO:tensorflow:global_step/sec: 9.74817\n",
      "INFO:tensorflow:loss = 83.89989, step = 498501 (10.266 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.0445\n",
      "INFO:tensorflow:loss = 131.24237, step = 498601 (12.422 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.6477\n",
      "INFO:tensorflow:loss = 77.43802, step = 498701 (11.562 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.2462\n",
      "INFO:tensorflow:loss = 101.735504, step = 498801 (12.128 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.50078\n",
      "INFO:tensorflow:loss = 46.31436, step = 498901 (11.767 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 499000 into ./Trained_models/Models_WnD/xwd2/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 9.06381\n",
      "INFO:tensorflow:loss = 76.35008, step = 499001 (11.026 sec)\n",
      "INFO:tensorflow:global_step/sec: 9.04229\n",
      "INFO:tensorflow:loss = 54.33985, step = 499101 (11.076 sec)\n",
      "INFO:tensorflow:global_step/sec: 7.56647\n",
      "INFO:tensorflow:loss = 118.61186, step = 499201 (13.206 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.90742\n",
      "INFO:tensorflow:loss = 215.71289, step = 499301 (11.228 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.2247\n",
      "INFO:tensorflow:loss = 70.63097, step = 499401 (8.905 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.09571\n",
      "INFO:tensorflow:loss = 98.15281, step = 499501 (12.352 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.31476\n",
      "INFO:tensorflow:loss = 44.57628, step = 499601 (12.026 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.87367\n",
      "INFO:tensorflow:loss = 53.925697, step = 499701 (11.270 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.6095\n",
      "INFO:tensorflow:loss = 83.64249, step = 499801 (9.426 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.5092\n",
      "INFO:tensorflow:loss = 114.715164, step = 499901 (9.521 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 500000 into ./Trained_models/Models_WnD/xwd2/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 6.99994\n",
      "INFO:tensorflow:loss = 228.42216, step = 500001 (14.274 sec)\n",
      "INFO:tensorflow:global_step/sec: 9.33939\n",
      "INFO:tensorflow:loss = 184.95236, step = 500101 (10.715 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.0213\n",
      "INFO:tensorflow:loss = 201.24931, step = 500201 (9.069 sec)\n",
      "INFO:tensorflow:global_step/sec: 9.13316\n",
      "INFO:tensorflow:loss = 133.41936, step = 500301 (10.952 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.08547\n",
      "INFO:tensorflow:loss = 121.78375, step = 500401 (12.375 sec)\n",
      "INFO:tensorflow:global_step/sec: 9.66818\n",
      "INFO:tensorflow:loss = 29.72057, step = 500501 (10.336 sec)\n",
      "INFO:tensorflow:global_step/sec: 9.37814\n",
      "INFO:tensorflow:loss = 66.5661, step = 500601 (10.662 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.82207\n",
      "INFO:tensorflow:loss = 227.96696, step = 500701 (11.335 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.09496\n",
      "INFO:tensorflow:loss = 108.43992, step = 500801 (12.363 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.72999\n",
      "INFO:tensorflow:loss = 97.549194, step = 500901 (11.446 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 501000 into ./Trained_models/Models_WnD/xwd2/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 124.31213.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2018-12-19-08:47:26\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from ./Trained_models/Models_WnD/xwd2/model.ckpt-501000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [50/500]\n",
      "INFO:tensorflow:Evaluation [100/500]\n",
      "INFO:tensorflow:Evaluation [150/500]\n",
      "INFO:tensorflow:Evaluation [200/500]\n",
      "INFO:tensorflow:Evaluation [250/500]\n",
      "INFO:tensorflow:Evaluation [300/500]\n",
      "INFO:tensorflow:Evaluation [350/500]\n",
      "INFO:tensorflow:Evaluation [400/500]\n",
      "INFO:tensorflow:Evaluation [450/500]\n",
      "INFO:tensorflow:Evaluation [500/500]\n",
      "INFO:tensorflow:Finished evaluation at 2018-12-19-08:47:36\n",
      "INFO:tensorflow:Saving dict for global step 501000: accuracy = 0.06757133, average_loss = 4.7543387, global_step = 501000, loss = 287.9452\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 501000: ./Trained_models/Models_WnD/xwd2/model.ckpt-501000\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Warm-starting with WarmStartSettings: WarmStartSettings(ckpt_to_initialize_from='./Trained_models/Models_WnD/xwd2/', vars_to_warm_start='.*', var_name_to_vocab_info={}, var_name_to_prev_var_name={})\n",
      "INFO:tensorflow:Warm-starting from: ('./Trained_models/Models_WnD/xwd2/',)\n",
      "INFO:tensorflow:Warm-starting variable: dnn/hiddenlayer_1/kernel; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: linear/linear_model/ConstructionType/weights; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: dnn/hiddenlayer_0/bias; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: dnn/input_from_feature_columns/input_layer/BpType_embedding/embedding_weights; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: linear/linear_model/x_ProductCodes/weights; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: dnn/hiddenlayer_2/batchnorm_2/beta; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: dnn/hiddenlayer_1/batchnorm_1/beta; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: dnn/hiddenlayer_0/batchnorm_0/beta; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: dnn/hiddenlayer_2/batchnorm_2/gamma; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: linear/linear_model/ConstructionType_X_Region/weights; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: dnn/hiddenlayer_1/batchnorm_1/gamma; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: linear/linear_model/bias_weights; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: dnn/input_from_feature_columns/input_layer/ConstructionType_embedding/embedding_weights; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: dnn/hiddenlayer_0/kernel; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: dnn/hiddenlayer_1/bias; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: dnn/hiddenlayer_0/batchnorm_0/gamma; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: dnn/logits/kernel; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: linear/linear_model/show_ProductCodes/weights; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: dnn/hiddenlayer_2/kernel; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: dnn/logits/bias; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: dnn/input_from_feature_columns/input_layer/BpClass_embedding/embedding_weights; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: dnn/hiddenlayer_2/bias; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: dnn/input_from_feature_columns/input_layer/Region_embedding/embedding_weights; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from ./Trained_models/Models_WnD/xwd2/model.ckpt-501000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 501000 into ./Trained_models/Models_WnD/xwd2/model.ckpt.\n",
      "INFO:tensorflow:loss = 56.25026, step = 501001\n",
      "INFO:tensorflow:global_step/sec: 8.62617\n",
      "INFO:tensorflow:loss = 41.206802, step = 501101 (11.602 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.2427\n",
      "INFO:tensorflow:loss = 85.83974, step = 501201 (9.770 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.81961\n",
      "INFO:tensorflow:loss = 52.83613, step = 501301 (11.330 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 8.28542\n",
      "INFO:tensorflow:loss = 72.55939, step = 501401 (12.070 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.77739\n",
      "INFO:tensorflow:loss = 110.806244, step = 501501 (11.390 sec)\n",
      "INFO:tensorflow:global_step/sec: 9.73742\n",
      "INFO:tensorflow:loss = 150.6163, step = 501601 (10.268 sec)\n",
      "INFO:tensorflow:global_step/sec: 9.38992\n",
      "INFO:tensorflow:loss = 89.507706, step = 501701 (10.654 sec)\n",
      "INFO:tensorflow:global_step/sec: 12.0486\n",
      "INFO:tensorflow:loss = 173.87512, step = 501801 (8.295 sec)\n",
      "INFO:tensorflow:global_step/sec: 13.8664\n",
      "INFO:tensorflow:loss = 223.02852, step = 501901 (7.213 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 502000 into ./Trained_models/Models_WnD/xwd2/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 8.79338\n",
      "INFO:tensorflow:loss = 115.85833, step = 502001 (11.371 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.5998\n",
      "INFO:tensorflow:loss = 163.80069, step = 502101 (4.631 sec)\n",
      "INFO:tensorflow:global_step/sec: 18.4246\n",
      "INFO:tensorflow:loss = 194.97575, step = 502201 (5.427 sec)\n",
      "INFO:tensorflow:global_step/sec: 15.5587\n",
      "INFO:tensorflow:loss = 197.37473, step = 502301 (6.431 sec)\n",
      "INFO:tensorflow:global_step/sec: 15.7701\n",
      "INFO:tensorflow:loss = 180.45905, step = 502401 (6.338 sec)\n",
      "INFO:tensorflow:global_step/sec: 16.0063\n",
      "INFO:tensorflow:loss = 155.79622, step = 502501 (6.248 sec)\n",
      "INFO:tensorflow:global_step/sec: 13.1284\n",
      "INFO:tensorflow:loss = 141.12343, step = 502601 (7.619 sec)\n",
      "INFO:tensorflow:global_step/sec: 7.47911\n",
      "INFO:tensorflow:loss = 241.1223, step = 502701 (13.380 sec)\n",
      "INFO:tensorflow:global_step/sec: 7.51471\n",
      "INFO:tensorflow:loss = 129.66788, step = 502801 (13.299 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.86136\n",
      "INFO:tensorflow:loss = 144.33661, step = 502901 (14.576 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 503000 into ./Trained_models/Models_WnD/xwd2/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 5.93285\n",
      "INFO:tensorflow:loss = 121.140686, step = 503001 (16.849 sec)\n",
      "INFO:tensorflow:global_step/sec: 7.54681\n",
      "INFO:tensorflow:loss = 135.61249, step = 503101 (13.256 sec)\n",
      "INFO:tensorflow:global_step/sec: 7.53202\n",
      "INFO:tensorflow:loss = 164.54758, step = 503201 (13.277 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.31187\n",
      "INFO:tensorflow:loss = 148.6718, step = 503301 (12.031 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.75606\n",
      "INFO:tensorflow:loss = 40.217087, step = 503401 (11.428 sec)\n",
      "INFO:tensorflow:global_step/sec: 9.36881\n",
      "INFO:tensorflow:loss = 54.758263, step = 503501 (10.665 sec)\n",
      "INFO:tensorflow:global_step/sec: 9.34227\n",
      "INFO:tensorflow:loss = 86.31665, step = 503601 (10.707 sec)\n",
      "INFO:tensorflow:global_step/sec: 9.71285\n",
      "INFO:tensorflow:loss = 129.35184, step = 503701 (10.308 sec)\n",
      "INFO:tensorflow:global_step/sec: 9.30717\n",
      "INFO:tensorflow:loss = 28.194618, step = 503801 (10.731 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.04729\n",
      "INFO:tensorflow:loss = 95.31031, step = 503901 (12.428 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 504000 into ./Trained_models/Models_WnD/xwd2/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 7.02291\n",
      "INFO:tensorflow:loss = 175.00616, step = 504001 (14.233 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.09595\n",
      "INFO:tensorflow:loss = 231.28107, step = 504101 (12.360 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.42341\n",
      "INFO:tensorflow:loss = 94.873474, step = 504201 (11.869 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.2264\n",
      "INFO:tensorflow:loss = 189.30176, step = 504301 (8.908 sec)\n",
      "INFO:tensorflow:global_step/sec: 9.65133\n",
      "INFO:tensorflow:loss = 180.93079, step = 504401 (10.361 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.43454\n",
      "INFO:tensorflow:loss = 42.6127, step = 504501 (11.855 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.87799\n",
      "INFO:tensorflow:loss = 121.28508, step = 504601 (11.261 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.1421\n",
      "INFO:tensorflow:loss = 183.14847, step = 504701 (8.976 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.94637\n",
      "INFO:tensorflow:loss = 141.76396, step = 504801 (11.184 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.49081\n",
      "INFO:tensorflow:loss = 83.026245, step = 504901 (11.776 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 505000 into ./Trained_models/Models_WnD/xwd2/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 7.73969\n",
      "INFO:tensorflow:loss = 135.8442, step = 505001 (12.910 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.2699\n",
      "INFO:tensorflow:loss = 72.126785, step = 505101 (9.742 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.494\n",
      "INFO:tensorflow:loss = 166.14081, step = 505201 (8.707 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.45568\n",
      "INFO:tensorflow:loss = 222.81348, step = 505301 (11.818 sec)\n",
      "INFO:tensorflow:global_step/sec: 9.94358\n",
      "INFO:tensorflow:loss = 130.33061, step = 505401 (10.069 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.9226\n",
      "INFO:tensorflow:loss = 100.34863, step = 505501 (8.377 sec)\n",
      "INFO:tensorflow:global_step/sec: 9.66322\n",
      "INFO:tensorflow:loss = 122.994194, step = 505601 (10.349 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.93243\n",
      "INFO:tensorflow:loss = 36.112663, step = 505701 (11.193 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.3597\n",
      "INFO:tensorflow:loss = 156.85545, step = 505801 (9.651 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.3235\n",
      "INFO:tensorflow:loss = 92.25204, step = 505901 (9.692 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 506000 into ./Trained_models/Models_WnD/xwd2/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 7.17093\n",
      "INFO:tensorflow:loss = 145.4174, step = 506001 (13.939 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.82003\n",
      "INFO:tensorflow:loss = 160.19179, step = 506101 (11.342 sec)\n",
      "INFO:tensorflow:global_step/sec: 9.31789\n",
      "INFO:tensorflow:loss = 73.098404, step = 506201 (10.739 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.4993\n",
      "INFO:tensorflow:loss = 202.73114, step = 506301 (9.513 sec)\n",
      "INFO:tensorflow:global_step/sec: 9.43787\n",
      "INFO:tensorflow:loss = 121.32515, step = 506401 (10.601 sec)\n",
      "INFO:tensorflow:global_step/sec: 12.472\n",
      "INFO:tensorflow:loss = 164.20245, step = 506501 (8.013 sec)\n",
      "INFO:tensorflow:global_step/sec: 13.2466\n",
      "INFO:tensorflow:loss = 203.79797, step = 506601 (7.562 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.6507\n",
      "INFO:tensorflow:loss = 95.31999, step = 506701 (8.567 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.0815\n",
      "INFO:tensorflow:loss = 75.97534, step = 506801 (3.988 sec)\n",
      "INFO:tensorflow:global_step/sec: 18.4787\n",
      "INFO:tensorflow:loss = 190.13806, step = 506901 (5.412 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 507000 into ./Trained_models/Models_WnD/xwd2/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 11.9692\n",
      "INFO:tensorflow:loss = 194.2215, step = 507001 (8.354 sec)\n",
      "INFO:tensorflow:global_step/sec: 16.3445\n",
      "INFO:tensorflow:loss = 196.85205, step = 507101 (6.120 sec)\n",
      "INFO:tensorflow:global_step/sec: 16.338\n",
      "INFO:tensorflow:loss = 156.927, step = 507201 (6.118 sec)\n",
      "INFO:tensorflow:global_step/sec: 14.0785\n",
      "INFO:tensorflow:loss = 59.03727, step = 507301 (7.110 sec)\n",
      "INFO:tensorflow:global_step/sec: 7.89612\n",
      "INFO:tensorflow:loss = 63.472084, step = 507401 (12.663 sec)\n",
      "INFO:tensorflow:global_step/sec: 7.62604\n",
      "INFO:tensorflow:loss = 77.887146, step = 507501 (13.121 sec)\n",
      "INFO:tensorflow:global_step/sec: 7.92274\n",
      "INFO:tensorflow:loss = 173.3025, step = 507601 (12.615 sec)\n",
      "INFO:tensorflow:global_step/sec: 7.31856\n",
      "INFO:tensorflow:loss = 186.27783, step = 507701 (13.672 sec)\n",
      "INFO:tensorflow:global_step/sec: 7.76525\n",
      "INFO:tensorflow:loss = 94.89624, step = 507801 (12.869 sec)\n",
      "INFO:tensorflow:global_step/sec: 7.9253\n",
      "INFO:tensorflow:loss = 199.32018, step = 507901 (12.616 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 508000 into ./Trained_models/Models_WnD/xwd2/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 7.18547\n",
      "INFO:tensorflow:loss = 65.541916, step = 508001 (13.915 sec)\n",
      "INFO:tensorflow:global_step/sec: 9.21427\n",
      "INFO:tensorflow:loss = 198.88066, step = 508101 (10.859 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.2015\n",
      "INFO:tensorflow:loss = 137.90196, step = 508201 (9.799 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.0077\n",
      "INFO:tensorflow:loss = 114.88909, step = 508301 (9.990 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.5656\n",
      "INFO:tensorflow:loss = 213.41064, step = 508401 (9.466 sec)\n",
      "INFO:tensorflow:global_step/sec: 9.9723\n",
      "INFO:tensorflow:loss = 81.284164, step = 508501 (10.029 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.41361\n",
      "INFO:tensorflow:loss = 129.6108, step = 508601 (11.892 sec)\n",
      "INFO:tensorflow:global_step/sec: 9.09949\n",
      "INFO:tensorflow:loss = 94.6729, step = 508701 (10.978 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.89383\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 91.11488, step = 508801 (11.258 sec)\n",
      "INFO:tensorflow:global_step/sec: 9.33307\n",
      "INFO:tensorflow:loss = 49.89338, step = 508901 (10.703 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 509000 into ./Trained_models/Models_WnD/xwd2/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 9.44404\n",
      "INFO:tensorflow:loss = 77.69331, step = 509001 (10.586 sec)\n",
      "INFO:tensorflow:global_step/sec: 9.43567\n",
      "INFO:tensorflow:loss = 71.5511, step = 509101 (10.602 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.22607\n",
      "INFO:tensorflow:loss = 118.92496, step = 509201 (12.157 sec)\n",
      "INFO:tensorflow:global_step/sec: 9.35138\n",
      "INFO:tensorflow:loss = 208.34885, step = 509301 (10.697 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.0863\n",
      "INFO:tensorflow:loss = 76.02121, step = 509401 (9.012 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.38389\n",
      "INFO:tensorflow:loss = 106.89839, step = 509501 (11.933 sec)\n",
      "INFO:tensorflow:global_step/sec: 9.25248\n",
      "INFO:tensorflow:loss = 52.936962, step = 509601 (10.810 sec)\n",
      "INFO:tensorflow:global_step/sec: 9.55725\n",
      "INFO:tensorflow:loss = 56.721832, step = 509701 (10.469 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.7219\n",
      "INFO:tensorflow:loss = 88.00458, step = 509801 (9.328 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.0369\n",
      "INFO:tensorflow:loss = 109.713104, step = 509901 (9.052 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 510000 into ./Trained_models/Models_WnD/xwd2/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 7.1145\n",
      "INFO:tensorflow:loss = 214.00111, step = 510001 (14.051 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.2475\n",
      "INFO:tensorflow:loss = 182.89073, step = 510101 (9.772 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.6013\n",
      "INFO:tensorflow:loss = 195.94952, step = 510201 (8.611 sec)\n",
      "INFO:tensorflow:global_step/sec: 9.49299\n",
      "INFO:tensorflow:loss = 144.07513, step = 510301 (10.533 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.26611\n",
      "INFO:tensorflow:loss = 127.55294, step = 510401 (12.096 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.0532\n",
      "INFO:tensorflow:loss = 46.514, step = 510501 (9.960 sec)\n",
      "INFO:tensorflow:global_step/sec: 9.5676\n",
      "INFO:tensorflow:loss = 66.82945, step = 510601 (10.438 sec)\n",
      "INFO:tensorflow:global_step/sec: 9.28421\n",
      "INFO:tensorflow:loss = 223.57925, step = 510701 (10.775 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.62297\n",
      "INFO:tensorflow:loss = 111.333115, step = 510801 (11.597 sec)\n",
      "INFO:tensorflow:global_step/sec: 9.25635\n",
      "INFO:tensorflow:loss = 100.36212, step = 510901 (10.814 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 511000 into ./Trained_models/Models_WnD/xwd2/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 122.40211.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2018-12-19-09:05:33\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from ./Trained_models/Models_WnD/xwd2/model.ckpt-511000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [50/500]\n",
      "INFO:tensorflow:Evaluation [100/500]\n",
      "INFO:tensorflow:Evaluation [150/500]\n",
      "INFO:tensorflow:Evaluation [200/500]\n",
      "INFO:tensorflow:Evaluation [250/500]\n",
      "INFO:tensorflow:Evaluation [300/500]\n",
      "INFO:tensorflow:Evaluation [350/500]\n",
      "INFO:tensorflow:Evaluation [400/500]\n",
      "INFO:tensorflow:Evaluation [450/500]\n",
      "INFO:tensorflow:Evaluation [500/500]\n",
      "INFO:tensorflow:Finished evaluation at 2018-12-19-09:05:43\n",
      "INFO:tensorflow:Saving dict for global step 511000: accuracy = 0.06751753, average_loss = 4.7579403, global_step = 511000, loss = 288.16272\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 511000: ./Trained_models/Models_WnD/xwd2/model.ckpt-511000\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Warm-starting with WarmStartSettings: WarmStartSettings(ckpt_to_initialize_from='./Trained_models/Models_WnD/xwd2/', vars_to_warm_start='.*', var_name_to_vocab_info={}, var_name_to_prev_var_name={})\n",
      "INFO:tensorflow:Warm-starting from: ('./Trained_models/Models_WnD/xwd2/',)\n",
      "INFO:tensorflow:Warm-starting variable: dnn/hiddenlayer_1/kernel; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: linear/linear_model/ConstructionType/weights; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: dnn/hiddenlayer_0/bias; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: dnn/input_from_feature_columns/input_layer/BpType_embedding/embedding_weights; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: linear/linear_model/x_ProductCodes/weights; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: dnn/hiddenlayer_2/batchnorm_2/beta; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: dnn/hiddenlayer_1/batchnorm_1/beta; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: dnn/hiddenlayer_0/batchnorm_0/beta; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: dnn/hiddenlayer_2/batchnorm_2/gamma; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: linear/linear_model/ConstructionType_X_Region/weights; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: dnn/hiddenlayer_1/batchnorm_1/gamma; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: linear/linear_model/bias_weights; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: dnn/input_from_feature_columns/input_layer/ConstructionType_embedding/embedding_weights; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: dnn/hiddenlayer_0/kernel; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: dnn/hiddenlayer_1/bias; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: dnn/hiddenlayer_0/batchnorm_0/gamma; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: dnn/logits/kernel; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: linear/linear_model/show_ProductCodes/weights; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: dnn/hiddenlayer_2/kernel; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: dnn/logits/bias; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: dnn/input_from_feature_columns/input_layer/BpClass_embedding/embedding_weights; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: dnn/hiddenlayer_2/bias; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: dnn/input_from_feature_columns/input_layer/Region_embedding/embedding_weights; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from ./Trained_models/Models_WnD/xwd2/model.ckpt-511000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 511000 into ./Trained_models/Models_WnD/xwd2/model.ckpt.\n",
      "INFO:tensorflow:loss = 60.121986, step = 511001\n",
      "INFO:tensorflow:global_step/sec: 9.27416\n",
      "INFO:tensorflow:loss = 34.272594, step = 511101 (10.788 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.3934\n",
      "INFO:tensorflow:loss = 69.93891, step = 511201 (9.624 sec)\n",
      "INFO:tensorflow:global_step/sec: 9.16198\n",
      "INFO:tensorflow:loss = 59.076096, step = 511301 (10.911 sec)\n",
      "INFO:tensorflow:global_step/sec: 9.43652\n",
      "INFO:tensorflow:loss = 73.13171, step = 511401 (10.597 sec)\n",
      "INFO:tensorflow:global_step/sec: 9.1294\n",
      "INFO:tensorflow:loss = 104.295044, step = 511501 (10.952 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.0403\n",
      "INFO:tensorflow:loss = 146.90668, step = 511601 (9.958 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.6805\n",
      "INFO:tensorflow:loss = 85.686264, step = 511701 (9.367 sec)\n",
      "INFO:tensorflow:global_step/sec: 12.6235\n",
      "INFO:tensorflow:loss = 174.20442, step = 511801 (7.920 sec)\n",
      "INFO:tensorflow:global_step/sec: 14.1526\n",
      "INFO:tensorflow:loss = 219.60951, step = 511901 (7.075 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 512000 into ./Trained_models/Models_WnD/xwd2/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 9.10606\n",
      "INFO:tensorflow:loss = 108.70628, step = 512001 (10.970 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.9295\n",
      "INFO:tensorflow:loss = 168.03355, step = 512101 (4.360 sec)\n",
      "INFO:tensorflow:global_step/sec: 20.0793\n",
      "INFO:tensorflow:loss = 191.96588, step = 512201 (4.982 sec)\n",
      "INFO:tensorflow:global_step/sec: 16.6023\n",
      "INFO:tensorflow:loss = 208.2977, step = 512301 (6.024 sec)\n",
      "INFO:tensorflow:global_step/sec: 17.0541\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 189.53143, step = 512401 (5.861 sec)\n",
      "INFO:tensorflow:global_step/sec: 16.4693\n",
      "INFO:tensorflow:loss = 160.46295, step = 512501 (6.074 sec)\n",
      "INFO:tensorflow:global_step/sec: 15.0319\n",
      "INFO:tensorflow:loss = 126.23038, step = 512601 (6.655 sec)\n",
      "INFO:tensorflow:global_step/sec: 7.91827\n",
      "INFO:tensorflow:loss = 239.89944, step = 512701 (12.631 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.2105\n",
      "INFO:tensorflow:loss = 119.658966, step = 512801 (12.177 sec)\n",
      "INFO:tensorflow:global_step/sec: 7.8263\n",
      "INFO:tensorflow:loss = 146.0073, step = 512901 (12.777 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 513000 into ./Trained_models/Models_WnD/xwd2/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 6.41903\n",
      "INFO:tensorflow:loss = 123.206314, step = 513001 (15.576 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.52727\n",
      "INFO:tensorflow:loss = 133.26918, step = 513101 (11.734 sec)\n",
      "INFO:tensorflow:global_step/sec: 7.97907\n",
      "INFO:tensorflow:loss = 160.47958, step = 513201 (12.543 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.73909\n",
      "INFO:tensorflow:loss = 145.61436, step = 513301 (11.429 sec)\n",
      "INFO:tensorflow:global_step/sec: 9.41133\n",
      "INFO:tensorflow:loss = 47.568245, step = 513401 (10.629 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.4328\n",
      "INFO:tensorflow:loss = 66.904655, step = 513501 (9.583 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.9123\n",
      "INFO:tensorflow:loss = 93.11511, step = 513601 (9.160 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.4315\n",
      "INFO:tensorflow:loss = 121.12945, step = 513701 (8.749 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.503\n",
      "INFO:tensorflow:loss = 34.874664, step = 513801 (9.525 sec)\n",
      "INFO:tensorflow:global_step/sec: 9.37993\n",
      "INFO:tensorflow:loss = 96.97028, step = 513901 (10.659 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 514000 into ./Trained_models/Models_WnD/xwd2/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 7.42214\n",
      "INFO:tensorflow:loss = 170.62744, step = 514001 (13.470 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.25638\n",
      "INFO:tensorflow:loss = 236.27567, step = 514101 (12.115 sec)\n",
      "INFO:tensorflow:global_step/sec: 9.331\n",
      "INFO:tensorflow:loss = 86.33453, step = 514201 (10.715 sec)\n",
      "INFO:tensorflow:global_step/sec: 12.6682\n",
      "INFO:tensorflow:loss = 182.8462, step = 514301 (7.894 sec)\n",
      "INFO:tensorflow:global_step/sec: 9.80222\n",
      "INFO:tensorflow:loss = 178.39825, step = 514401 (10.213 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.38541\n",
      "INFO:tensorflow:loss = 41.38939, step = 514501 (11.917 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.84041\n",
      "INFO:tensorflow:loss = 128.04318, step = 514601 (11.314 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.3983\n",
      "INFO:tensorflow:loss = 183.61957, step = 514701 (8.767 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.51103\n",
      "INFO:tensorflow:loss = 112.475204, step = 514801 (11.764 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.60369\n",
      "INFO:tensorflow:loss = 75.20325, step = 514901 (11.614 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 515000 into ./Trained_models/Models_WnD/xwd2/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 7.91841\n",
      "INFO:tensorflow:loss = 136.96701, step = 515001 (12.623 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.9296\n",
      "INFO:tensorflow:loss = 67.02398, step = 515101 (9.155 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.8555\n",
      "INFO:tensorflow:loss = 170.35269, step = 515201 (8.434 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.79576\n",
      "INFO:tensorflow:loss = 218.18893, step = 515301 (11.375 sec)\n",
      "INFO:tensorflow:global_step/sec: 9.80272\n",
      "INFO:tensorflow:loss = 126.79086, step = 515401 (10.194 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.8887\n",
      "INFO:tensorflow:loss = 95.21481, step = 515501 (8.413 sec)\n",
      "INFO:tensorflow:global_step/sec: 9.71266\n",
      "INFO:tensorflow:loss = 118.694855, step = 515601 (10.300 sec)\n",
      "INFO:tensorflow:global_step/sec: 9.02212\n",
      "INFO:tensorflow:loss = 38.512257, step = 515701 (11.077 sec)\n",
      "INFO:tensorflow:global_step/sec: 9.94419\n",
      "INFO:tensorflow:loss = 156.80544, step = 515801 (10.057 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.3022\n",
      "INFO:tensorflow:loss = 80.47575, step = 515901 (9.710 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 516000 into ./Trained_models/Models_WnD/xwd2/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 7.43914\n",
      "INFO:tensorflow:loss = 138.781, step = 516001 (13.436 sec)\n",
      "INFO:tensorflow:global_step/sec: 9.14175\n",
      "INFO:tensorflow:loss = 159.00508, step = 516101 (10.942 sec)\n",
      "INFO:tensorflow:global_step/sec: 9.11416\n",
      "INFO:tensorflow:loss = 76.34631, step = 516201 (10.971 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.4991\n",
      "INFO:tensorflow:loss = 211.48059, step = 516301 (9.524 sec)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-cbb11526b0bd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# tot_model.evaluate(input_fn=eval_input_fn,steps=500)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mtot_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_input_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1e4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mtot_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0meval_input_fn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/estimator/estimator.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, input_fn, hooks, steps, max_steps, saving_listeners)\u001b[0m\n\u001b[1;32m    352\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    353\u001b[0m       \u001b[0msaving_listeners\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_listeners_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 354\u001b[0;31m       \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    355\u001b[0m       \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Loss for final step: %s.'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/estimator/estimator.py\u001b[0m in \u001b[0;36m_train_model\u001b[0;34m(self, input_fn, hooks, saving_listeners)\u001b[0m\n\u001b[1;32m   1205\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_model_distributed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1206\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1207\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_model_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1208\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1209\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_train_model_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/estimator/estimator.py\u001b[0m in \u001b[0;36m_train_model_default\u001b[0;34m(self, input_fn, hooks, saving_listeners)\u001b[0m\n\u001b[1;32m   1239\u001b[0m       return self._train_with_estimator_spec(estimator_spec, worker_hooks,\n\u001b[1;32m   1240\u001b[0m                                              \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglobal_step_tensor\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1241\u001b[0;31m                                              saving_listeners)\n\u001b[0m\u001b[1;32m   1242\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1243\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_train_model_distributed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/estimator/estimator.py\u001b[0m in \u001b[0;36m_train_with_estimator_spec\u001b[0;34m(self, estimator_spec, worker_hooks, hooks, global_step_tensor, saving_listeners)\u001b[0m\n\u001b[1;32m   1469\u001b[0m       \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1470\u001b[0m       \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mmon_sess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_stop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1471\u001b[0;31m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmon_sess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mestimator_spec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mestimator_spec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1472\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1473\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    669\u001b[0m                           \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    670\u001b[0m                           \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 671\u001b[0;31m                           run_metadata=run_metadata)\n\u001b[0m\u001b[1;32m    672\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    673\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mrun_step_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1154\u001b[0m                               \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1155\u001b[0m                               \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1156\u001b[0;31m                               run_metadata=run_metadata)\n\u001b[0m\u001b[1;32m   1157\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0m_PREEMPTION_ERRORS\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1158\u001b[0m         logging.info('An error was raised. This may be due to a preemption in '\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1238\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1239\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1240\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1241\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_PREEMPTION_ERRORS\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1242\u001b[0m       \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1310\u001b[0m                                   \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1311\u001b[0m                                   \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1312\u001b[0;31m                                   run_metadata=run_metadata)\n\u001b[0m\u001b[1;32m   1313\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1314\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_hooks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1074\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1075\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1076\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1077\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1078\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mrun_step_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraw_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_with_hooks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    927\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 929\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    930\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1150\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1152\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1153\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1327\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1328\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1329\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1330\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1332\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1333\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1334\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1335\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1336\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1317\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1319\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1405\u001b[0m     return tf_session.TF_SessionRun_wrapper(\n\u001b[1;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1407\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1409\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# # train step # = trains데이터수/64=4500 -> 10,000=2epoch\n",
    "# # eval step # = eval데이터수/64=240 -> 500=2epoch\n",
    "# tot_model.train(input_fn=train_input_fn, steps = int(1e4)) \n",
    "# tot_model.evaluate(input_fn=eval_input_fn,steps=500) \n",
    "while True:\n",
    "    tot_model.train(input_fn=train_input_fn, steps = int(1e4)) \n",
    "    tot_model.evaluate(input_fn=eval_input_fn,steps=500) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 평가평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/util/tf_inspect.py:75: DeprecationWarning: inspect.getargspec() is deprecated, use inspect.signature() instead\n",
      "  return _inspect.getargspec(target)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from ./Trained_models/Models_WnD/xwd2/model.ckpt-516000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "0.23732614249219416\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from ./Trained_models/Models_WnD/xwd2/model.ckpt-516000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "0.3682940675560602\n"
     ]
    }
   ],
   "source": [
    "# 평가 with predict data\n",
    "with open('./Datasets/eval_181218_final.pkl','rb') as f:\n",
    "    test1 = pickle.load(f)\n",
    "\n",
    "true_label = test1.y_ProductCodes.tolist()\n",
    "y_voca = np.array(vL[\"yv\"])\n",
    "ex_item = y_voca != b\"99999999999\"\n",
    "\n",
    "p_result = tot_model.predict(input_fn=pred_input_fn)\n",
    "answers = []\n",
    "  \n",
    "for num, item in enumerate(p_result):\n",
    "    if num>=len(true_label):\n",
    "        break\n",
    "    else:\n",
    "        prob_list = ex_item*item['probabilities']\n",
    "        esti_label = y_voca[np.argsort(np.argsort(prob_list)[::-1])<5]\n",
    "        answers.append(int(true_label[num] in esti_label))\n",
    "print(np.mean(answers))\n",
    "\n",
    "p_result = tot_model.predict(input_fn=pred_input_fn)\n",
    "answers = []\n",
    "  \n",
    "for num, item in enumerate(p_result):\n",
    "    if num>=len(true_label):\n",
    "        break\n",
    "    else:\n",
    "        prob_list = ex_item*item['probabilities']\n",
    "        esti_label = y_voca[np.argsort(np.argsort(prob_list)[::-1])<10]\n",
    "        answers.append(int(true_label[num] in esti_label))\n",
    "print(np.mean(answers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.datetime(2018, 12, 18, 7, 8, 8)"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os.path, time\n",
    "folder = \"../skts_project/Datasets/\"\n",
    "foldertime = time.ctime(os.path.getmtime(file))\n",
    "foldertime2 = datetime.datetime.strptime(foldertime, \"%a %b %d %H:%M:%S %Y\")\n",
    "foldertime2\n",
    "# 로드 피클\n",
    "# 마지막 날짜와 비교\n",
    "# 현 날짜가 피클 마지막 보다 더 늦은 시간이면 변경\n",
    "# 현 날짜 피클에 추가\n",
    "# 피클 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "주문_2014 = pd.read_csv('C:/Users/kim85/OneDrive/Project_AgileSoda/원본/추가5차_180920/주문_2014.csv', encoding = 'utf-8', index_col=0, dtype = 'str')\n",
    "주문_2015 = pd.read_csv('C:/Users/kim85/OneDrive/Project_AgileSoda/원본/추가5차_180920/주문_2015.csv', encoding = 'utf-8', index_col=0, dtype = 'str')\n",
    "주문_2016 = pd.read_csv('C:/Users/kim85/OneDrive/Project_AgileSoda/원본/추가5차_180920/주문_2016.csv', encoding = 'utf-8', index_col=0, dtype = 'str')\n",
    "주문_2017 = pd.read_csv('C:/Users/kim85/OneDrive/Project_AgileSoda/원본/추가5차_180920/주문_2017.csv', encoding = 'utf-8', index_col=0, dtype = 'str')\n",
    "주문_2018 = pd.read_csv('C:/Users/kim85/OneDrive/Project_AgileSoda/원본/추가5차_180920/주문_2018.csv', encoding = 'utf-8', index_col=0, dtype = 'str')\n",
    "주문상품_2014 = pd.read_csv('C:/Users/kim85/OneDrive/Project_AgileSoda/원본/추가5차_180920/주문상품_2014.csv', encoding = 'utf-8', index_col=0, dtype = 'str')\n",
    "주문상품_2015 = pd.read_csv('C:/Users/kim85/OneDrive/Project_AgileSoda/원본/추가5차_180920/주문상품_2015.csv', encoding = 'utf-8', index_col=0, dtype = 'str')\n",
    "주문상품_2016 = pd.read_csv('C:/Users/kim85/OneDrive/Project_AgileSoda/원본/추가5차_180920/주문상품_2016.csv', encoding = 'utf-8', index_col=0, dtype = 'str')\n",
    "주문상품_2017 = pd.read_csv('C:/Users/kim85/OneDrive/Project_AgileSoda/원본/추가5차_180920/주문상품_2017.csv', encoding = 'utf-8', index_col=0, dtype = 'str')\n",
    "주문상품_2018 = pd.read_csv('C:/Users/kim85/OneDrive/Project_AgileSoda/원본/추가5차_180920/주문상품_2018.csv', encoding = 'utf-8', index_col=0, dtype = 'str')\n",
    "주문상품출하_2014 = pd.read_csv('C:/Users/kim85/OneDrive/Project_AgileSoda/원본/추가5차_180920/주문상품출하_2014.csv', encoding = 'utf-8', index_col=0, dtype = 'str')\n",
    "주문상품출하_2015 = pd.read_csv('C:/Users/kim85/OneDrive/Project_AgileSoda/원본/추가5차_180920/주문상품출하_2015.csv', encoding = 'utf-8', index_col=0, dtype = 'str')\n",
    "주문상품출하_2016 = pd.read_csv('C:/Users/kim85/OneDrive/Project_AgileSoda/원본/추가5차_180920/주문상품출하_2016.csv', encoding = 'utf-8', index_col=0, dtype = 'str')\n",
    "주문상품출하_2017 = pd.read_csv('C:/Users/kim85/OneDrive/Project_AgileSoda/원본/추가5차_180920/주문상품출하_2017.csv', encoding = 'utf-8', index_col=0, dtype = 'str')\n",
    "주문상품출하_2018 = pd.read_csv('C:/Users/kim85/OneDrive/Project_AgileSoda/원본/추가5차_180920/주문상품출하_2018.csv', encoding = 'utf-8', index_col=0, dtype = 'str')\n",
    "상품마스터 = pd.read_csv('c:/Users/kim85/OneDrive/Project_AgileSoda/원본/추가6차_181005/상품마스터.csv',encoding ='utf-8',dtype = 'str')\n",
    "조직마스터 = pd.read_csv('c:/users/kim85/OneDrive/Project_AgileSoda/원본/추가6차_181005/조직마스터.csv', encoding ='utf-8', dtype ='str')\n",
    "사업장= pd.read_csv('c:/users/kim85/OneDrive/Project_AgileSoda/원본/추가6차_181005/사업장.csv', encoding ='utf-8', dtype ='str')\n",
    "공사유형 = pd.read_csv('c:/users/kim85/OneDrive/Project_AgileSoda/원본/추가6차_181005/공사유형.csv', encoding ='utf-8', dtype ='str')\n",
    "\n",
    "주문 = pd.concat([주문_2014, 주문_2015, 주문_2016, 주문_2017, 주문_2018])\n",
    "주문상품 = pd.concat([주문상품_2014, 주문상품_2015, 주문상품_2016, 주문상품_2017, 주문상품_2018])\n",
    "주문상품출하 = pd.concat([주문상품출하_2014, 주문상품출하_2015, 주문상품출하_2016, 주문상품출하_2017, 주문상품출하_2018])\n",
    "\n",
    "# 주문 처리\n",
    "주문 = 주문.reset_index()[['ORDE_IDEN_NUMB','CONS_IDEN_NAME','GROUPID','CLIENTID','BRANCHID',\n",
    "                       'DELI_AREA_CODE','REGI_DATE_TIME','ORDE_USER_ID']].drop_duplicates(keep='first')\n",
    "주문상품 = 주문상품.reset_index()[['ORDE_IDEN_NUMB','ORDE_SEQU_NUMB','GOOD_IDEN_NUMB',\n",
    "                           'ORDE_REQU_QUAN']].drop_duplicates(keep='first')\n",
    "주문상품['ORDE_REQU_QUAN'] = 주문상품['ORDE_REQU_QUAN'].astype('int64')\n",
    "주문상품 = 주문상품.groupby(['ORDE_IDEN_NUMB','GOOD_IDEN_NUMB'])['ORDE_REQU_QUAN'].agg('sum').reset_index()\n",
    "주문상품출하 =  주문상품출하.reset_index()[['ORDE_IDEN_NUMB', 'DELI_STAT_FLAG']].drop_duplicates(keep='first')\n",
    "주문상품출하 = 주문상품출하[주문상품출하.DELI_STAT_FLAG=='70'].ORDE_IDEN_NUMB.unique()\n",
    "\n",
    "주문상품_주문 = pd.merge(주문상품, 주문, on = 'ORDE_IDEN_NUMB', how = 'left')\n",
    "주문상품_주문_출하 = 주문상품_주문[주문상품_주문.ORDE_IDEN_NUMB.isin(주문상품출하)]\n",
    "주문전체 = 주문상품_주문_출하[주문상품_주문_출하.GROUPID != '101'].drop_duplicates(keep='first')\n",
    "\n",
    "# 상품 처리\n",
    "상품마스터 = 상품마스터[['good_iden_numb','cate_id','good_name','good_spec','good_type','repre_good']].drop_duplicates(keep='first')\n",
    "상품마스터 = 상품마스터.rename(columns = {'good_iden_numb':'GOOD_IDEN_NUMB'})\n",
    "# repre_good - Y : 옵션대표상품, N : 단품, P : 옵션상품 // good_type - 10 : 일반, 20 : 지정,60 : 공구, 70 : 안전,80 : 보안\n",
    "\n",
    "상품주문전체 = pd.merge(주문전체, 상품마스터, on = 'GOOD_IDEN_NUMB', how = 'left')\n",
    "상품주문전체 = 상품주문전체[상품주문전체.repre_good=='N'] # 옵션상품 제외"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 사업장 처리\n",
    "사업장 = pd.concat([\n",
    "        사업장[['BRANCHID','AREATYPE','BRANCHBUSITYPE','BRANCHBUSICLAS','WORKID']].rename(columns={'BRANCHID':'BORGID'}), \n",
    "        사업장[['BRANCHCD','AREATYPE','BRANCHBUSITYPE','BRANCHBUSICLAS','WORKID']].rename(columns={'BRANCHCD':'BORGID'})\n",
    "    ], axis=0).drop_duplicates(keep='first')\n",
    "\n",
    "공사유형_사업장 = pd.merge(\n",
    "    사업장, \n",
    "    공사유형[['WORKID','WORKNM']].drop_duplicates(keep='first'), \n",
    "    how = 'left', on = 'WORKID')\n",
    "\n",
    "조직마스터 = 조직마스터[(조직마스터.BORGTYPECD == 'BCH') & (조직마스터.SVCTYPECD == 'BUY')] # 사업장레벨 및 구매사만\n",
    "조직마스터 = pd.concat([\n",
    "        조직마스터[['BORGID','BORGNM']], \n",
    "        조직마스터[['BORGCD','BORGNM']].rename(columns={'BORGCD':'BORGID'})\n",
    "    ], axis=0).drop_duplicates(keep='first')\n",
    "\n",
    "조직전체 = pd.merge(조직마스터, 공사유형_사업장, how = 'left', on = 'BORGID').rename(columns={'BORGID':'BRANCHID'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
